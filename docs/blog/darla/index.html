<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Joey Stanley">
<meta name="dcterms.date" content="2025-02-12">

<title>A tutorial on using DARLA – Joey Stanley</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-5b4ad623e5705c0698d39aec6f10cf02.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=350348361"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', '350348361', { 'anonymize_ip': true});
</script>
<link href="https://fonts.googleapis.com/css2?family=Crimson+Pro:ital,wght@0,200..900;1,200..900&amp;family=Noto+Music&amp;family=Noto+Sans+Display:ital,wght@0,100..900;1,100..900&amp;family=Noto+Sans+Math&amp;family=Noto+Sans+Mono:wght@100..900&amp;family=Noto+Sans:ital,wght@0,100..900;1,100..900&amp;family=Noto+Serif+Display:ital,wght@0,100..900;1,100..900&amp;family=Noto+Serif:ital,wght@0,100..900;1,100..900&amp;display=swap" rel="stylesheet">


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title"><span id="name">Joey Stanley</span><br><span id="tagline">assistant professor, linguistics</span></span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About Me <em>who am I?</em></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cv/index.html"> 
<span class="menu-text">CV <em>what have I done?</em></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../research/index.html"> 
<span class="menu-text">Research <em>what do I research?</em></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../teaching.html"> 
<span class="menu-text">Teaching <em>what do I teach?</em></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../pages/idiolect"> 
<span class="menu-text">Idiolect <em>what do I sound like?</em></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text">Blog <em>what’s going on?</em></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../ai.html"> 
<span class="menu-text">AI <em>how do I feel about it?</em></span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:joey_stanley@byu.edu"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-list" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-list" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-bi-list">    
        <li>
    <a class="dropdown-item" href="https://bsky.app/profile/joeystanley.com">
 <span class="dropdown-text"><i class="fa-brands fa-bluesky" aria-label="bluesky"></i> Bluesky</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://twitter.com/joey_stan"><i class="bi bi-twitter" role="img">
</i> 
 <span class="dropdown-text">Twitter</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://scholar.google.com/citations?user=61pJV_YAAAAJ&amp;hl=en&amp;oi=sra"><i class="bi bi-mortarboard-fill" role="img">
</i> 
 <span class="dropdown-text">Google Scholar</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/JoeyStanley/joeystanley_new"><i class="bi bi-github" role="img">
</i> 
 <span class="dropdown-text">Github</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../joeystanley.com/feed.xml"><i class="bi bi-rss" role="img">
</i> 
 <span class="dropdown-text">RSS feed</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A tutorial on using DARLA</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">How-to Guides</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Joey Stanley </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 12, 2025</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">February 13, 2025</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#what-is-darla" id="toc-what-is-darla" class="nav-link active" data-scroll-target="#what-is-darla"><span class="header-section-number">1</span> What is DARLA?</a>
  <ul class="collapse">
  <li><a href="#how-this-tutorial-will-work" id="toc-how-this-tutorial-will-work" class="nav-link" data-scroll-target="#how-this-tutorial-will-work"><span class="header-section-number">1.1</span> How this tutorial will work</a></li>
  </ul></li>
  <li><a href="#sec-completely_automated" id="toc-sec-completely_automated" class="nav-link" data-scroll-target="#sec-completely_automated"><span class="header-section-number">2</span> Completely Automated Vowel Extraction</a>
  <ul class="collapse">
  <li><a href="#darlas-in-house-transcription-system" id="toc-darlas-in-house-transcription-system" class="nav-link" data-scroll-target="#darlas-in-house-transcription-system"><span class="header-section-number">2.1</span> DARLA’s in-house transcription system</a></li>
  <li><a href="#sec-bedword" id="toc-sec-bedword" class="nav-link" data-scroll-target="#sec-bedword"><span class="header-section-number">2.2</span> Bed Word</a></li>
  </ul></li>
  <li><a href="#sec-semiautomated" id="toc-sec-semiautomated" class="nav-link" data-scroll-target="#sec-semiautomated"><span class="header-section-number">3</span> Semi-Automated Alignment and Extraction</a>
  <ul class="collapse">
  <li><a href="#a-textgrid-transcription" id="toc-a-textgrid-transcription" class="nav-link" data-scroll-target="#a-textgrid-transcription"><span class="header-section-number">3.1</span> A TextGrid transcription</a></li>
  <li><a href="#a-plaintext-file" id="toc-a-plaintext-file" class="nav-link" data-scroll-target="#a-plaintext-file"><span class="header-section-number">3.2</span> A plaintext file</a></li>
  </ul></li>
  <li><a href="#sec-faveonly" id="toc-sec-faveonly" class="nav-link" data-scroll-target="#sec-faveonly"><span class="header-section-number">4</span> FAVE only</a></li>
  <li><a href="#sec-further_instructions" id="toc-sec-further_instructions" class="nav-link" data-scroll-target="#sec-further_instructions"><span class="header-section-number">5</span> Further instructions</a>
  <ul class="collapse">
  <li><a href="#sec-filtering" id="toc-sec-filtering" class="nav-link" data-scroll-target="#sec-filtering"><span class="header-section-number">5.1</span> The filtering options</a></li>
  <li><a href="#sec-speaker_information" id="toc-sec-speaker_information" class="nav-link" data-scroll-target="#sec-speaker_information"><span class="header-section-number">5.2</span> Enter Speaker Information</a></li>
  </ul></li>
  <li><a href="#sec-output" id="toc-sec-output" class="nav-link" data-scroll-target="#sec-output"><span class="header-section-number">6</span> DARLA’s output</a></li>
  <li><a href="#sec-troubleshooting" id="toc-sec-troubleshooting" class="nav-link" data-scroll-target="#sec-troubleshooting"><span class="header-section-number">7</span> Troubleshooting</a>
  <ul class="collapse">
  <li><a href="#sec-preparing_textgrids" id="toc-sec-preparing_textgrids" class="nav-link" data-scroll-target="#sec-preparing_textgrids"><span class="header-section-number">7.1</span> Preparing TextGrids</a></li>
  <li><a href="#what-to-do-if-darla-crashes" id="toc-what-to-do-if-darla-crashes" class="nav-link" data-scroll-target="#what-to-do-if-darla-crashes"><span class="header-section-number">7.2</span> What to do if DARLA crashes</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">8</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<p>This tutorial focuses on DARLA, an online tool to facilitate automatic processing phonetic data, specifically for English vowels.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> I’ll walk you through the most common use cases, based on my experience using DARLA and what I’ve seen students do. There is more to DARLA than what I can show here, and I encourage you to explore its full capabilities once you’ve mastered the basics.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;This tutorial comes about a decade later than it should have. I hope it can still be of use to new linguistics students.</p></div></div><div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>I am not affiliated with the folks who created or maintain DARLA, but I have been using DARLA since soon after its release in 2015. In grad school, I processed many hundreds of files of all kinds, lengths, and qualities. I don’t know all the inner workings of DARLA, so what I present here is what I’ve been able to gather based on using it a lot.</p>
</div>
</div>
<section id="what-is-darla" class="level2 page-columns page-full" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="what-is-darla"><span class="header-section-number">1</span> What is DARLA?</h2>
<p>DARLA is a website that has various sociophonetic data processing tools set up in a pipeline so that you can send files through various steps to get acoustic measurements. The various tools it uses are difficult to install for an average person, and even if you do have them on your computer, getting the output of one to feed nicely into the next is sometimes not a trivial task. DARLA does all the hard work of setting up the assembly line for you so that you don’t have to.</p>
<p>DARLA’s ultimate goal is to provide you a spreadsheet of acoustic measurements. Specifically, formant measurements at multiple points along the duration of each vowel in your audio file. Because some of the software that it uses are based on English, it only works on English data. And while some people have had success using DARLA for other varieties of English, you’ll have the best results when working with American English.</p>
<p>There are three main processing steps that need to happen to go from raw audio to a spreadsheet of formant measurements. First is <strong>transcription</strong>. We need to have a sentence- or utterance-level transcription of the audio, with timestamps, in regular English orthography. The timestamps are important. If you think about the closed captioning in a movie, it needs to know when to start showing a particular sentence and when to stop showing it. I suspect there’s a file somewhere under-the-hood of a DVD or streaming service that has a transcription file that has the sentence, the start time and the end time. Unlike closed captioning though, our transcription needs to be in a Praat TextGrid format (see <a href="#sec-preparing_textgrids" class="quarto-xref">Section&nbsp;7.1</a> for more details). Regardless of how the transcription is done, it will help in DARLA’s ultimate goal of knowing the start and end points of each vowel in the audio.</p>
<p>Next, is <strong>forced-alignment</strong>. Using a software called the Montreal Forced Aligner (or MFA).<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> This takes a sentence-level transcription and ultimately converts it to a word- and phoneme-level transcription. The way it does this is it’ll take every word in the transcription and look it up in a pronunciation dictionary. DARLA uses the <a href="http://darla.dartmouth.edu/cmudict">CMU Dict</a>.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> It’ll then convert your transcription into a quasi-IPA transcription called ARPABET (see the bottom of <a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict">this page</a>). The MFA then goes through its acoustic model, which knows what each speech sound is supposed to look/sound like in an audio file. For each utterance, it then does the best job it can at matching the audio to the string of speech sounds it’s expecting to find. It’s a somewhat complicated process, but you don’t need to fully understand it. The point is, at the end of forced alignment, MFA (and therefore DARLA) will provide you a version of your transcription that has every word and every phoneme aligned with start and end times.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;Created by Michael McAuliffe, Michaela Socolof, Sarah Mihuc, Michael Wagner, and Morgan Sonderegger in 2017.</p></div><div id="fn3"><p><sup>3</sup>&nbsp;You can <a href="https://montreal-forced-aligner.readthedocs.io/en/latest/">install MFA yourself</a>, but it’s not as easy as other software.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;Also available <a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict">here</a></p></div></div><p>Finally, we have <strong>formant extraction</strong>. DARLA uses a software called <a href="https://github.com/JoFrhwld/FAVE">FAVE</a> to do this step. FAVE goes through the phoneme-level transcription that MFA provides, and looks at each vowel. For each one, it’ll extract a whole bunch of acoustic measurements and save them into a spreadsheet. In the end FAVE (and therefore DARLA) will provide you with that spreadsheet, which you can use for whatever you want, including processing in Excel or some statistical software.</p>
<p>You can do all these steps yourself manually if you’d like, but as old-school sociophoneticians know, that takes forever. You can also install these pieces of software yourself and do it completely offline if you’d like too, but it takes a bit of computer know-how to get that going. Or, you can upload your files to DARLA and with a few clicks, have it do the hard work of sending it through those three processing steps!</p>
<div class="callout callout-style-default callout-tip callout-titled" title="To summarize…">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>To summarize…
</div>
</div>
<div class="callout-body-container callout-body">
<p>The main pipeline is transcription → forced alignment (with MFA) → formant extraction (with FAVE). DARLA lets you jump into the pipeline at any point. You can choose to do all three, just the last two, or just the last one. And with transcription and forced alignment, it offers a few options on how to do it.</p>
</div>
</div>
<section id="how-this-tutorial-will-work" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="how-this-tutorial-will-work"><span class="header-section-number">1.1</span> How this tutorial will work</h3>
<p>What do you need in order to use DARLA? Well, it depends on how much automatic work you want to do. For the rest of this tutorial, it’ll be a bit of a choose-your-own-adventure book.</p>
<ul>
<li><p>If all you have is an audio file and you want DARLA to do transcription, forced alignment, and formant extraction, go to <a href="#sec-completely_automated" class="quarto-xref">Section&nbsp;2</a>.</p></li>
<li><p>If you have a transcription of your audio, and want to do forced alignment and formant extraction, go to <a href="#sec-semiautomated" class="quarto-xref">Section&nbsp;3</a>.</p></li>
<li><p>If you have a force-aligned transcription of your audio already and all you need to do is run FAVE to get formants, go to <a href="#sec-faveonly" class="quarto-xref">Section&nbsp;4</a>.</p></li>
</ul>
<p>Regardless of where along the pipeline you are, many of the options that DARLA presents to you to customize the processing are the same, so I’ve included <a href="#sec-further_instructions" class="quarto-xref">Section&nbsp;5</a>, which has further instructions that apply regardless of what method you choose. If you run into trouble, see <a href="#sec-troubleshooting" class="quarto-xref">Section&nbsp;7</a>.</p>
</section>
</section>
<section id="sec-completely_automated" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="sec-completely_automated"><span class="header-section-number">2</span> Completely Automated Vowel Extraction</h2>
<p>If you’ve got an audio file and are excited to get some quick-and-dirty results, you can send it through DARLA’s <a href="http://darla.dartmouth.edu/cave">completely automatic pipeline</a>. This will automatically transcribe your data using one of two speech recognition systems, and then send it off for further processing.</p>
<section id="darlas-in-house-transcription-system" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="darlas-in-house-transcription-system"><span class="header-section-number">2.1</span> DARLA’s in-house transcription system</h3>
<p>The first of the two methods is DARLA’s <a href="http://darla.dartmouth.edu/uploadasr">in-house speech recognition system</a>. You’ll be presented with this interface, which is typical of all DARLA’s interfaces:</p>
<p><img src="automated_inhouse.png" class="img-fluid"></p>
<p>First, it’ll ask you to upload a sound recording. They recommend audio files at least two minutes long, but it will run on slightly shorter files, although I don’t know what kind of effect that has on the output. As for the next thre questions about filters, see <a href="#sec-filtering" class="quarto-xref">Section&nbsp;5.1</a>. Once you’ve filled out that page and hit “submit”, you can jump to <a href="#sec-speaker_information" class="quarto-xref">Section&nbsp;5.2</a>.</p>
<p>Regarding DARLA’s in-house transcription, <a href="http://darla.dartmouth.edu/about#">they say</a> that it’s not a particularly good model and is really only intended to reliably transcribe the stressed vowel. It’s a model based on 400 hours of speech, but compared to contemporary speech-to-text methods, it doesn’t fare particularly well. They say in <a href="https://aclanthology.org/N15-3015.pdf">their write-up</a> that it has a 42% word-error rate and a 9% stressed vowel error rate once you’ve filtered out some of the bad measurements. If all you’re interested in are average positions of vowel categories, you’re probably okay trying it out, but for anything beyond that and I would start to think about providing your own transcription rather than have DARLA doing it.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="My Recommendation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>My Recommendation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Only use DARLA’s in-house speech recognition system if you want to get a very rough look at some vowel formants. Don’t rely on it for any serious analysis of vowels.</p>
</div>
</div>
</section>
<section id="sec-bedword" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-bedword"><span class="header-section-number">2.2</span> Bed Word</h3>
<p>The other option for completely automated transcription in DARLA is to <a href="http://darla.dartmouth.edu/bedword">use a third-party software called Bed Word</a>. This is a relatively new option (around 2023) and works on more than just English.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Some backstory; feel free to skip">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Some backstory; feel free to skip
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Bed Word is the brainchild of Marcus Ma, a then-undergraduate at Georgia Tech. He noticed that there are decent speech-to-text systems out there, but linguists hardly use them because the output they return is in a format that’s not particularly easy for linguists to work with, especially for subsequent acoustic analysis. So, with the help of Lelia Glass (a linguist at Georgia Tech) and Jim Stanford (who maintains DARLA), Ma took the Deepgram model and incorporated it into a pipeline that gives a Praat TextGrid instead of some other format. I had the opportunity to meet Ma and try out Bed Word before it went live and I was impressed with how good it was!</p>
<p>This is not the first time linguists have incorporated third-party transcription models into linguistic analysis pipelines. DARLA used to have another option that involved sending the audio through YouTube’s closed captioning service. And in 2018, linguists at the University of Washington (Alicia Wassink, Rob Squizzero, Campion Fellin, and David Nichols) introduced <a href="https://clox.ling.washington.edu/#/">CLOx</a>, which involved using Microsoft’s speech-to-text system. These let users leverage the power of models created by companies with far more money and resources than what linguists have, but in sort of a backdoor sort of way. The difference here is that Bed Word is incorporated into DARLA, and the output can be sent on to subsequent processing steps all in one go, which makes it even more convenient.</p>
</div>
</div>
</div>
<p>Because Bed Word uses a third-party software, there’s a small bit of work involved when getting started fo the first time. DARLA gives some instructions on how to do this, which will involve creating an account through <a href="https://developers.deepgram.com/docs/introduction">Deepgram</a>. Using Deepgram (and therefore Bed Word) is technically <a href="https://deepgram.com/pricing">not free</a>, but at the time of writing in February 2025, you get $200 of free credit, which is far more than what you’d need if you’re a casual user of DARLA. So, you shouldn’t have to worry about paying for this service.</p>
<p>If you select this option, you’ll see a screen that looks like this:</p>
<p><img src="bedword.png" class="img-fluid"></p>
<p>There are more options than the in-house transcription. I honestly don’t use Bed Word too much, so I can’t offer additional insight into these options other than what DARLA has on that webpage. I encourage you to read through the explanations carefully. The main one you’ll want to pay attention to is the last one. If your data is in English and you want to get formant measurements and a vowel chart, check this box so DARLA will send your files down the rest of the pipeline.</p>
<p>Once you’ve filled out the entire page and hit “submit”, see <a href="#sec-speaker_information" class="quarto-xref">Section&nbsp;5.2</a> for what to next.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="My Recommendation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>My Recommendation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Bed Word is pretty good. If you plan on processing multiple files with DARLA, and you don’t have other feasible options for transcribing your audio, it’s worth it to get your Deepgram account set up and to use it for transcription.</p>
</div>
</div>
</section>
</section>
<section id="sec-semiautomated" class="level2 page-columns page-full" data-number="3">
<h2 data-number="3" class="anchored" data-anchor-id="sec-semiautomated"><span class="header-section-number">3</span> Semi-Automated Alignment and Extraction</h2>
<p>Automated transcription is great, but it introduces errors and uncertainty into your analysis. If you have the time and resources to do so, it is better to provide DARLA a transcription of the audio. There are several ways to do this.</p>
<ul>
<li><p>You could transcribe your audio manually using <a href="https://www.fon.hum.uva.nl/praat/">Praat</a>, <a href="https://archive.mpi.nl/tla/elan">ELAN</a>, or some other software. This is very time consuming but it is likely the best option if you are concerned about accuracy. It’s a bit of a rite of passage for some linguists (<a href="../../blog/transcribing-a-sociolinguistic-corpus">here are my thoughts</a> when I finished transcribing my dissertation data) and there’s no better way to really get to know your data than to listen and trascribe every second of it. If you’re doing just one audio file, manual transcription shouldn’t take too long.</p></li>
<li><p>If you don’t have the time or resources to do a full manual transcription, you can try correcting an automatic transcription. There are <em>tons</em> of free or paid transcription services and software that you could use, including <a href="@sec-bedword">Bed Word via DARLA</a>. The problem though is that the output might not be in a format that can be processed by phonetic software like DARLA (i.e.&nbsp;a Praat TextGrid). And if the automatic transcription is not very good, you might spend just as much time correcting as you would have just transcribing it yourself.</p></li>
</ul>
<p>Regardless of how you get your transcriptions, in order to use the semi-automated option in DARLA, you’ll need a transcription of your audio file. The format of that transcription will determine which option you use.</p>
<section id="a-textgrid-transcription" class="level3 page-columns page-full" data-number="3.1">
<h3 data-number="3.1" class="anchored" data-anchor-id="a-textgrid-transcription"><span class="header-section-number">3.1</span> A TextGrid transcription</h3>
<p>Probably the most typical way of using DARLA is to provide it with a transcription in the form of a Praat TextGrid.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> This is the method recommended by DARLA. Here are the instructions that DARLA provides when prepping your TextGrid.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;It is beyond the scope of this tutorial to explain what a TextGrid is or how to prepare one. I do however have a <a href="../../downloads/190911-intro_to_Praat.html">Praat basics tutorial</a>, which includes how to create TextGrids. You can also watch Jim Stanford’s <a href="https://www.youtube.com/watch?v=HK1MVfqemUQ">YouTube video</a> on how to prepare a TextGrid for DARLA.</p></div></div><p><img src="textgrid_option.png" class="img-fluid"> I also have some tips on how to prepare your TextGrid in <a href="#sec-preparing_textgrids" class="quarto-xref">Section&nbsp;7.1</a>, including a screenshot of what a properly prepared TextGrid looks like.</p>
<p>Once you’re prepared your TextGrid using DARLA’s instructions and you’ve gone through my tips, you’re ready to go. Here’s the screen you’ll see:</p>
<p><img src="textgrid_interface.png" class="img-fluid"></p>
<p>You just need to upload your audio and your transcription file. For the filtering options see <a href="#sec-filtering" class="quarto-xref">Section&nbsp;5.1</a>. Once you hit submit, see <a href="#sec-speaker_information" class="quarto-xref">Section&nbsp;5.2</a>.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="My Recommendation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>My Recommendation
</div>
</div>
<div class="callout-body-container callout-body">
<p>I agree that this is the best way to use DARLA. It takes time to get the transcriptions you need, but the output is usually very clean.</p>
</div>
</div>
</section>
<section id="a-plaintext-file" class="level3" data-number="3.2">
<h3 data-number="3.2" class="anchored" data-anchor-id="a-plaintext-file"><span class="header-section-number">3.2</span> A plaintext file</h3>
<p>The alternative to using a TextGrid is to upload your transcription as a “plaintext” file. If you’re not even sure what this means, here’s what that would look like:</p>
<p><img src="plaintext_example.png" class="img-fluid"></p>
<p>It’s not pretty, but the content is all there. It’s kind of like a TextGrid transcription but without any timestamps. You might get this if you use a third-party transcription service that does not have linguistic data processing in mind.</p>
<p>DARLA has some instructions on how to prepare for this method, which involves removing extraneous noise from the audio file itself:</p>
<p><img src="plaintext_option.png" class="img-fluid"></p>
<p>The last tip references the “smart replace” option (or something similar) that a lot of word processors have. See <a href="#sec-preparing_textgrids" class="quarto-xref">Section&nbsp;7.1</a>, specifically the part about curly quotes, to get a little more clarification on what that means.</p>
<p>The interface for this looks simliar to what was seen with the TextGrid transcriptions. Simply upload your audio and transcription file. See <a href="#sec-filtering" class="quarto-xref">Section&nbsp;5.1</a> for what to do about the filtering options and see <a href="#sec-speaker_information" class="quarto-xref">Section&nbsp;5.2</a> for what to do once you hit the “submit” button.</p>
<p>I don’t recommend this option for a few reasons. DARLA has to work harder to get an accurate transcription. With a sentence- or utterance-level transcription, DARLA only needs to scan a few seconds of speech and match up a few dozen speech sounds to the audio. With a transcription like this without timestamps, DARLA has to scan the entire audio file and look through hundreds or thousands of speech sounds to match them up. It’s far more prone to error this way, even on pristine audio.</p>
<p>Another reason I don’t recommend it is because extraneous noise and speech errors complicate things. The transcription needs to match <em>exactly</em> what the person says, so DARLA recommends you remove things like loud breaths and other voices. You also need to remove things like false starts or stutters. And since we’re used to tuning those things out, you’re likely going to miss some. To me, this takes a lot of work—perhaps as much as just doing a transcription—and is still prone to error. One single “um” that you forgot to transcribe might throw off the entire transcription. It also means you’re no longer working with the original audio, which makes reproducibility difficult.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="My Recommendation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>My Recommendation
</div>
</div>
<div class="callout-body-container callout-body">
<p>I can’t think of a good reason to use this option unless the transcription file you’re provided is in this format. Even then, I would try to create a Praat TextGrid with what I have to make processing less error-prone.</p>
</div>
</div>
</section>
</section>
<section id="sec-faveonly" class="level2" data-number="4">
<h2 data-number="4" class="anchored" data-anchor-id="sec-faveonly"><span class="header-section-number">4</span> FAVE only</h2>
<p>The last option for DARLA is to just have it extract formant measurements, given an already force-aligned TextGrid. You might need to do this if you have MFA installed on your computer already and just need to run FAVE. Or perhaps you took the MFA output that DARLA provides and made some corrections and want to get an updated spreadsheet of formant measrurements based on those updates.</p>
<p>This option is the last on the page of “semi-automated” options and the interface looks basically the same as all the others we’ve discussed above. Once again, see <a href="#sec-filtering" class="quarto-xref">Section&nbsp;5.1</a> for more detail on the filtering options. Once you hit submit, see <a href="#sec-speaker_information" class="quarto-xref">Section&nbsp;5.2</a>.</p>
<p>You should know that DARLA has a tool to help <a href="http://darla.dartmouth.edu/asreval">look at the quality of transcriptions</a>. In all my years of using DARLA, I’ve actually never used this feature. It may be helpful for you if you need to compare two different transcriptions, but I unfortunately can’t offer any advice.</p>
</section>
<section id="sec-further_instructions" class="level2 page-columns page-full" data-number="5">
<h2 data-number="5" class="anchored" data-anchor-id="sec-further_instructions"><span class="header-section-number">5</span> Further instructions</h2>
<p>The sections below apply to multiple DARLA options, so I’ve put them here instead of integrated with the above walkthroughs so that I don’t have to repeat myself too much. You should have been linked to these sections already if you’re doing a walkthrough.</p>
<section id="sec-filtering" class="level3 page-columns page-full" data-number="5.1">
<h3 data-number="5.1" class="anchored" data-anchor-id="sec-filtering"><span class="header-section-number">5.1</span> The filtering options</h3>
<p>In pretty much every uploading interface in DARLA, you’ll be presented with three filtering options: stop-words, unstressed vowels, and bandwidths:</p>
<p><img src="filtering.png" class="img-fluid"></p>
<p>Let’s go through each of these:</p>
<ul>
<li><p><strong>stop-words</strong>: This refers to the most common words in English. There are numerous lists of stopwords, so there’s no hard-and-fast rule for what is considered a stopword and what is not. <a href="http://darla.dartmouth.edu/stopwords">DARLA’s list</a> is relatively small. The reason why you’d want to remove stopwords is because they tend to be phonetically reduced. Because they’re so common, we tend not to say them with full vowel qualities as we might with other words. Some researchers are not interested in that kind of phonetic reduction, so they often remove stopwords from analysis because it arguably gets in the way of the patterns they hope to find.</p></li>
<li><p><strong>unstressed vowels</strong>: In English, unstressed vowels tend to be schwa-like or otherwise reduced. Many sociophoneticians are not interested in unstressed vowels and instead focus on the vowel quality of stressed vowels. So, you can filter those unstressed vowels out so you don’t have to worry about them.</p></li>
<li><p><strong>bandwidths</strong>: This is a way to kinda measure the quality of audio at the moment the vowel formant measurements are taken. Without getting into the nitty-gritty of it, a larger bandwidth just means that the sound quality is probably not great, which means the formant estimation will be less reliable. <a href="https://www.youtube.com/watch?v=fh7GPtzx5D8">Marinaccino, Shapp, &amp; Singler (2021)</a> is the only study I’ve seen that analyzes bandwidths directly, and they find that checking this box gives you a little less data but overall doesn’t affect the results all that much. Of course, it depends highly on the audio quality: this will filter out many more vowels from digitized cassette tapes than from audio recorded in a sound booth.</p></li>
</ul>
<p>For what it’s worth, these filtering options are not an original feature of DARLA, but I’m glad they’re there.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> I personally say “no” to all of those boxes so that I can be in control of the filters. For example, I use a different set of stopwords than what DARLA uses.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> Ultimately, whether you use those filters is up to you.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;I’m pretty sure they were added was because my team at the University of Georgia requested the option to opt out of those filters so that we could have greater flexibility in how we filter our data.</p></div><div id="fn7"><p><sup>7</sup>&nbsp;I typically use the one called “marimo” from <a href="https://cran.r-project.org/web/packages/stopwords/readme/README.html">the stopwords R package</a>.</p></div></div><div class="callout callout-style-default callout-tip callout-titled" title="My Recommendation">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>My Recommendation
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you are just getting started with sociophonetic analysis, say “yes” to all three of those filters.</p>
<p>If you are competent at sociophonetic data analysis, say “no” to all three of those filters.</p>
</div>
</div>
</section>
<section id="sec-speaker_information" class="level3 page-columns page-full" data-number="5.2">
<h3 data-number="5.2" class="anchored" data-anchor-id="sec-speaker_information"><span class="header-section-number">5.2</span> Enter Speaker Information</h3>
<p>Once you’ve filled out all the information on the form and hit the “submit” button, you’ll have to wait a minute or longer for your files to upload. If you’re working with large, uncompressed .wav files, it might take several minutes, depending on your internet connection. If you’re working with shorter .mp3 files, it might be only a few seconds. Don’t close the webpage just yet! You’ll need to wait until it’s fully uploaded, and only then will a couple new menu options appear that will prompt you to give the Speaker ID and their “Voice Type.”</p>
<p><img src="enter_speaker_information.png" class="img-fluid"></p>
<p>The Speaker ID is just whatever ID you use to refer to that speaker in your own records. If you’re doing just a one-off analysis of your speech or something, just put your name. If it’s part of a larger project, you can use the unique identifier (UT001-Joey or whatever).</p>
<p>For the Voice Type, this determines a setting in FAVE’s formant extraction. Typically, you’d use the “Low” option for men or taller people, and the “High” option for women and shorter people. But it’s not a precise setting, so if your data comes out looking messier than you expect, try resubmitting it with the other option and see if it works better.</p>
<p>Once you’ve hit “submit” this second time, you’re good to go. You are now free to close that window and you should get an email confirmation saying the process has started. See <a href="#sec-output" class="quarto-xref">Section&nbsp;6</a> for more detail on what you do once DARLA has started processing your files.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Tips for submitting multiple files in a row">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Tips for submitting multiple files in a row
</div>
</div>
<div class="callout-body-container callout-body">
<p>If you plan on submitting multiple files to DARLA simultaneously in multiple tabs, it’s important to note that when you see this “Enter speaker information” part of the screen, the rest of the form resets. So, you won’t see the name of the audio or TextGrid you submitted. This is normally not a problem for the one-off file, but if you’ve got, say, five open DARLA tabs, you might forget which one had which files uploading. There were many times in grad school where I forgot which file was uploaded in that tab, and I ended up writing down the wrong speaker ID and selecting the wrong voice type, which means I had to process it all over again.</p>
<p>My first recommendation is to limit the number of simultaneous uploads to about five otherwise it might cause DARLA to crash for all of them. See <a href="#sec-error_email" class="quarto-xref">Section&nbsp;7.2.2</a>.</p>
<p>My other recommendation is to simply have a piece of paper handy and write down the names of the files you’re processing. Once you’ve submitted the speaker ID and voice type, you can cross off that speaker, close that tab (which moves all other tabs to the left), start a new DARLA tab all the way to the right, and write down that speaker. You then wait for the next one to finish uploading (they may not be ready in the order you submit them because of file size differences) and repeat the process, always carefully noting the order you submit them and crossing things off when you’re done. The highest uncrossed-out name on the paper corresponds to the leftmost DARLA tab. This technique has the added benefit of making it clear what files still need to be processed, reducing the accidental submission of the same file twice.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
</div>
</div>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;I often had to process dozens of files in a single setting, and this technique worked for me. If you ever walked past my desk in grad school, you probably saw tons of little sheets of paper with speaker IDs organized in neat columns with all but the bottom five or so crossed out.</p></div></div></section>
</section>
<section id="sec-output" class="level2" data-number="6">
<h2 data-number="6" class="anchored" data-anchor-id="sec-output"><span class="header-section-number">6</span> DARLA’s output</h2>
<p>If everything goes well, you should get two emails from DARLA. The first comes a few moments after you’ve submitted your files. It is just a confirmation to let you know that the processing has started. The second comes a few minutes later (perhaps up to 20 minutes) and contains five files for you. Let’s look at those individually.</p>
<ul>
<li><p><strong>formants.csv</strong>: this is the whole reason you used DARLA. It contains all the formant measurements for the entire file. Unfortunately, it’s out of the scope of this tutorial to go through that file in depth, but I hope to have a separate tutorial on that soon.</p></li>
<li><p><strong>formants.fornorm.tsv</strong>: this is the same data as in formants.csv, but it’s formatted in a specific way so that it can be read in by an online tool called <a href="http://lingtools.uoregon.edu/norm/">NORM</a>. That site is used for normalizing vowel formant data. If you’re not sure what that means or how to use NORM that’s okay—it’s a bit of an outdated tool nowadays anyway. I usually do nothing with that file.</p></li>
<li><p>some sort of <strong>.TextGrid</strong> file: this is the word- and phoneme-level transcription provided by MFA.</p></li>
<li><p><strong>transcription.txt</strong>: This contains just the text of the transcription file. This is useful in case you want to create a text corpus of your audio files. This file can easily be read into a program like <a href="https://www.laurenceanthony.net/software/antconc/">AntConc</a>.</p></li>
<li><p><strong>plot.pdf</strong>: A basic vowel plot of your data. I have some issues with this plot because it’s often a bit misleading. All vowels are averaged across the entire dataset to get these points, but the problem is it includes things like prerhotic and prenasal allophones which can throw everything off. If you don’t have any other data processing skills, this plot is the best you’ve got. (Stay tuned for an online tool I’ve created to help with creating interactive vowel plots based on DARLA data for people who don’t have coding skills!)</p></li>
</ul>
<p>Once you’ve got those files, you’re good! Save them in a place that makes sense, probably in the same folder with the audio and original transcription or maybe in a separate subfolder called “DARLA.”</p>
</section>
<section id="sec-troubleshooting" class="level2 page-columns page-full" data-number="7">
<h2 data-number="7" class="anchored" data-anchor-id="sec-troubleshooting"><span class="header-section-number">7</span> Troubleshooting</h2>
<p>I have prepared hundreds of files for DARLA, so I’ve seen what works and what doesn’t. In this section, I give some advice to help you prepare your files for DARLA. You should also look at DARLA’s <a href="http://jstanford.host.dartmouth.edu/DARLA_Helpful_Hints_page.html">Helpful Hints page</a> and watch Jim Stanford’s <a href="https://www.youtube.com/watch?v=HK1MVfqemUQ">YouTube video</a> on how to prepare Textgrids.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As of writing in February 2025, this section is very much incomplete. I’ll try to add to it when I can.</p>
</div>
</div>
<section id="sec-preparing_textgrids" class="level3 page-columns page-full" data-number="7.1">
<h3 data-number="7.1" class="anchored" data-anchor-id="sec-preparing_textgrids"><span class="header-section-number">7.1</span> Preparing TextGrids</h3>
<p>Here are a few tips you should keep in mind when preparing your TextGrids to reduce the likelihood of DARLA crashing or otherwise being unable to process your file.</p>
<ul>
<li><p>Make sure the tier you want to be transcribed by DARLA is called “sentence”.</p></li>
<li><p>Don’t use digits in the transcription. So, type “nine” instead of “9”. This applies to dates and years too. For years, this is actually important because DARLA (well, technically MFA) won’t know whether “2017” is “twenty-seventeen” or “two thousand seventeen.” It might be unnatural to type those out, but it makes for a more accurate transcription and it’ll prevent some errors when processing it with DARLA.</p></li>
<li><p>Don’t use curly quotes and apostrophes. To understand what I mean by that, I’ll need to get into some typographical detail, but it’s important. Every time you type the apostrophe or double-quote character, there’s a possibility that it’ll convert into a curly quote character. Here is a straight apostrophe ( <code>'</code> ) and double quote ( <code>"</code> ) and here are curly apostrophes ( ‘ ) or ( ’ ) and curly double quotes ( “ ) and ( ” )<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>. Not all software does this conversion automatically—Praat and ELAN do not—but if you’re copying text over from Microsoft Word or some other program, it’s likely that there are curly quotes in there. You should care about this because <em>DARLA will crash if it encounters a curly quote character</em>! So you’ll need to learn to spot them and change them back to straight quotes before uploading it to DARLA.</p></li>
<li><p>Avoid very short intervals.</p></li>
<li><p>Avoid including sharp intakes of breath in a transcribed interval. DARLA may think it’s an [h] sound which could mess up the rest of that interval. So, even if it’s mid-sentence, end an interval before the breath and start a new one after it. (In general, the way to exclude something from being analyzed in DARLA is to simply put it in an empty interval.)</p></li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;For more information about quotes, see <a href="https://practicaltypography.com/straight-and-curly-quotes.html">Butterick’s Practical Typography</a>.</p></div></div><p>Here is an example of what a TextGrid prepared for DARLA looks like:</p>
<div class="column-screen">
<p><img src="textgrid_example.png" class="img-fluid"></p>
</div>
<p>Here, you can see I have just one tier and it’s called “sentence”. You can add more tiers if you want (and you probably should if you want to transcribe additional people, make a note of extraneous noise, or have other annotations), but DARLA will ignore it. Notice that the number is spelled out. And notice at the very end a loud sound (it was the interviewer saying something like “mm” as some verbal feedback). To have DARLA ignore it, I just left that interval blank.</p>
</section>
<section id="what-to-do-if-darla-crashes" class="level3 page-columns page-full" data-number="7.2">
<h3 data-number="7.2" class="anchored" data-anchor-id="what-to-do-if-darla-crashes"><span class="header-section-number">7.2</span> What to do if DARLA crashes</h3>
<p>If you use DARLA, you will likely experience it crashing. It is, unfortunately, not an uncommon occurrence. In this section I go through some of the error messages you might see and how to maybe fix things so they’ll work with DARLA.</p>
<section id="a-terrifying-error-page" class="level4 page-columns page-full" data-number="7.2.1">
<h4 data-number="7.2.1" class="anchored" data-anchor-id="a-terrifying-error-page"><span class="header-section-number">7.2.1</span> A terrifying error page</h4>
<p>DARLA can crash in a variety of ways. Sometimes it’s a full-screen error page that is terrifying to some people.</p>
<p><img src="error_page.png" class="img-fluid"></p>
<p>In my experience, the most common reason this page shows up is because there’s some sort of special character in the transcription. This may be a curly quote, punctuation mark, or anything that is not normally used in English orthography. To force this page, I actually added an <em>é</em> to an otherwise good transcription.</p>
<p>Fortunately, while this page is scary, DARLA now sends you an email with specifics on where the problem occurred.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> Here’s what my email looked like:</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;I only discovered this today when I purposely triggered that error page! It must be a relatively new feature!</p></div></div><p><img src="nonascii-email.png" class="img-fluid"></p>
<p>Here it gives very specific information about where the error occurred (between 10.7 seconds and 15.84 seconds into the transcription). It then gives the transcription of that interval, with the problematic character replced with “X”. The character’s unicode value is provided (“0xe9”), which you can google to hopefully get an answer about what it is. That information is exactly right: here’s the relevant section of the TextGrid:</p>
<p><img src="nonascii_textgrid.png" class="img-fluid"></p>
<p>As you can see, there’s an <em>é</em> exactly where DARLA said it was! So, if you get an email like this, you can hopefully use it to find where the problem occurred and fix the special character.</p>
</section>
<section id="sec-error_email" class="level4 page-columns page-full" data-number="7.2.2">
<h4 data-number="7.2.2" class="anchored" data-anchor-id="sec-error_email"><span class="header-section-number">7.2.2</span> A generic error email</h4>
<p>Other times you’ll simply get an email saying DARLA failed:</p>
<p><img src="error_email.png" class="img-fluid"></p>
<p>This is, rather unfortunately, not a particularly helpful error message because it doesn’t say at all what the problem might be.</p>
<p>My recommendation is to just try submitting it again, possibly a third time. I have noticed that DARLA crashes if there are too many files in line to be processed at once.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> So if you submit many files all in a row, try spacing them out.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> If you happen to submit around the time other people are doing so, wait a few minutes or maybe try again later.</p>
<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;I’ve made the mistake of having 25 students all try to submit files to DARLA during class. A few lucky ones got their files, but the rest all got error emails. I tell them to just continue trying several times until it goes through and usually everyone eventually is successful. Apparently, getting 25 submissions all at once overwhelms DARLA.</p></div><div id="fn12"><p><sup>12</sup>&nbsp;In grad school, I found that I could submit about four or five files at once without them crashing. As soon as I got the results of one, I would then submit the next one so that I never had too many going at the same time.</p></div></div><p>If that doesn’t work, please visit DARLA’s <a href="http://jstanford.host.dartmouth.edu/DARLA_Helpful_Hints_page.html">Helpful Hints page</a>. It lists may possible reasons why your file isn’t working. Some are just double-checking to make sure things are prepared properly. Other hints involve a bit of work, like the “divide and conquer” solution.</p>
</section>
</section>
</section>
<section id="conclusion" class="level2" data-number="8">
<h2 data-number="8" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">8</span> Conclusion</h2>
<p>As far as where to go from here, well, that’s the next step in sociophonetic data processing! If you want to learn to make your own vowel plots, I have <a href="https://joeystanley.com/blog/making-vowel-plots-in-r-part-1/">a tutorial</a> that walks you through how to do so, and it’s even based on a DARLA-generated spreadsheet! For all other data processing, try to find books, websites, or advisors who can help you go from there.</p>


</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/joeystanley\.com");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>