<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Joey Stanley</title>
<link>https://new.joeystanley.com/blog/index.html</link>
<atom:link href="https://new.joeystanley.com/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.433</generator>
<lastBuildDate>Mon, 25 Sep 2023 04:12:00 GMT</lastBuildDate>
<item>
  <title>Website Version 3</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/website-version-3/index.html</link>
  <description><![CDATA[ 




<p>After exactly seven years with my old website, Iâ€™ve decided to change it to what you are seeing now.</p>
<section id="what-was-wrong-with-the-old-one" class="level2">
<h2 class="anchored" data-anchor-id="what-was-wrong-with-the-old-one">What was wrong with the old one?</h2>
<p>I built my old website in September 2016. I had a research assistantship at the DigiLab at UGA, and Emily McGinn, the supervisor, suggested I find ways to increase my online presence. I learned some <a href="../../blog/making-a-website-is-fun">web design and CSS skills</a> skills and eventually made Version 1 of my website. That version was essentially the same as what I built in the tutorial I followed, so a few months later I rewrote everything from scratch and made Version 2. (Letâ€™s be honest though, itâ€™s still obviously heavily based on the tutorial.) Other than very minor tweaks to a few things, thatâ€™s how my website has been since then.</p>
<p>However, it got a bit unwieldy. The blog was organized just fine, but I also added pages here and there to go along with workshops and other presentations I gave. It got more confusing when I gave the same workshop a second time and had multiple similar pages floating around. Since I didnâ€™t foresee some of these additions, its growth was reminiscent of unplanned suburban sprawl. For examples, sometimes images were just dumped into a folder, others were better organized. Non-blog pages were hidden and were sometimes a top-level page and other times within a dedicated subdirectory. Each individual addition wasnâ€™t a big deal, but once I stepped back and looked at it all, it was a mess.</p>
<p>The format of my tutorials wasnâ€™t consistent either. I have lots of handouts on my website, tucked away here and there. If they were associated with a workshop, they were separate R Markdown files that didnâ€™t fit in with the rest of the site. Some of my earliest ones are PDFs of Word files!If they werenâ€™t associated with a workshop, theyâ€™re regular blog posts. But because the site wasnâ€™t connected to R, I had to do a <em>lot</em> of copying and pasting R Markdown code and careful insertion of images to get those tutorials to look right. In some cases, the extra work made it possible to do things like syntax highlighting in Praat and highlighting specific lines of code. But that was all done by manually inserting HTML tags and updating my CSS.</p>
<p>Also, as careful as I was about my CSS, it wasnâ€™t perfect. I think there were some issues if like a list had only one element, and there were things with hyperlinks. Some one-off portions of blogs or tutorials sometimes didnâ€™t look right. I had a disclaimer at the top of every page, something like, â€œThis website is built from scratch. Pardon the flaws; I am not a web designer.â€ Which was a humble brag if anything. But as the site grew I didnâ€™t want to change the CSS because it might change some blog post from years ago in unexpected ways.</p>
<p>Ultimately, I didnâ€™t mind the mess because itâ€™s what made my site unique. But, what made me finally decide to migrate to Quarto was the underlying architecture. It was built using Jekyll, which involves a programming language called Ruby in some way. After seven years I still have no idea what either of those are. I did this because itâ€™s what the tutorial I followed used. When the site worked, it was great. But sometimes, the Ruby dependencies (called â€œgemsâ€) would update or break or whatever and I had to google around trying to find a fix. I had no idea what I was doing and it led to a lot of frustrated late nights trying to get my website up and running again.</p>
<p>Then Quarto comes along, which makes it easy to make a blog entirely within R Studio. I have been very familiar with the R world for a while. In 2017, I was an early adopter of <a href="https://www.rstudio.com/products/shiny/">Shiny</a> (at least in linguistics, I think), so I was able to integrate all my html, CSS, and R skills into the <a href="http://lap3.libs.uga.edu/u/jstanley/vowelcharts/">Gazetteer of Southern Vowels</a>. In 2020, I also started dabbling with creating my own R Packages and using the amazing <a href="https://pkgdown.r-lib.org">pkgdown</a> to make dedicated websites for them (see <a href="https://joeystanley.github.io/joeyr/">joeyr</a>, <a href="https://github.com/JoeyStanley/futurevisions">futurevisions</a>, <a href="https://joeystanley.github.io/barktools/">barktools</a>, and <a href="https://joeystanley.github.io/joeysvowels/">joeysvowels</a>). Finally, I have a side project that involves collecting and analyzing data about what hymns are sung in LDS congregations, and in 2023 I decided to build the <a href="hymnstats.joeystanley.com">site</a> entirely in Quarto.</p>
<p>So, Iâ€™ve gradually built up to web development in R over the years and Quarto seems like the logical place to migrate to. Plus, it has some features that Iâ€™ve always wanted, like scrolling table of contents and a search feature. After some encouragement from folks on Twitter, I decided itâ€™s time to bite the bullet and go for it.</p>
</section>
<section id="what-does-it-take-to-migrate" class="level2">
<h2 class="anchored" data-anchor-id="what-does-it-take-to-migrate">What does it take to migrate?</h2>
<p>Iâ€™m doing this page by page. Hereâ€™s the order I took:</p>
<ul>
<li>My homepage and any links on it. I didnâ€™t clean up the linked pages, but at least there werenâ€™t any dead links.</li>
<li>My blogs.</li>
</ul>
</section>
<section id="things-that-are-the-same" class="level2">
<h2 class="anchored" data-anchor-id="things-that-are-the-same">Things that are the same</h2>
<p>Iâ€™ve tried to keep as much of the original structure of the site the same as I could. However, as I migrate</p>
</section>
<section id="changes" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="changes">Changes</h2>
<p>Hereâ€™s a list of the changes Iâ€™ve made.</p>
<ul>
<li><p>Each blog is now in its own self-contained folder. The previous structure had all posts in a single folder and all images in another folder. This time, the images associated with a blog post are contained within that folder. So, instead of this:</p>
<pre><code>â”œâ”€â”€ğŸ“blog
|  â”œâ”€â”€ğŸ“„blog post 1.md
|  â”œâ”€â”€ğŸ“„blog post 2.md
â”œâ”€â”€ğŸ“images
|  â”œâ”€â”€ğŸŒ…image1.png
|  â”œâ”€â”€ğŸŒ…image2.png</code></pre>
<p>Itâ€™s now this:</p>
<pre><code>â”œâ”€â”€ğŸ“blog
|  â”œâ”€â”€ğŸ“blog post 1
|  |  â”œâ”€â”€  ğŸ“„index.qmd
|  |  â”œâ”€â”€  ğŸŒ…image1.png
|  â”œâ”€â”€ğŸ“blog post 2
|  |  â”œâ”€â”€  ğŸ“„index.qmd
|  |  â”œâ”€â”€  ğŸŒ…image2.png</code></pre>
<p>It shouldnâ€™t affect any urls to existing blog posts because the url <code>blog/blog post 1</code> in the old format would go to the <code>blog post 1.md</code> file and in the new one itâ€™ll go to the <code>blog post 1</code> directory, whichâ€™ll display <code>index.qmd</code> by default. I was concerned about changing the url because I know some people have cited my turorials in published work and I didnâ€™t want those urls to break. I think thisâ€™ll work <em>and</em> itâ€™ll keep the site better organized.</p></li>
<li><p>Within each post, I need to update the header. I change from â€œtagsâ€ to â€œcategoriesâ€, from â€œredirect_fromâ€ to â€œaliases.â€ I add a date-modified if needed. I remove excerpts because I only used them with my â€œbig-linkâ€ style button. Iâ€™m replacing big-links with a standard callout box. I havenâ€™t figured out if I can do redirects-to, which is a bummer for the GSV.</p></li>
</ul>


<div class="no-row-height column-margin column-container"><span class="">By the way, Iâ€™m stealing this way of visualizing file structure directly from <a href="https://github.com/tjmahr/quarto-blog/blob/main/posts/migrating-from-jekyll-to-quarto/index.qmd">TJ Mahrâ€™s Migrating-to-Quarto page.</a>.</span></div></section>

 ]]></description>
  <category>Meta</category>
  <guid>https://new.joeystanley.com/blog/website-version-3/index.html</guid>
  <pubDate>Mon, 25 Sep 2023 04:12:00 GMT</pubDate>
</item>
<item>
  <title>NWAV50</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/nwav50/index.html</link>
  <description><![CDATA[ 




<p>Today I gave a talk that Betsy Sneller and I have been working on called â€œHow Sample Size Impacts Pillai Scores â€“ and What Sociophoneticians Should Do About Itâ€ at the 50th New Ways of Analyzing Variation conference in San Jose! This is an updateto what we presented at <a href="../../blog/asa2021">ASA2021</a>.</p>
<p>We have three things you can download.</p>
<ol type="1">
<li><p>First is <a href="../../downloads/221014-NWAV50_pillai.pptx">the actual powerpoint file</a>. In the notes of each slide though you can see the actual script I read, so you can read every word that was said during the talk.</p></li>
<li><p>Next, if thatâ€™s too much for you, you can download just <a href="../../downloads/221014-NWAV50_pillai.pdf">a PDF of the talk</a>. In case you want this ligherweight version of the slides.</p></li>
<li><p><del>Finally, here is the current manuscript that is under review with the <em>Journal of the Acoustical Society of America</em>. The final product will likely change somewhat, but most of the information is there.</del> [Edit (December 14, 2022): <a href="../../downloads/221202-Pillai-preprint.pdf">Here</a> is the accepted version.]</p></li>
</ol>
<p>If you need to calculate Pillai scores in R, Iâ€™ve got a two-part tutorial for you (<a href="../../blog/a-tutorial-in-calculating-vowel-overlap">here</a> and <a href="../../blog/vowel-overlap-in-r-advanced-topics">here</a>). I also did a blog post (<a href="../../blog/pillai-scores-dont-change-after-normalization">here</a>) about how Pillai scores donâ€™t seem to change after normalization.</p>



 ]]></description>
  <category>Conferences</category>
  <category>Methods</category>
  <category>Phonetics</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>Simulations</category>
  <category>Statistics</category>
  <category>Vowel Overlap</category>
  <guid>https://new.joeystanley.com/blog/nwav50/index.html</guid>
  <pubDate>Fri, 14 Oct 2022 03:30:00 GMT</pubDate>
</item>
<item>
  <title>ADS and LSA 2022</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/ads-and-lsa-2022/index.html</link>
  <description><![CDATA[ 




<p>Iâ€™m attending the Annual Meeting of the Linguistic Society of America and the American Dialect Society and Iâ€™ve got three presentations to tell you about! Please find links, summaries, and images from these presentations below!</p>
<section id="perspectives-on-georgia-vowels-from-legacy-to-synchrony" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="perspectives-on-georgia-vowels-from-legacy-to-synchrony">Perspectives on Georgia Vowels: From Legacy to Synchrony</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/220106-ADS-Georgia.pdf">here</a>!</p>
</div>
</div>
<div class="page-columns page-full"><p>On Thursday afternoon, Peggy Renwick, Jon Forrest, Lelia Glass, and I kicked off the ADS sessions with our presentation on English in Georgia. The four of us have been collaborating for about a year, pooling together datasets and sharing resources, on a project focusing on English in Georgia. This is our first talk showcasing some of our findings. Our results are largely descriptive at this point. Here are the main plots we used (in a fun dark mode!) split up by generation, gender, and ethnicity:</p><div class="no-row-height column-margin column-container"><span class="">For those of you that were there, this was the one that was horribly Zoombombed!</span></div></div>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-white_older.png" class="img-fluid"></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-white_younger.png" class="img-fluid"></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-black.png" class="img-fluid"></p>
<p>Turns out pretty vowel changes if you give it 100 years. Weâ€™re just excited to see acoustic data from such a large span of time analyzed together.</p>
<p><br></p>
</section>
<section id="homogeneity-and-heterogeneity-in-western-american-english" class="level2">
<h2 class="anchored" data-anchor-id="homogeneity-and-heterogeneity-in-western-american-english">Homogeneity and Heterogeneity in Western American English</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/220107-ADS-MTurk.pdf">here</a>!</p>
</div>
</div>
<p>At the ADS poster session on Friday, I presented a poster with two students, Jessica Shepherd and Auna Nygaard. As a bit of background, in <em>Speech in the Western States: Volume 2</em>, Fridland et al (2012:172) point out that pretty much every study of the front lax vowels in the Western US has been based on independent, isolated studies. Because each research collects and processes data their own way, itâ€™s difficult to disentangle differences that may be due to region and differences that may be due to methodological choices. They say that â€œclearly, collecting the same type of data from all sites would be optimal in allowing us the most reliable cross-region assessment.â€</p>
<p>This project is a direct response to that call. When I was a grad student I recruited people via Amazon Mechanical Turk to a bunch of recordings of people reading sentences and wordlists. In total, 212 people completed the task, scattered all across the Western US. This poster describes the first results from this project. As it turns out, our findings match the Westâ€™s description as exhibiting both â€œhomogeneity and heterogeneityâ€ (Fridland et al.&nbsp;2012:172). We find homogeneity in that most people have the LBMS to some degree and that education level and region werenâ€™t statistically significant predictors. However, thereâ€™s a wide range of variation for the LBMS and <sc>ban</sc>-raising, with younger people and sometimes women appearing to lead both of these sound changes. Here are some sample plots from four representative speakers.</p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-mturk_samples.png" class="img-fluid"></p>
<p>And hereâ€™s an overall look at the vowel space in our dataset, with some additional allophones we donâ€™t analyze here.</p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-mturk_overall.png" class="img-fluid"></p>
<p>We look forward to digging into this dataset a little bit more in the future!</p>
<p><br></p>
</section>
<section id="vowels-can-merge-because-of-changes-in-trajectory-prelaterals-in-rural-utah-english" class="level2">
<h2 class="anchored" data-anchor-id="vowels-can-merge-because-of-changes-in-trajectory-prelaterals-in-rural-utah-english">Vowels can merge because of changes in trajectory: Prelaterals in rural Utah English</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/220107-LSA-Prelaterals.pdf">here</a>!</p>
</div>
</div>
<p>Finally, on Friday afternoon, Lisa Johnson and I talked about vowel trajectories and what they can tell us about vowel merger. We look at prelaterals in rural Utah and find that, on the surface, they look like mergers by approximation. However, when we looked at the trajectories (with the help of some pretty cool animations!), it seems like the lateral gradually increases its influence on the vowel so that the merger happens â€œleftward,â€ from the coda to the onset. In this example, we have <sc>zeal</sc> and <sc>guilt</sc>, representing /il/ (<em>feel</em>, <em>deal</em>, <em>meal</em>) and /Éªl/ (<em>fill</em>, <em>dill</em>, <em>mill</em>), <a href="../../blog/extending-wells-lexical-sets-to-prelateral-vowels">respectively.</a></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_ZEAL-GUILT.gif" class="img-fluid"></p>
<p><br></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_FLAIL-SHELF.gif" class="img-fluid"></p>
<p><br></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_JOLT-MULCH.gif" class="img-fluid"></p>
<p><br></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_WOLF-MULCH.gif" class="img-fluid"></p>
<p>This was a pretty consistent pattern across all the pairs of prelateral vowels we looked at. We suspect that we might find this among other conditioned and vowel shifts, like prevelar raising, the <sc>mary-merry-marry</sc> merger, and post-coronal /u/-fronting. The point is, we think trajectories should be considered more when looking at vowel mergers because even among these supposed monophthongs, trajectories really illuminated how that merger happened.</p>
<p><br></p>


</section>

 ]]></description>
  <category>Animations</category>
  <category>Conferences</category>
  <category>Data Viz</category>
  <category>MTurk</category>
  <category>Phonetics</category>
  <category>Presentations</category>
  <category>R</category>
  <category>Research</category>
  <category>South</category>
  <category>Students</category>
  <category>Utah</category>
  <category>Vowel Overlap</category>
  <category>West</category>
  <guid>https://new.joeystanley.com/blog/ads-and-lsa-2022/index.html</guid>
  <pubDate>Sun, 02 Jan 2022 12:00:00 GMT</pubDate>
</item>
<item>
  <title>ASA181</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/asa181/index.html</link>
  <description><![CDATA[ 




<p>Iâ€™m in Seattle at the 181st Meeting of the Acoustical Society of America right now! This is my first in-person conference since October 2019, so itâ€™s great to be here. I presented two posters today, which you can read about and download below.</p>
<p><br></p>
<section id="beyond-midpoints-vowel-dynamics-of-the-low-back-merger-shift" class="level2">
<h2 class="anchored" data-anchor-id="beyond-midpoints-vowel-dynamics-of-the-low-back-merger-shift">Beyond Midpoints: Vowel Dynamics of the Low-Back-Merger Shift</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211129-ASA2021-trajs.pdf">here</a>!</p>
</div>
</div>
<p>For some reason, I hadnâ€™t yet presented any of my dissertation findings at a conference, not even while I was working on them or writing them up. Anyway, Iâ€™m happy to finally present some of my results at a conference. The purpose of this paper is to describe changes in vowel trajectory that accompany changes in midpoints. The Low-Back-Merger Shift is a now-widespread shift across much of North America. My data from Washington shows it pretty clearly across generations. But when I take a wide-angle lens at the vowel trajectories, I found that there was much more to the story than just a global lowering/centralizing of the front lax vowels.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/asa181/asa2021_trajs.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>There were perhaps three patterns I noticed when I modeled vowel trajectories. First is that the trajectory length was different between them. The low vowel /Ã¦/ was much longer, then /É›/, and then /Éª/. Thereâ€™s also a general U-shaped pattern. Finally, the â€œangleâ€ of this U-shaped was more towards the â€œleftâ€ for /Ã¦/, more towards the right for /Éª/, and in the middle for /É›/. These descriptions are consistent across generations and between the two geneders modeled, so it may say more about American English articulation than anything sociolinguistic.</p>
<p>Perhaps more interestingly though was <em>how</em> these trajectories changedâ€”within the parameters just describedâ€”across generations. Older peopleâ€™s vowels traversed through much more of the F2 space than younger generations did. The result is that the older peopleâ€™s vowels look more like a shallow U-shape while the younger peopleâ€™s is more of V-shape or even a â€œbounceâ€ straight up and down in the F1-F2 vowel space. The fact that this was consistent across all three front lax vowels and between the genders suggests some interesting sociolinguistic change.</p>
<p>At this point, this is largely descriptive work. I donâ€™t know how perceptible these differences are and Iâ€™m not even sure if everything I just described is statistically significant. Itâ€™ll take additional work to confirm both of these. Trajectories are often ignored because theyâ€™re chalked up articulatory causes; are we comfortable saying that trajectories are 100% phonetic and 0% sociolinguistic? (Meanwhile, if I may be a bit snarky, are the arbitrary single-point measurements that are typically analyzed magically sociolinguistically important?) I think people can exploit trajectories for sociolinguistic purposes. I just donâ€™t know how or to what extent yet.</p>
<p><br></p>
</section>
<section id="sample-size-matters-when-calculating-pillai-scores" class="level2">
<h2 class="anchored" data-anchor-id="sample-size-matters-when-calculating-pillai-scores">Sample size matters when calculating Pillai scores</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211129-ASA2021_pillai.pdf">here</a>!</p>
</div>
</div>
<p>Iâ€™m very excited about this Pillai scores paper with a new colleague, <a href="https://betsysneller.github.io">Betsy Sneller</a>! The background for this papers is that a while ago I was analyzing some <em>cot-caught</em> merger data I had collected. I noticed that, without exception, I got higher pillai scores in wordlists than I did in conversational data. I thought I had stumbled upon some interesting style shifting! But it was <em>too</em> clean of a pattern, so I did some digging and found that itâ€™s likely because of the sample size between the two subsets. I had less data from the wordlists than I did from the conversation. I hypothesized then that less data leads to higher Pillai scores.</p>
<section id="methods-and-experiements" class="level3">
<h3 class="anchored" data-anchor-id="methods-and-experiements">Methods and Experiements</h3>
<p>So in this paper, we test this hypothesis specifically by running a bunch of simulations. We started with a single bivariate normal distribution. We then randomly drew 5 numbers from that distribution and called it â€œgroup 1.â€ We then drew another 5 numbers from the <em>exact same distribution</em> and called it â€œgroup 2.â€ The fact that theyâ€™re drawn from the same underlying distribution represents a true underlying vowel merger. We then calculated the Pillai score of those two groups. We repeated with these group sizes 1000 times. Then we drew 6 tokens from each group 100 times and calcualted Pillai scores. Then 7. And all the way up to 100.</p>
<p>As seen in the main figure in the poster (slightly modified below), the results were clear: the larger the sample sizes, the lower the Pillai scores were. In theory, the Pillai scores should all be around zero since theyâ€™re from the same distribution. But with small samples sizes (&lt;10) observations per group, we very often got pretty high Pillai scoresâ€”scores that some researchers have considered to be distinct. It took around 30 observations per group to reliably (meaning 95% of the time) get the Pillai score under the somewhat conservative threshold of 0.1. It took 60 observations per group to get Pillai scores reliably below 0.05. This was concerning to us because few sociophonetic studies have sample sizes that large!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/asa181/asa2021_equal.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We were also concerned about unequal sample sizes betwen groups. So we reran the experiment, except the group sizes werenâ€™t the same size. Each group could be anywhere from 5 to 100 observations, and we ran all 9000 or so combinations. The results were surprising to usâ€”unequal group sizes doesnâ€™t matter at all. The only thing that mattered was the total sample size. You can see this in the figure in the top right of the poster (or below): as you go from bottom-left to top-right, the average log Pillai score<span class="sidenote">We used log(pillai) because it worked better for this visual and for the math.</span> goes from high to low. But the fact that there is no pattern from the top-left to the bottom-right diagonal means that unequal sizes donâ€™t matter.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/asa181/asa2021_unequal.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>In other words, if Group A has 25 observations and Group B has 5, the Pillai score will average around 0.07. Thatâ€™s the same as if you had two groups of 15. If Group A has 25 observations and Group B has 100, the Pillai score will average around 0.01. Thatâ€™s the same as if you had two groups of 62.</p>
</section>
<section id="implications" class="level3">
<h3 class="anchored" data-anchor-id="implications">Implications</h3>
<p>We can think of a <em>lot</em> of implications for these findings. For one, mergers are probably underreported and splits/distinctions are probably overreported. This is because many sociophonetic studies run Pillai scores on somewhat smaller samples.</p>
<p>Because of sample size differences, comparison across studies is difficult. A study that collects lots of data per person will likely report lower Pillai scores than a study that is based on fewer observations per person.</p>
<p>Going back to the main impetus for this paper, comparison <em>within</em> studies is difficult. Since more careful speech styles typically elicit fewer observations, <strong>reading tasks will have higher Pillai scores than conversational data</strong>. To a naive researcher, this will be interpreted as style differences, when it is really just a reflection of the underlying math! This is such an important point and you can count on hearing more from me and Betsy about this in later venues.</p>
<p>Finally, one way to overcome the sample size difference is to look at the <em>p</em>-value that comes out the MANOVA test that the Pillai score came from. These <em>p</em>-values do seem to be reported in more phonetics-oriented papers, but for some reason theyâ€™re not in sociophonetics papers. So rather than us coming up with arbitrary and ad hoc thresholds for what a merged Pillai score should be, letâ€™s us the <em>p</em>-value instead. Not reporting this <em>p</em>-value, to me at least, is kinda like reporting a <em>t</em>-statistic or <em>F</em>-ratio but without the accompanying <em>p</em>-value.</p>
<p>As a final note, and this is more of an after-thought for us, I wonder if it would be more helpful to report log(pillai) rather than raw pillai scores. Since Pillai ranges from 1 (completely distinct) to 0 (complete overlap), log Pillai would range from 0 (completely distinct) to negative infinity (complete overlap). In practical terms, it would mostly be betwen 0 and around â€“4 (the latter corresponding to a raw Pillai score of about 0.01). Weâ€™ll probably talk more about this in other venues so stay tuned for that.</p>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Dissertation</category>
  <category>Methods</category>
  <category>Pacific Northwest</category>
  <category>Phonetics</category>
  <category>Presentations</category>
  <category>R</category>
  <category>Research</category>
  <category>Simulations</category>
  <category>Statistics</category>
  <category>Vowel Overlap</category>
  <guid>https://new.joeystanley.com/blog/asa181/index.html</guid>
  <pubDate>Mon, 29 Nov 2021 06:00:00 GMT</pubDate>
</item>
<item>
  <title>NWAV49</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/nwav49/index.html</link>
  <description><![CDATA[ 




<p>Iâ€™m at New Ways of Analyzing Variation 49 online right now! Other than an quick online satellite session of LabPhon last summer, I havenâ€™t attended a conference since November 2019 when we hosted LCUGA at UGA. Anyway, Iâ€™m excited to be conferencing again and while I miss seeing colleagues in-person, this online format isnâ€™t bad. Anyway, on this page youâ€™ll find links to the slides and YouTube videos of my two talks.</p>
<p><br></p>
<section id="order-of-operations-in-sociophonetic-analysis" class="level2">
<h2 class="anchored" data-anchor-id="order-of-operations-in-sociophonetic-analysis">Order of Operations in Sociophonetic Analysis</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211019-NWAV49_OoO.pdf">here</a>!</p>
</div>
</div>
<p>Iâ€™m very excited and nervous about this Order of Operations one. As it turns out, even if you start with the exact same spreadsheet and use the exact same functions, if you do those function in different orders, itâ€™ll produce different results. Sometimes drastically different results. I did this by processing a spreadsheet 5,040 unique ways and got a whole range of results. To me at least, itâ€™s making me rethink how I process my data and how I can interpret othersâ€™ results when the order isnâ€™t explicitly reported in the methods section of a paper.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/8TEip-Fixyw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="years-of-georgia-english" class="level2">
<h2 class="anchored" data-anchor-id="years-of-georgia-english">100 Years of Georgia English</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211019-NWAV49_Georgia.pdf">here</a>!</p>
</div>
</div>
<p>As a continuation of some work I did as a grad student, <a href="http://faculty.franklin.uga.edu/mrenwick/">Peggy Renwick</a> and I presented our research on Georgia English vowels and how theyâ€™ve changed over 100 years. Basically, all of them have. The Southern Vowel Shift seems to have undergone a rise and fall, perhaps peaking in those born around WWII. Meanwhile, back vowels are fronting. Younger people today have something like the Low-Back-Merger Shift, but flavored with some Southernisms still. Youâ€™ll hear more about this project in later conferences too.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/USF6fspxiGU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p><br></p>


</section>

 ]]></description>
  <category>Conferences</category>
  <category>Methods</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>Simulations</category>
  <category>South</category>
  <guid>https://new.joeystanley.com/blog/nwav49/index.html</guid>
  <pubDate>Mon, 18 Oct 2021 12:00:00 GMT</pubDate>
</item>
<item>
  <title>#365 Papers (Update)</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/365-papers-update/index.html</link>
  <description><![CDATA[ 




<p>At the beginning of 2018, I set the ambitious goal of reading 365 papers during that year. I <a href="https://twitter.com/joey_stan/status/971972160322387968?s=20">tweeted</a> about it and <a href="../../blog/365-papers">blogged</a> about it, but ultimately didnâ€™t achieve my goal. Turns out 365 is a lot. Well, after 1338 days, I can finally say Iâ€™ve ready 365 papers! So hereâ€™s just some visuals to see what kinds of things Iâ€™ve been reading.</p>
<p>What counts as a â€œpaperâ€ and what counts as â€œreadingâ€ it? I didnâ€™t have any hard and fast rules, but these were the guidelines I laid out before starting.</p>
<ul>
<li><p><em>Chapters are okay</em>: I think that in addition to journal articles, chapters from either edited volumes, monographs, or dissertations count as one each.</p></li>
<li><p><em>Notes are required</em>: I like to take a lot of notes while I read things, so Iâ€™ll only count it if I dutifully summarize and take notes as I go along. This means that skimming an article doesnâ€™t count. If Iâ€™ve already read an article but for whatever reason didnâ€™t take notes, Iâ€™ll only count it if I go through it again and take notes.</p></li>
<li><p><em>Conferences donâ€™t count</em>: At least for me, attending a conference and taking notes there doesnâ€™t count, and neither does going through the slides/poster if available. Not that thereâ€™s anything wrong with conferences, but this is #365<em>papers</em> after all.</p></li>
</ul>
<p>In a few cases, I counted full books as a single entry, like if they had short chapters. I think a 3-page chapter of a book shouldnâ€™t count the same as an article in <em>Language</em>, for example. Similarly, a lot of the Masters Theses I read were shorter and about the same as an article reading so those counted as one.</p>
<p>I will say that <em>re-reading</em> something counts a second time if I do it just as thoroughly. Things like textbook chapters from classes Iâ€™m teaching are the main culprit, but itâ€™s nice to revisit things after a few years.</p>
<p>And to be clear, this doesnâ€™t represent <em>all</em> the papers Iâ€™ve ever read. In fact, Iâ€™d say the bulk of reading for my dissertation happened before I started keeping track. Iâ€™ve kept decent notes about what Iâ€™ve read since about 2010, but Iâ€™ll just focus on the most recent 365 for now.</p>
<section id="pace" class="level2">
<h2 class="anchored" data-anchor-id="pace">Pace</h2>
<p>If I wanted to read 365 papers in a year, thatâ€™s obviously one paper a day. What was my actual pace and did it change? The following plot answers this. From left to right are the months of the year. The colored lines go up as I finished a paper that year. In dashed gray lines, I have benchmarks for where the colored lines would be if I had maintained a constant rate.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/pace.jpg" class="img-fluid"></p>
<p>Looks like in 2018 and 2019 (when I was in the throes of dissertation-writing), my pace was usually somewhere around one paper every 4 to 8 days. So about one a week or occasionally two a week, on average. Starting in 2020 and continuing into this year, my pace is quicker and Iâ€™m reading a paper at least every three days on average.</p>
<p>My pace ebbed and flowed within a single year quite a bit and itâ€™s interesting to see the patterns. In August of 2018 for example, I started really hunkering down and writing my dissertation, so thereâ€™s a sudden increase in pace (in the blue line). In early 2019 you can see I read in short bursts (I binge-read several 3rd Wave sociolinguistics papers). In June 2019 I took GIS and Stats courses so that uptick was from those classes. In September I was in a data visualization phase. And it looks like the time between when I submitted my dissertation and when I defended it (in December 2019), I didnâ€™t do much reading at all.</p>
<p>My pace went up quite a bit in 2020 as I was transitioning from dissertation work to teaching. I read some material related to my job talk and was working on submitting my chapter in <em>Speech in the Western States: Volume III</em>. The biggest jump was in March 2020. Yes, thatâ€™s when COVID hit, but I was also fortunate to be hired as an â€œinstructional designerâ€ for BYU so I was prepping a course and doing a <em>lot</em> of reading. Things waned as I moved to Utah but when Fall semester hit, I kept that pretty quick pace up as I was prepping two new courses. This continued into 2021 as I prepped another two new courses. And you can see my recent uptick as I start getting ready to teach again.</p>
</section>
<section id="content" class="level2">
<h2 class="anchored" data-anchor-id="content">Content</h2>
<p>So now that weâ€™ve got the pace covered, letâ€™s look at the content itself.</p>
<section id="years" class="level3">
<h3 class="anchored" data-anchor-id="years">Years</h3>
<p>First, Iâ€™ll show the publication years of the things I read. Note that I do have two colums for â€œno dateâ€ and forthcoming: those are mostly reviews I did or other sneak-peaks at unpublished work.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/years.jpg" class="img-fluid"></p>
<p>Iâ€™m happy to see that a large proportion of what I read was recent, having come out since I started this little project. Looks like half of the papers I read came out in 2008 or later (or rather, within the last 10â€“14 years); a third was 2017 or later (the last 1â€“4 years). I honestly wish I had read even more recent stuff though because I feel a little behind the times. A quarter of what I read was before 1993. Itâ€™s good to read the classics, but I think I need to be staying more up to date though. Something that certainly accounts for this older skew is that I read while walking and the things I read are typically older (Trudgill 1978, Petyt 1980, Preston 1989, etc). Iâ€™m happy I read some older things, but I wish this plot had been more skewed towards the right.</p>
</section>
<section id="topics" class="level3">
<h3 class="anchored" data-anchor-id="topics">Topics</h3>
<p>Next, hereâ€™s a plot of the broad topic the papers fell in. I only gave each paper a single tag, and sometimes the decision to call something sociolinguistics vs dialectology, for example, was somewhat arbitrary. But this should give you a rough idea of what things I read.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/tags.jpg" class="img-fluid"></p>
<p>It should come to no surprise that most of what I read was sociolinguistic in nature, followed closely by dialectology. The socio stuff is relevant to research and teaching and the dialectology stuff is mostly for research. Phonetics and statistics coming next are also exactly what Iâ€™d expect. I wish I had a bit wider range of topics though so that I can be more well-rounded of a linguist.</p>
</section>
<section id="publication-type" class="level3">
<h3 class="anchored" data-anchor-id="publication-type">Publication Type</h3>
<p>Next, hereâ€™s a basic plot on the publication type. Iâ€™ve divided everything into three broad categories: journal articles (which include conference proceedings), monographs, and edited volumes.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/pub_type.jpg" class="img-fluid"></p>
<p>This is where I think I fall short. Iâ€™m happy to see that journal articles were the most common, but I think I should be reading a higher proportion of newer articles than I am. In fact, monographs and edited volumes combined make up 54% of what I read. This may also be because I read as I walk to and from my car and around my building, so I do get more regular book-reading time than sit-and-read-an-article time.</p>
</section>
<section id="publication-venue" class="level3">
<h3 class="anchored" data-anchor-id="publication-venue">Publication Venue</h3>
<p>Finally, the publication venue. Just focusing on the journal articles, hereâ€™s a list of the venues I read from the most. (Iâ€™ve filtered out venues that I only read from once or twice, for space issues).</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/venue.jpg" class="img-fluid"></p>
<p>Based on my research, it should come as no surprise that <em>American Speech</em> and <em>LVC</em> are the top two. I have a print subscription to <em>American Speech</em>, and I had a habit of reading through all the articles while on the bus. My guess is that the <em>PWPL</em> ones are mostly proceedings from NWAV too. <em>JASA</em>, <em>JEngL</em>, and <em>J. Soc.</em> are also not much of a surprise.</p>
<p>However, this plot again highlights what I think are my shortcomings. I feel like I need to be reading more <em>Language in Society</em> and <em>Journal of Sociolinguistics</em>. I also think I need to be reading about languages other than English too. I feel like Iâ€™ve latched on to my venues to my detriment and Iâ€™m missing a lot of interesting work by not expanding my horizons.</p>
</section>
</section>
<section id="outlook" class="level2">
<h2 class="anchored" data-anchor-id="outlook">Outlook</h2>
<p>Iâ€™m glad I did this exercise ad Iâ€™ll certainly continue with it. And looking back at the past 3â…” years has been enlightening to say the least. My goals for the next 365 papers are the following:</p>
<ul>
<li><p>Read a larger proportion of journal articles. Specifically, I want to go from 45% journal articles to 65%.</p></li>
<li><p>Read a larger proportion of newer articles. Specifically, I want over half of what I read to be since 2015 (6â€“9 years old).</p></li>
<li><p>Finish 365 papers sooner. It took 44 months to do this first batch. Since Iâ€™ve been keeping a pretty good pace of a paper every three days, Iâ€™ll aim for 36 months and finish by August 31, 2024.</p></li>
</ul>
<p>I also want to get through my to-read list. I have about 50 papers on it. It is always growing, and as I read more I find more things to read. But my current list has been nagging me so I want to knock out a bunch of those.</p>


</section>

 ]]></description>
  <category>Personal</category>
  <guid>https://new.joeystanley.com/blog/365-papers-update/index.html</guid>
  <pubDate>Tue, 31 Aug 2021 15:03:00 GMT</pubDate>
</item>
<item>
  <title>Kohler Tapes (Update)</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/kohler-tapes-update/index.html</link>
  <description><![CDATA[ 




<p>In <a href="../../blog/kohler-tapes">February</a>, I acquired a goldmine of data that I can use for linguistic analysis. Hereâ€™s an update on that project, now that I have some more solid numbers.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/kohler_tapes2.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">(560 of 751 tapes!)</figcaption>
</figure>
</div>
<section id="cataloguing" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="cataloguing">Cataloguing</h2>
<p>Soon after getting the tapes, I had to organize them in some way. Since I donâ€™t really know what Iâ€™m doing, I reached out to a few people I know who have worked with collections comparable in size to ask for their advice. (I also had to ask some Gen Xers how to handle and store cassette tapes because, well, Iâ€™ve never done that before ğŸ¤·ğŸ»â€â™‚ï¸).</p>
<div class="page-columns page-full"><p>So, over the course of a couple months, I took the tapes home in batches of fifty or so and cataloged them. By this, I mean that I labeled each with a sequential identifier and took photos of all sides of the tape, its case (if it had one), and any other slips of paper it came with.</p><div class="no-row-height column-margin column-container"><span class="">Thanks, Charlie, for that tip!</span></div></div>
<p>While I was there, I wrote down whatever information was written on the outside of the tape. Things like the studentâ€™s name, the intervieweeâ€™s name, the date of the interview, their age, and the relationship between the two people (grandparent, great-grandparent, etc.). It looks like most of the tapes were done between 1986 and 1999. The ones from the 80s werenâ€™t documented as consistently and I think Mr.&nbsp;Kohler caught on to that and asked his students to do a better job because the ones in the 90s were much more well-documented.</p>
<p>There are a couple really fun gems for me as I went through the names. First, I went to Heber in 2018 to collect some audio data myself. I talked to several older people then. As it turns out, some of these tapes contain recorded interviews with some of the people I talked to! Again, itâ€™s a small town, so not a complete surprise, but itâ€™s still pretty cool. Also, my sister-in-law has family from Heber, and sure enough, the collection contains interviews with about 10 of her distant relatives (great-grand-uncle, etc.). Iâ€™m sure Iâ€™ll discover some other gems as I dig deeper into this collection.</p>
</section>
<section id="digitizing" class="level2">
<h2 class="anchored" data-anchor-id="digitizing">Digitizing</h2>
<p>Thanks to a great tip from my colleague Chris Rogers, I found out that the <a href="https://hlr.byu.edu">Humanities Learning Resource Center</a> in my building can digitize tapes. So I dropped everything and talked to them. Not only can they do it, but they said they do it for free! Wow!</p>
<p>So, I dropped off a box of tapes for them and two weeks later the files magically appeared in my Box drive! So I went and collected them, dropped off another several dozen and repeat the process over and over. It was a good morning when I woke up to the notification from Box saying that another 100 files were ready to download.</p>
<p>I want to just pause and do a huge shout-out to the student employees who processed all this audio! They had to hear the whir of the digitizing machine going for 8â€“9 hours days for 86 straight work days. Not to mention get up and flip the tape over or insert a new tape every 30â€“60 minutes, trim the audio, and upload the file. As someone who canâ€™t stand unnecessary white noise or interruptions, that sounds like awful work to me. Iâ€™m sure if I had had to do it myself, itâ€™d take me three or four times as long to get it all done and I wouldnâ€™t be a happy camper.</p>
</section>
<section id="file-structure" class="level2">
<h2 class="anchored" data-anchor-id="file-structure">File Structure</h2>
<p>Something that I havenâ€™t yet figured out though is the best way to store all this. When I worked with the Linguistic Atlas Project, it was simple: one speaker per file. Most interviews were longer and were recorded on multiple reels, so a single speaker may be on as many as ten or so files, but it was otherwise pretty well-organized.</p>
<p>This collection though is a hot mess. Hereâ€™s a list of the kinds of things Iâ€™m working with:</p>
<ul>
<li><p>Many students did the cleanest route and interviewed one person and turned in one tape. Great.</p></li>
<li><p>However, some students went overboard and turned in multiple (as many as five!) tapes for a single interview. I welcome more data, so thatâ€™s not too bad.</p></li>
<li><p>To complicate things, sometimes the same person was interviewed by different students on different years. One person was interviewed six different times!</p></li>
<li><p>Sometimes, if the first interview wasnâ€™t long enough, a student would conduct another interview with a different person. So there are two interviews and two different people on a single tape.</p></li>
<li><p>The messier route was if a student interviewed two grandparents at the same time. So the husband and wife would alternate back and forth. So one interview, but two people. This will be the trickiest to process.</p></li>
<li><p>And, of course, there are a few cases where multiple joint interviews are tagged on to each other, and this collection of interviews was spread across multiple tapes. Ugh.</p></li>
</ul>
<p>Currently, my file structure is one-folder-per-tape, but as I get my hands dirty, Iâ€™m realizing I need to switch to a one-folder-per-person structure.</p>
<p>And of course, all this necessarily will need to come with multiple spreadsheets and some minor databasing to keep track of it all. Currently, Iâ€™ve got a spreadsheet for tapes, a spreadsheet for sides of tapes, and a spreadsheet for individuals. Itâ€™s not as clean as a single spreadsheet but it works.</p>
</section>
<section id="some-numbers" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="some-numbers">Some numbers</h2>
<p>So now that theyâ€™ve all been cataloged and digitized, I can give some more concrete numbers than I did in my previous blog post.</p>
<section id="number-of-tapes-751" class="level3">
<h3 class="anchored" data-anchor-id="number-of-tapes-751">Number of tapes: 751</h3>
<p>My estimate before was 600â€“700, so itâ€™s a little more than I expected (which is great!)</p>
</section>
<section id="hours-of-audio-631" class="level3">
<h3 class="anchored" data-anchor-id="hours-of-audio-631">Hours of audio: 631</h3>
<p>I know that some of that is music (some students taped over mix tapes) so the number may go down as I listen to it all. I anticipated â€œonlyâ€ 467 hours of audio at first, so this is 33% more than what I originally thought.</p>
<p>â–¼ I tried to estimate how much Iâ€™d end up with before they were all done, and it looks like by around 200 tapes or so I had a pretty good idea. The blue line is the predicted number and the black lines are some error. The pink line shows the true total.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/estimated_audio.jpg" class="img-fluid"></p>
</section>
<section id="minutes-per-tape-51.7-on-average." class="level3">
<h3 class="anchored" data-anchor-id="minutes-per-tape-51.7-on-average.">Minutes per tape: 51.7 (on average).</h3>
<p>My estimate in February was 40 minutes, so not only did I end up with more tapes than I expected, but they were 30% longer than I expected. I think the assignment was to have 30 minutes, but I didnâ€™t expect so many students to go that much longer.</p>
<p>â–¼ Hereâ€™s the distribution of how many minutes of audio were on each tape (both sides). Iâ€™m pretty sure the peaks at 30, 65, and 95 or so reflect how much audio a cassette tape can hold.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/audio_per_tape.jpg" class="img-fluid"></p>
</section>
<section id="digitizing-pace-8.46-tapes-a-day-on-average" class="level3">
<h3 class="anchored" data-anchor-id="digitizing-pace-8.46-tapes-a-day-on-average">Digitizing pace: 8.46 tapes a day (on average)</h3>
<p>Since digitization happens in real-time, that means these students had this going for like nine hours a day. It took them 86 work days to do it all.</p>
<p>â–¼ Based on the creation date of the files, hereâ€™s how much work they did per day. They worked Monday through Saturday every week. You can see that after the semester ended in April it was slightly less consistent. Sometimes I wasnâ€™t on campus the day they finished a box so they had to wait a day or two to get the next batch.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/digitization.jpg" class="img-fluid"></p>
</section>
<section id="number-of-people-806" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="number-of-people-806">Number of people: 806</h3>
<p>Thatâ€™s just interviewees. If you add the 667 students, thatâ€™s 1473 total people. My guess is that that number will go down a small amount as I clean up the metadata. Iâ€™ve already had to change â€œMr.&nbsp;Normanâ€ and â€œMrs.&nbsp;Normanâ€ to their full names once I listened to them. Correcting any typos may change the number too if people were interviewed multiple times. I mentioned this in <a href="../../blogs/kohler-tapes">my last blog post</a>, but Heber only had a few thousand people living in it at the time, so this is decent proportion of the total population of Heber. And if you just focus on the age group that this collection represents, that proportion goes up quite a bit!</p>
<p>There are a fair number of common family names like Jones, Smith, Johnson, McDonald, Thompson, Anderson, Davis of course. But there are also a lot of names like Giles, Bethers, Jensen, Web, Allred, Broadhead, Casper, Duke, Probst, and Young, which I presume are local families.</p>
<div class="page-columns page-full"><p>I will say right now that some of the studentsâ€™ speech has some pretty distinctive linguistic features. These would be people born between about 1972 and 1987, or Gen Xers and early Millennials,  who grew up in Heber. Unfortunately, I wonâ€™t have enough data from them to do much of an analysis.</p><div class="no-row-height column-margin column-container"><span class="">Geriatric Millennials?</span></div></div>
</section>
<section id="interview-years-19862001" class="level3">
<h3 class="anchored" data-anchor-id="interview-years-19862001">Interview years: 1986â€“2001</h3>
<p>Thatâ€™s at least based on the 418 tapes where the interview date was written on the outside. Almost all were in April or May of each year. I suppose if I really wanted to I could track down some old yearbooks and find when the students were in 8th grade and get an exact year. I may find this information in the audio, but I havenâ€™t listened to all of them yet. I may also be able to deduce it from peopleâ€™s ages and birth years if they mention them.</p>
<p>â–¼ Notice there are many more in the 90s. I think itâ€™s a sampling bias though. My guess is that later on in the project, the students received more explicit instructions to write that information than the students in the 1980s did.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/interview_years.jpg" class="img-fluid"></p>
</section>
<section id="birth-years-19051953" class="level3">
<h3 class="anchored" data-anchor-id="birth-years-19051953">Birth Years: 1905â€“1953</h3>
<p>Again, thatâ€™s at least based on the 28 tapes Iâ€™ve listened to. This information was not written on the outside of the tape, so I can only get it in the audio itself. If they donâ€™t say it explicitly, I can usually get enough information about the person to look up census records and get a confirmed date.</p>
<p>â–¼ Hereâ€™s the spread of confirmed birth years. Theyâ€™re color-coded by generation cohort in case thatâ€™s meaningful to you. I estimated everyone would be born between 1900 and 1940, so that was pretty close being right.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/birth_years.jpg" class="img-fluid"></p>
</section>
<section id="places-of-birth-mostly-wasatch-county" class="level3">
<h3 class="anchored" data-anchor-id="places-of-birth-mostly-wasatch-county">Places of birth: mostly Wasatch County</h3>
<p>Once again, thatâ€™s based on the 28 tapes so far. Wasatch County includes Heber, Charleston, Daniel, and Walsburg. Keep in mind these interviews took place in Heber, the county seat of Wasatch County.</p>
<p>â–¼ Several other places in Utah are represented so far too. 14 unique cities in just 28 tapes. Only one person so far was born outside of Utah. <img src="https://new.joeystanley.com/blog/kohler-tapes-update/birth_places.jpg" class="img-fluid" style="width:85.0%"></p>
</section>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>I wonâ€™t rehash what I wrote in my earlier blog post, but now that I have some more solid numbers, I can have better estimate for what I need to get this project done.</p>
<p>With 631 hours of audio and a rough estimate of 10 hours of work for every hour of audio, thatâ€™s 6,310 hours of manual labor needed to transcribe this all. Again, thatâ€™s about 35% more than I anticipated in February. At $15 per hour of work, thatâ€™s $94,650 in student wages.</p>
<p>If I can get some more stellar RAs like I had this semester, who worked 10 hours a week, thatâ€™s 631 student-weeks. At 15 weeks a semester, thatâ€™s 42 student-semesters of work. If I want this done in two years, thatâ€™ll take an average of 14 RAs each semester, including summers. Anyone who has worked with transcribers knows that retention is not great, so Iâ€™ll most certainly need more than 14 student helpers and theyâ€™ll most certainly not last two years.</p>
<p>This doesnâ€™t even include my pipe dream of getting some grad student workers to form a core group of researchers. Theyâ€™d help with supervising and training the transcribers, quality control, other aspects of the data processing (force-aligning, formant-extraction, file management), and analysis.</p>
<p>Am I already looking at external grants? Yes, yes I am. And am I already looking at different types of transcription software, methods, speech-to-text programs, and other things to speed this up and/or make it less costly? Yes, yes I am.</p>
</section>
<section id="immediate-plans" class="level2">
<h2 class="anchored" data-anchor-id="immediate-plans">Immediate Plans</h2>
<p>My first task though is to get as many of the gaps in my metadata spreadsheet filled as quickly as possible. I only know the birth years and places for 28 of the 806 people. Iâ€™d like to get a much more complete picture of what this collection is like before I start prioritizing which tapes to transcribe first. Sometimes this information is near the start of the interview but sometimes itâ€™s not. Not quite sure how to get that information without just listening to all of them.</p>
<p>Fortunately, I got a grant from the <a href="https://reddcenter.byu.edu">Redd Center for Western Studies</a> to go towards this project. Itâ€™s about the right amount needed to process enough data for a preliminary linguistic analysis. So I hope to get the ball rolling on some transcriptions and metadata extraction. Stay tuned for the first results at a conference near you!</p>


</section>

 ]]></description>
  <category>Research</category>
  <category>Utah</category>
  <guid>https://new.joeystanley.com/blog/kohler-tapes-update/index.html</guid>
  <pubDate>Wed, 16 Jun 2021 17:24:00 GMT</pubDate>
</item>
<item>
  <title>Kohler Tapes</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/kohler-tapes/index.html</link>
  <description><![CDATA[ 




<p>So, I just acquired a goldmine of data that I can use for linguistic analysis. Sitting in my office are 452 cassette tapes, each containing at least 30 minutes of recorded interviews with an older folks from Heber City, Utah. And thatâ€™s about half of the collection: the other half is with a historian in Midway, Utah. So, Iâ€™m looking at roughly 400â€“500 hours of audio. Not sure how Iâ€™m going to process it all, but I wanted to kick off the beginning of this long-term project with a blog post describing the history of the tapes, why Iâ€™m interested in them, and speculations about the future.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/kohler-tapes/kohler_tapes.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">452 tapes sitting on my shelf!</figcaption>
</figure>
</div>
<section id="background" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I first heard about the tapes a little over three years ago. In January 2018, the LSA annual meeting was in Salt Lake City. Wanting to take advantage of the trip out there, I applied for and received a grant from the University of Georgia to collect audio in Heber City, aiming for multiple generations within a family to track language change over time. I decided on Heber partly because it was a region of Utah that had never been the subject of acoustic (let alone linguistic) analysis, as far as I know. My parents were living there at the time too, so they could hook me up with some potential contacts.</p>
<div class="page-columns page-full"><p>So on the morning of the first day of my fieldwork, the first thing I did was go to the Heber Valley Visitorâ€™s Center as a way to potentially find some contacts. Literally the first person I talked to told me about a man who had a huge collection of tapes. One person led me to another, and I was talking to an elderly man named Norm Kohler in his nursing home.</p><div class="no-row-height column-margin column-container"><span class="">Side note, itâ€™s amazing that I heard about this goldmine <em>literally</em> through the first person I talked to while doing fieldwork? Who knew that thereâ€™d be such an amazing collection of audio sitting in someoneâ€™s basement nearby? In fact, there could be lots of collections like these, just collecting dust in peopleâ€™s basements. All it takes is to find the right person!</span></div></div>
<p>Norm was a beloved middle school teacher in Heber City in the 1980s and 1990s. As a history project, he had each of his students get a cassette tape and interview a grandparent. I donâ€™t know what the interview questions were, but I think they mostly concerned life in Heber Valley. He kept all the tapes his students turned in and, over the course of two decades, he ended up with over 1200 interviews! Norm intended to compile them and put together an oral history of the town, but unfortunately was unable to do so. So, just weeks before I met him, he decided it was best to return the tapes to the family membersâ€™ of his students and the people they interviewed. So he put an ad in the paper and hundreds of people claimed their tapes and were able to hear their ancestorsâ€™ voices, perhaps for the first time.</p>
<p>However, not all the tapes were claimed. I was told a few hundred remained. So, after Norm passed away a few months later, his family held on to them for a while before finally donating them to the Midway Historical Society. (Midway is the town next door to Heber.) Several complications made it difficult for me to get access to the tapes, including outdated contact information on Midwayâ€™s website, the society going on an extended hiatus, me living in Georgia, and then covid. But I did my best to reach out to anyone who might know about where the tapes were being stored.</p>
<p>Finally, on Thursday this week, I was contacted by the historian in custody of the tapes. She asked if I was still interested in them, and I most definitely am! So we had a nice chat about what my goals were for them and what the goals were for the Historical Society, and we think thereâ€™s mutual interest in getting them digitized and transcribed. So, the next day, yesterday, she happened to be in Provo so she dropped off about half of the tapesâ€”452 of them!â€”at my office!</p>
<p>So after three years of following tenuous leads, I finally have the tapes!</p>
</section>
<section id="why-am-i-so-interested" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="why-am-i-so-interested">Why am I so interested?</h2>
<p>I am a linguist, so why should I care about these tapes? Well, the obvious reason is that itâ€™s a <em>lot</em> of audio. For my dissertation I analyzed about 40 hours of interviews and that was already a lot of data. This is at least 10 times the amount of audio. In fact, itâ€™s about the size of the <em>Digital Archive of Southern Speech</em>, a subset of the <em>Linguistic Atlas of the Gulf States</em>, that I spent four years in grad school analyzing. So having access to this much audio is absolutely incredible.</p>
<p>But itâ€™s not just the amount of audio. There are dozens of oral history projects even in Utah. This particular set is attractive for several reasons:</p>
<ol type="1">
<li><p>The nature of the homework assignment ensured good metadata. A few tapes have already been digitized and they all start off introducing the interviewer (the middle-schooler) and the interviewee, with information like the date of interview, their age, and where they grew up.</p></li>
<li><p>Because these were all students in the same smallish town in Utah the sample will be relatively homogeneous geographically. While it doesnâ€™t ensure that the interviewees (the grandparents) were from Heber or Heber Valley generally, my guess is that a significant number of them are.</p></li>
<li><p>Typically, interviews happen with a historian or someone that the interviewer is unfamiliar with. In sociolinguistics, itâ€™s generally accepted that the degree of familiarity with the interviewer can have an influence on a personâ€™s speech. In all cases with these tapes, the interviewer is a teenager and a grandchild of the interviewee. So that lowers the formality of the situation and will likely mean that the intervieweesâ€™ speech will be more casual.</p></li>
<li><p>Heber Valley has been the focus of very little acoustic research. There may be occasional interviews as parts of the Linguistic Atlas Project or the <em>Dictionary of Regional American English</em>, but no study, as far as I know, has focused on Heber. Instead, most research looks at people from Utah Valley and Salt Lake Valley. This collection of interviews will offer a new spot on the map of Utah dialectology and a nice point of comparison between more urban and more rural areas of the state.</p></li>
<li><p>I have virtually no metadata about the interviewees right now, but if their grandchildren were about 14 years old in the 1980s and 1990s, then the speakers in these tapes were born perhaps sometime between 1900 and 1940. There has been some research on the development of Utah English, mostly by David Bowie, but he acknowledges that it was based on public sermons given by upper-class white men. This collection offers a unique look into how other Utahns born around that time talked. And since I have some comparable data from contemporary Heber City residents, I can begin to look at language change in real time.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><span class="">There were about 4500 people living in Heber in the 1980s and 1990s, which means this sample is a significant chunk of the community!</span></div><p>So there are lots of reasons for why Iâ€™m really interested in this collection of tapes. And thatâ€™s on top of the oral history the Midway Historical Society wants to create based on them.</p>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>Luckily, Iâ€™ve had some experience working on a project of this size. For four years at the University of Georgia, I was a part of the team that processed the <a href="http://www.lap.uga.edu/Site/DASS.html"><em>Digital Archive of Southern Speech</em></a>, which is a 367-hour subset of the <em>Linguistic Atlas of the Gulf States</em>. So Iâ€™ve sat in on transcriber training sessions, seen what kinds of obstacles get in the way of processing, managed thousands of files, and analyzed spreadsheets with a couple million acoustic measurements in them. However, that was only as a graduate student. Iâ€™m sure thereâ€™s a lot that goes on behind the scenes as a PI that I didnâ€™t see.</p>
<p><em>Transcribers</em>â€”Some back-of-the-envelope calculations suggest that Iâ€™ll need a sizable grant to get this all processed. Again, I donâ€™t have definite numbers for anything, I know my 452 tapes are a little over half of them, so letâ€™s say there are 700 tapes total. Theyâ€™re all at least 30 minutes long and I know many went longer, so if I average say 40 minutes per tape, thatâ€™s 28,000 minutes or roughly 467 hours. I think the the transcribers for <em>DASS</em> averaged about 13 hours per 50 minutes of audio or so, but this audio is newer and I presume Utah transcribers will be more familiar with Utah speakers I think, so Iâ€™ll estimate 10 hours of work per tape. Thatâ€™s 4670 hours of transcription. At $15 per hour, Iâ€™m looking at about $70,000 in student wages. Obviously, I canâ€™t get that much coin internally so it sounds like this is only going to happen with an external grant.</p>
<p><em>Grad student workers</em>â€”Thatâ€™s of course assuming that the only wages Iâ€™ll need to pay for are transcribers. This might be getting into â€œIf you give a mouse a cookieâ€ territory, but it would be nice to have some grad students helping out with the project. At UGA, we had at least four and as many as six grad students involved in the project at a time. There was a lot of overlap between our duties, but very roughly speaking, one managed the transcribers, one managed the spot-checks, one managed the acoustic analysis, and one did miscellaneous duties. We were all involved in analysis, and a few others popped in for a semester or two to do additional analysis or perform other duties. To lighten my load, it would be handy to have perhaps three grad students manage the transcribers, check their work, and do the acoustic analysis. Iâ€™m fuzzy on what costs are associated with RA-ships at BYU, but I do know itâ€™ll add significantly to the total cost of the project.</p>
<p><em>Time</em>â€”How long will transcriptions take? Iâ€™ve done transcriptions and theyâ€™re soul-sucking work. Even when I was highly motivated to process my own dissertation data, that I collected myself, and under a bit of a time crunch, I could barely put in more than about two hours a day. I surely donâ€™t expect undergraduate transcribers to do more than 10 hours a week. When motivated by money, Iâ€™ve seen some at UGA do more, but those students were exceptional. Iâ€™ll estimate five hours of work per transcriber per week. So under the assumption of 4670 hours of work total, thatâ€™s 934 transcriber-weeks. If a semester is fifteen weeks, thatâ€™s 62 transcriber-semesters. If I set a goal of getting all the work done in two years (six semesters if you include summers), it would take ten or eleven transcribers to do it in two years. Of course, these are all very rough estimates, but managing several tens of thousands of dollars and almost a dozen workers for two years is not something I expected to do right away!</p>
<p><em>Digitizing</em>â€”Regardless of the cost, number of workers, and time involved, the first step of the process will be digitization. Fortunately, it sounds like the Office of Digital Humanities can take care of that for me! Wow! So my short term goal is to get a batchâ€”maybe 30 or 50 tapesâ€”done first. While they work on digitizing the next batch, I can get started on listening to the first few minutes of the completed tapes and extracting whatever metadata I can from them. Eventually, all the tapes will be digitized and I can have a more concrete idea of how much audio (and consequently, people, time, hours, and money) Iâ€™m looking at.</p>
<p><em>Metadata</em>â€”After digitizing all of them, my next step will be to finish collecting the metadata. Itâ€™ll be nice to have a clear picture of birth years, genders, and birthplaces for all 700 or so people. The most likely scenario is that I <em>wonâ€™t</em> get an external grant because theyâ€™re extremely competitive, so Iâ€™ll have to prioritize which ones to transcribe first. The Historical Society would like to start with some of the prominent members of the community and descendants of the townâ€™s founders. Iâ€™d like to find a balance of genders and birth years too, so weâ€™ll probably settle on a subset that satisfies both of our needs. How big? Iâ€™m thinking between 35 and 70 (5% to 10% of the tapes). Thatâ€™s a more reasonably-sized project that I could possibly get funded internally. It could provide me at least a beginning look at the speech community which would help seed an external grant.</p>
<p><em>Follow-up project?</em>â€”In case I just need more data to analyze (ha!) wouldnâ€™t it be cool to track down some of the tapes that were given away? Presumably, if an ad in the paper is what it took for the families to get them, then an ad might be a good place to start to find them. Weâ€™d digitize the tapes right there for people, give them a copy and return the tape to them of course, but then also add that to the collection for the oral history. I think it would be especially cool to interview those people themselves! That way we can get some contemporary data to compare the tapes to, as well as track change within the family. Thatâ€™ll have to wait until I get NSF grant number two!</p>
<p><em>Publications</em>â€”Whatâ€™s the end goal? Well, Iâ€™ll obviously start cranking out some papers as soon as a reasonable amount of data has been processed. There is a <em>lot</em> going on in Utah English. Many of the stereotyped features are dying out, so these people may provide good acoustic data for what would otherwise be hard to study phonetically today. But there are also lots of other features that I believe are recent innovations, so if theyâ€™re infrequent or missing from these speakers, itâ€™ll help establish the timing of when they did develop. Even before I had the tapes, Iâ€™ve been thinking a full analysis of this collection deserves a book-length treatment. It likely wonâ€™t get done before Iâ€™m up for tenure, but maybe itâ€™ll go towards my application for full professor.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The history of the Kohler Tapes is pretty cool, and Iâ€™m lucky to be a part of the creation of an oral history of Heber City. Itâ€™s so satisfying teaming up with a historical society and finding ways to help the community Iâ€™m studying too. Linguistically, theyâ€™re interesting to me for lots of reasons, but I think everyone benefits from seeing these tapes get processed. As far as how Iâ€™m going to go about processing all of them, I really have no idea what Iâ€™m doing so there will be a lot of learning involved. But Iâ€™m excited to be involved and to have a clear research trajectory for the next decade or so!</p>


</section>

 ]]></description>
  <guid>https://new.joeystanley.com/blog/kohler-tapes/index.html</guid>
  <pubDate>Sat, 13 Feb 2021 21:16:00 GMT</pubDate>
</item>
<item>
  <title>10 Years of Linguistics</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/ten-years-of-linguistics/index.html</link>
  <description><![CDATA[ 




<p>On this day, ten years ago, I decided to major in linguistics. Today, Iâ€™m an assistant professor. To celebrate this decade of linguistics, I thought Iâ€™d write a little bit about where I came from and how I came to the decision to go into linguistics.</p>
<section id="music" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="music">Music</h2>
<!--### Middle school and high school band

Growing up, I was a total band geek. I had already been playing piano for a a couple years and was pretty good for my age and I did well at the recorder in 4th and 5th grade music classes. When 6th grade came and it was time to choose my fine arts class, band was the obvious choice over orchestra, choir, or general music. I honestly don't remember my reasoning but I chose to learn the saxophone. 

I excelled in band in middle school. I was playing 8th grade material halfway through 6th grade. In 7th grade I was transferred to a brand new middle school and we were now combined with all the other band instruments (flutes, clarinets, saxophones, trumpets, and a few trombones). We had lots of new shiny instruments and way too many saxophonists, so when the director asked if anyone was willing to learn a new instrument, I jumped at the opportunity and signed up forâ€¦ well, all of them. 

I started off on tuba at my band director's recommendation to fill out the bottom end of the band's sound. I even made regionals on Tuba. I also learned french horn and oboe. I also learned the bass guitar since we had a middle school jazz band but no one to play the bass guitar. It helped too that some of my older siblings were in band but dropped out so I got their old instruments (trombone and flute) and my dad owned a thrift store so I could get a couple others (trumpet, accordion). It got to the point where I could just come into band holding whatever instrument I wanted and my band director wouldn't care. In fact, I had been practicing trumpet for a few days and decided to bring mine to school---the day they did seating tests. How did I do? I got first chair. (This is 7th grade band---it's not like I was amazing or anything.)

My band director this whole time was extremely supportive and saw that I stood out. He took me under his wing and even offered private lessons in his home after school once a week. We'd hang out and eat cereal with his wife and then he'd teach me jazz and stuff. I still like jazz. Thanks, Mr. Marx.

In 8th grade, I got a new band director who didn't approve of me jumping around so much, so I settled on trombone since we didn't have any others. I got first chair in the district band that year too! But when I saw that a piece we were playing had a bassoon part, I asked if I could take one home---less than a week before the concert. So, yes, I played bassoon in a concert after playing it for six days. When it came time to audition for high school band, I really had to settle down, so I auditioned on trombone for marching band and bassoon for concert band. They said that was the strangest combination they had seen. 

High school band was great. Marching band was a lot of fun and I made a lot of friends. I made the district band on trombone and bassoon (I chose bassoon I think) my sophomore year. When the bass trombonist graduated though, I jumped on the opportunity to learn that. So from junior year on, I was a dedicated bass trombone player. Of course when it came time for district band auditions, I had to see how many instruments I could audition on. I don't remember junior year, but my senior year I made it on both trombone and bass trombone (for both jazz and concert bands). I was also an alternate for tuba. (I auditioned for euphonium but didn't get in.)

One new skill that I sort of picked up was arranging music for whatever small ensemble I wanted. Friday mornings they liked having someone from the school sing or play the national anthem, so I arranged a trombone quartet for me and my friends to play. I started doing a couple other brass ensemble pieces too. So by the time I graduated high school I had a small collection of little pieces I had done.


### Music major 

Anyway, so music was my thing. So going into college, I knew that I would be a music major. I got accepted to Brigham Young University, but I was very disappointed that I didn't get accepted into the music school. I auditioned for a performance major, focusing on bass trombone. (In retrospect, I don't think I completed all the application materials.) So I was officially as "pre-music major" which is code for "I still want to do music but I haven't realized I'm not cut out for it." 

My freshman year was great. I met great friends that I'm still in contact with today. I also knocked out all my general education courses in a year, which was nice. I took as many music classes as I could, but it wasn't a lot because most of them are for declared, accepted music majors only. 

At this point, I had had a lot of experience arranging music. I met a lot of other music and pre-music majors my freshman year (they sort of tried to house us all together), so I met a lot of other really good piano players. So, instead of arranging music for brass ensembles, I tried arranging for piano ensembles. Like two people sitting at one piano or four people sitting at two pianos. I typically did movie music, like Star Wars or other John Williams pieces, since BYU's library had a really nice collection of them. My favorites were a 2-piano, 6-player arrangement of a piece from Star Wars ("The Forest Battle") and a 3-piano, 6-player piece from Spiderman (by Danny Elfman). (In fact, now that I'm back at BYU and have access to their library, I've started arranging movie music again---I'm working on Jurassic Park right now.) 

When it came time to audition for the music school again, I auditioned this time to be a "Media Music Major." This was recommended to me by Jeff Shumway, a piano professor in the music faculty who played in an piano quartet. I had always liked movie music anyway and I knew I wasn't cut out for performance. 

Side story. Part of the audition material was an aural skills test. They said the average score for accepted music majors was about 30 questions right out of 64. I was nervous going into it, but was confident I could do well. My score? A 60. I don't know how many people applied to the music school that year (well over a hundred for sure), and I got the second highest score. So even though I knew I wasn't going to make it as a performer, Media Music sounded right. I wanted to be the next John Williams.

Long story short, I got accepted into the music school. Hooray! The problem was I was about to leave on a two-year mission to Brazil. So, I put my acceptance on hold and moved to Brazil to be a full-time missionary. 

-->
<div class="page-columns page-full"><p>Growing up, I was a total band geek. Iâ€™ll spare you the details, but I took piano lessons when I was eight, started saxophone in 6th grade band, hopped around to pretty much all the instruments I could for a few years, and finally settled on bass trombone junior year of high school. I wasnâ€™t bad either: I made the district band most years (on trombone plus a couple other instruments) and even the Missouri All-State band my senior year.</p><div class="no-row-height column-margin column-container"><span class="">If you peek into the code of this webpage on Github, thereâ€™s a 1200-word summary of my band geekiness and musical background.</span></div></div>
<p>When I started my freshman year at BYU, I auditioned to get into the Brass Performance major, but I didnâ€™t get accepted. So I was officially a â€œpre-music majorâ€, or rather, the â€œI-havenâ€™t-realized-Iâ€™m-not-cut-out-for-this-yet major.â€ That gave me a year to knock out most of my general education courses though, which was nice.</p>
<p>I had a fun music hobby though. Iâ€™d find movie scores or other songs from the library and Iâ€™d arrange them for piano ensembles (like a six-person, two-piano arrangement of a piece from Star Wars). I had been doing that since high school, and BYU seems to have a disproportionate number of people who can play piano, so it was a cinch to find a handful of good sight-readers to play with me. So at the recommendation of a music faculty member I met with one time, I auditioned a second time for the music school, but this time it was to be a Media Music Studies major. And I was accepted!</p>
<p>But, I was 19 years old, and the important thing to do was to go on a full-time, two-year mission. So I took time off from school, knowing my spot in the music school would be waiting for me. Iâ€™m so grateful for this break though because without it I would have just barreled through my music major. But the time off gave me the chance to stop and figure out what I was doing with my life.</p>
</section>
<section id="early-signs-that-i-wanted-to-be-a-linguist" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="early-signs-that-i-wanted-to-be-a-linguist">Early signs that I wanted to be a linguist</h2>
<p>Until May 2008, linguistics was not on my radar at all. Like, I didnâ€™t even know what it <em>was</em>. I didnâ€™t even take any foreign language courses in high school.</p>
<p>There were a few signs though. The one I remember most was from when I was in a play my freshman year of high school. I didnâ€™t have a big role, so I had to kill a lot of time in the drama room while the others rehearsed. I was flipping through one of the textbooks and I saw this chart with whatâ€™s called the International Phonetic Alphabet. My brother, who had taken a couple theater classes, had mentioned the IPA to me a few years prior. He described it as basically if you can transcribe it well and read it well, you can use it to, in theory, speak in any accent. I remember thinking it was so cool so I copied down all the symbols from that book. [Edit: I found the paper! Here it is!]</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/ten-years-of-linguistics/highschool_IPA.png" class="img-fluid figure-img" style="width:85.0%"></p>
<figcaption class="figure-caption margin-caption">I copied this IPA guide from a theater book in 2003!</figcaption>
</figure>
</div>
<p>Anyway, it was in May of 2008 that I got the call that Iâ€™d be a missionary in Brazil. Meaning Iâ€™d have to learn Portuguese. Even though I would be spending the first two months of my mission in an intensive language school, I went ahead and tried learning as much as I could beforehand. And it was then that I realized that learning languages was pretty cool! I finally saw the IPA in action, and was able to use it to learn the sounds. But I remember it blew my mind that, for hundreds of millions of people, â€œhouse blueâ€ sounds totally normal and â€œblue houseâ€ sounds totally wrong. Blew. My. Mind.</p>
<p>So even before I had left for my mission, I had already been thinking about linguistics. I had even added to my Facebook profile was that I was considering a minor in linguistics. So, getting called to a foreign mission is what put linguistics on my radar for sure.</p>
</section>
<section id="my-time-in-brazil" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="my-time-in-brazil">My time in Brazil</h2>
<p>So I went to Brazil and served my mission. While I was down there, I <em>really</em> enjoyed learning Portuguese. I practiced vocabulary like crazy and studied as much grammar as I could. Some of the other missionaries joked that if anyone needed to talk to a lawyer about the gospel that they should call Elder Stanley because heâ€™s the only one that could understand him. After a year and a half or so, I could convince people that I was Brazilian (my darker complexion helped there)â€”not a local Brazilian, mind you, but Iâ€™d tell them I was from another part of the country. I would get phone calls from other missionariesâ€”native Portuguese-speaking Brazilians!â€”asking about some nuanced aspect of grammar. It was fun.</p>
<p>You may know that Mormon missionaries have pretty strict rules about what they can and canâ€™t do. At the time, the internet was completely off-limits except to email our parents once a week. Well, I would occasionally sneak on to Wikipedia and look up linguistics pages and print them out and stuff. Of all the ways to rebel, I think looking up IPA symbols was a pretty tame way to do so.</p>
<div class="page-columns page-full"><p>At one point, I was in a city relatively close to Paraguay and would occasionally run into GuaranÃ­ speakers. I wrote to my parents about the language, and my dad sent me a GuaranÃ­ translation of the <em>Book of Mormon</em> and encouraged me to learn as much of the language as I could. I also met someone who had what was basically a â€œTeach Yourself GuaranÃ­â€ textbook (written in Spanish, so I had to quickly learn to read some basic Spanish) so I used that to learn some of the morphology. So in the little free time I had, I spent it trying to learn GuaranÃ­.</p><div class="no-row-height column-margin column-container"><span class="">In retrospect, Iâ€™m not sure if they spoke Paraguayan GuaranÃ­ because they were Brazilians, but I wonder if they spoke some other TupÃ­ language in that part of the country.</span></div></div>
<div class="page-columns page-full"><p>Towards the end of my mission, I served in a college town and my companion and I went to the universityâ€™s bookstore. I bought a Portuguese Phonetics and Phonology textbook and <em>really</em> had fun reading that. I learned about minimal pairs and basic phonological distributions, and I especially enjoyed reading the dialectal variation that it mentioned. During my last month or so, I bought a comprehensive grammar book, one that was written entirely in Portuguese and was meant for Brazilian university students. In fact, my mission president saw me reading it one time and heâ€™s like, â€œElder Stanley, arenâ€™t you going home in like three weeks? Why are you reading that?â€ Why not? It was fascinating!</p><div class="no-row-height column-margin column-container"><span class="">It was ThaÃ¯s CristÃ³foro Silvaâ€™s 2007 textbook, <a href="https://www.editoracontexto.com.br/produto/fonetica-e-fonologia-do-portugues-roteiro-de-estudos-e-guia-de-exercicios-nova/1496828"><em>Fonetica e Fonologia do Portugues</em></a>.</span></div></div>
</section>
<section id="realizing-music-wasnt-for-me" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="realizing-music-wasnt-for-me">Realizing music wasnâ€™t for me</h2>
<section id="octoberdecember-2010" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="octoberdecember-2010">Octoberâ€“December 2010</h3>
<p>I got home from my mission in October so I had a few months before the next semester of school started. My plans hadnâ€™t changed yet: I wanted to be the next John Williams so my mind was set on Media Music Studies. But I knew I also wanted to at least minor in linguistics, if not double-major.</p>
<p>Because I was starting in January, I couldnâ€™t start all the the theory and other core classes with the other first-year students because those were only offered in the fall. So I had to sort of fill my semester with fluff. I was able to sign up for the Songwriting class though, which was kinda like the intro to the Media Music Studies major. And since I had a time slot available, I went ahead and signed up for Intro to Linguistics. I also signed up for Acoustics for Music and Speech, band, a non-audition choir, and private bass trombone lessons. So about as much music as I could do without those core classes.</p>
<div class="page-columns page-full"><p>My family visited Utah soon after I got back so I took the opportunity to meet with a linguistics advisor, just to see what classes theyâ€™d recommend. It was Alan Melby that I met with, and he recommended I minor in Linguistics Computing. I thought that was a pretty good idea, so I went ahead and signed up for an Intro to Linguistic Computing class as well.</p><div class="no-row-height column-margin column-container"><span class="">Now that Iâ€™m on the faculty side of the department, I can see why he pushed the minor: enrollment was low and they were struggling to keep the minor!</span></div></div>
<p>In the meantime, I worked for my dad and spent my free time getting the right equipment and software for my music studies. But I also spent a lot of time studying linguistics. Mostly looking at Wikipedia and other resources online, including lectures that I could listen to while driving. So even though I didnâ€™t know linguistics would eventually be my major (and career), I was already investing a lot of time into learning it and had a decent grasp of a lot of basic topics.</p>
</section>
<section id="wednesday-january-5th-2011" class="level3">
<h3 class="anchored" data-anchor-id="wednesday-january-5th-2011">Wednesday, January 5th, 2011</h3>
<p>First week of classes comes and I walk into my songwriting class full of confidence. This was going to be the first day of the rest of my life[Although, as my brothers point out, this is technically true every day :)]{.aside} That class turned out to be a pivotal moment like I had anticipated, it just wasnâ€™t <em>quite</em> pivotal moment I was expecting.</p>
<p>After going over the syllabus, we learn that the final project was going to be to write and record a pop song. Uh-oh. I donâ€™t listen to pop music. We got a homework assignment that day too: submit the names of three pop artists you think most closely resemble your own style of music. Ummmâ€¦&nbsp;what? I was there to learn to write movie music, not learn about pop singers. I had just barely gotten back to the country, so I literally couldnâ€™t even <em>name</em> three artists on the radio[Iâ€™d struggle with that today, to be fair.]{.aside} Pop music wasnâ€™t my thing. But the assignment had to be pop music.</p>
<p>Funnily enough, my Intro to Linguistics class was right after that. And I freaking loved it. I wrote in my journal that night that I was already considering changing majors. I think I had known for a long timeâ€”<em>really</em> deep downâ€”that I wasnâ€™t cut out for music. This experience in my Songwriting class was just what I needed to come to that realization.</p>
</section>
<section id="thursday-january-6th-2011" class="level3">
<h3 class="anchored" data-anchor-id="thursday-january-6th-2011">Thursday, January 6th, 2011</h3>
<p>The next day, I wrote to my songwriting professor expressing my concern. He said something along the lines of this: â€œToo bad. I accepted you into this major as a favor to a friend. The odds of you making it as a film score composer are basically zero. Either you expand your horizons or youâ€™re not getting anywhere in the music world. Pop music is where the jobs are so if you canâ€™t keep up, youâ€™re in the wrong major.â€</p>
<p>Ouch.</p>
<p>Since middle school, Iâ€™d thought of nothing but music and for two years in Brazil, I eagerly anticipated the day when Iâ€™d finally start my music classes. And literally in the first hour of the first one, I get a slap in the face, a reality check, and a rude awakening to the fact that I was not going to have a career in music. What was my life for then? Was all that music a waste?</p>
</section>
</section>
<section id="switching-to-linguistics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="switching-to-linguistics">Switching to linguistics</h2>
<section id="friday-january-7th-2011" class="level3">
<h3 class="anchored" data-anchor-id="friday-january-7th-2011">Friday, January 7th, 2011</h3>
<p>I spent several hours that evening looking through classes and figuring out what I was going to do. I considered switching to just a general Music major, but now that the rose-colored glasses were off, it occurred to me that the classes that looked the most fun (like orchestration and score analysis) were only possible after three or four long years of coursework that was <em>not</em> very fun-sounding. Iâ€™d have to slog through years of alone time in the practice room and classes I didnâ€™t want to take just to finally get to those fun ones at the very end.</p>
<p>Meanwhile, after taking a closer look at the courses in the linguistics major, I realized that they all sounded really fun! Phonetics? Phonology? Morphology? Sociolinguistics? Language documentation? Sign me up!</p>
</section>
<section id="saturday-january-8th-2011" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="saturday-january-8th-2011">Saturday, January 8th, 2011</h3>
<div class="page-columns page-full"><p>At this point, I was learning towards a double major in (general) music and linguistics, but I was weighing my options. To help me out, I made some charts to see how my semesters would be spent, credit-hour wise. According to my journal, 65% of my time would be spent in music classes. I had already decided my career wouldnâ€™t be in music at that point, so thatâ€™d be a lot of time spent doing something that wasnâ€™t going to lead me anywhere.</p><div class="no-row-height column-margin column-container"><span class="">â€¦and this offers a peek into how my mind works and was a early sign Iâ€™d do a lot of quantitative work</span></div></div>
<p>So at that point, the decision was clear. If all these music classes sounded lame and all the linguistics classes sounded fun, what was stopping me from switching to linguistics?</p>
</section>
<section id="sunday-january-9th-2011" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sunday-january-9th-2011">Sunday, January 9th, 2011</h3>
<p>My parents have always been extremely supportive of everything I do. They were in the loop on all the developments up to that point, but that afternoon, I Skyped with them to hash a few things out. As expected, they were just as shocked as I was that I was considering switching, but still extremely supportive.</p>
<p>I donâ€™t recall exactly how it all went down, but I know that by the end of that conversation with my parents, my mind was made up: I was going to major in linguistics and minor in linguistics computing.</p>
<div class="page-columns page-full"><p>Itâ€™s pretty interesting what my future plans were at that time. I had these grand plans of learning lots of languages (Mandarin, Arabic, and potentially Hebrew), minoring in TESOL, and teaching abroad somewhere. I was already considering a Masterâ€™s program (probably based on conversations with my Intro to Linguistics professor). None of that really panned out, but at that point, a PhD and academia were not in the picture.</p><div class="no-row-height column-margin column-container"><span class="">I did end up taking two semesters of Mandarin the next school year.</span></div></div>
<p>I thought it was interesting that I wrote in my journal how much I was looking forward to the Varieties of English class. When I did finally take it a couple semesters later, I was stoked (and it did not disappoint)! Little did I know Iâ€™d grow up to be a dialectologist and that Iâ€™d be teaching that very course in 10 yearsâ€™ time. In fact, I taught it in the very same classroom where my Intro to Linguistics class was!</p>
<p>So, at 11:00 on Wednesday the 5th, I was still confident that Iâ€™d be a music major. By the evening of Sunday the 9th, I had made up my mind to major in linguistics and was emotionally ready to abandon music studies. It was a tough five days, but thatâ€™s all it took. I donâ€™t regret doing music or being in band or learning trombone at all. I still get opportunities to play piano (Iâ€™m playing church this Sunday) and Iâ€™m still doing arrangements of movie music (Iâ€™m working on Jurassic Park right now). But I am <em>soooo</em> glad I didnâ€™t major in it.</p>
</section>
</section>
<section id="starting-linguistics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="starting-linguistics">Starting linguistics</h2>
<p>I met with a humanities advisor a few days later and showed her my pie charts and she basically said she had nothing to say because itâ€™s clear my mind was made up already. I donâ€™t know when I officially made the switch according to the university systems, but it must not have been much later because soon after that I was calling myself a linguistics major in my journal.</p>
<p>The advisor also recommended I do a study abroad. So the next day, I was looking through potential study abroad programs and found one that went to Ecuador to study Pastaza Kichwa with Dr.&nbsp;Janis Nuckolls. Iâ€™ve told Janis this sense then, but that study abroad was what set me into motion to get a PhD and ultimately go into academia. Being there in the field doing rigorous linguistic documentation was a total <em>blast</em>.</p>
<p>Later, she invited me to join her research team, which ultimately led me to a presentation at SSILA and attending my first LSA conference in Boston in 2013. I attended as many sessions as I could, including many in the American Dialect Society meetings. And thatâ€™s when I caught the bug. I knew then that I had to do my own research go to more conferences. I had already applied to grad schools at that point, but it was that conference that gave me the determination to present at conferences my first year of grad school (and many times since then).</p>
<div class="page-columns page-full"><p>Iâ€™m a little fuzzy on the details about deciding to do a PhD and figuring out what my research focus would be. I know I mentioned to my mission president during my closing interview with him that I was considering a PhD, but it didnâ€™t seem like it was on my radar when I switched to linguistics. I did apply to PhD programs though so it must have been that study abroad that sent me that direction. As far as my research focus, I started off wanted to do language documentation, but at some point I decided on sociolinguistics and, more specifically, dialectology. Iâ€™ll have to continue reading my journal and seeing if I can pinpoint exact dates for those too.</p><div class="no-row-height column-margin column-container"><span class="">I do have specifics about when I decided on my dissertation topic. Maybe Iâ€™ll do a blog post about that.</span></div></div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>So thatâ€™s it. Ten years ago today is when I decided to major in linguistics. After one difficult homework assignment (that I never finished by the way) and a strongly worded reality check from a professor, it took just five days to abandon the previous decadeâ€™s worth of plans to major in music. I look forward to another decade of linguistics and to see where this career will take me!</p>


</section>

 ]]></description>
  <guid>https://new.joeystanley.com/blog/ten-years-of-linguistics/index.html</guid>
  <pubDate>Sat, 09 Jan 2021 07:25:00 GMT</pubDate>
</item>
<item>
  <title>A big list of Mary-merry-marry words</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/mary-merry-marry/index.html</link>
  <description><![CDATA[ 




<p>Most Americans, including me, have this thing called the <em>Mary-merry-marry</em> merger. We pronounce all three wordsâ€”and the vowels in similarly patterning wordsâ€”the same. However, some Americans retain at least a two-way distinction and most, if not all, varieties of English outside of North America distinguish between all three.</p>
<p>As is typical for people with a merger, itâ€™s not easy for me to separate words into their historic distributions. But sometimes I need to for teaching or preparing wordlists. So, as I prepared to cover the merger (or rather, the lack thereof) in my Varieties of English course this semester, I wanted to show the students a list of words that group with <em>Mary</em>, <em>merry</em>, and <em>marry</em>. But I couldnâ€™t find a decent list anywhere. So I asked Twitter and I was pleasantly surprised to get lots of help from my non-merging followers!</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Is there a wordlist somewhere (perhaps an appendix to a paper) with a decent list of MARY, MERRY, and MARRY words? <br><br>(I know the list wouldn't be universal for all non-mergers, but as a MMM-merger myself, I have zero intuition about this stuff.)
</p>
â€” Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/1306359729933832193?ref_src=twsrc%5Etfw">September 16, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Thank you to all those who sent me lists of words that belong to each class! And to those who pointed me to searchable dictionaries that distinguish between the three! I wonâ€™t mention names here, but I hope they are okay with me turning their collective input into a blog post.</p>
<p>So, the purpose of this post is to provide the most comprehensive list I could come up with of <sc>Mary</sc>, <sc>merry</sc>, and <sc>marry</sc> wordsâ€”the list I was hoping to find a few days agoâ€”just in case any other American needs it.</p>
<p>Note: Iâ€™m told that outside the US, there is little variation in which class each word belongs to. However, in areas of North America that do make some distinction, there can be some variability. So I guess take this list with a grain of salt.</p>
<section id="merry" class="level2">
<h2 class="anchored" data-anchor-id="merry"><sc>merry</sc></h2>
<p>The first set, <sc>merry</sc>, is actually the <sc>dress</sc> lexical set. John Wells <a href="http://phonetic-blog.blogspot.com/2009/08/my-colleague-patricia-ashby-consulted.html">points out</a> that <sc>merry</sc> is typically spelled with &lt;e&gt;. It also seems like a lot of French words have this vowel.</p>
<p>Here are some words that were verified by some folks who do not have the merger.</p>
<p style="margin-left:35px; background-color: #BFD5ED; padding:5px; border-radius:7px">
<i>berry</i>, <i>beryl</i>, <i>burial</i>, <i>bur{y|ied}</i>, <i>cherry</i>, <i>derring-do</i>, <i>Derry</i>, <i>error</i>, <i>derriere</i>, <i>ferret</i>, <i>ferrous</i>, <i>ferry</i>, <i>Gerry</i>, <i>inherit(ed)</i>, <i>Jerry</i>, <i>Kerry</i>, <i>merit(s)</i>, <i>Merovingian</i>, <i>Merriam</i>, <i>Merrion</i>, <i>Merrow</i>, <i>merry</i>, <i>Perrier</i>, <i>Perry</i>, <i>perry</i>, <i>seropositive</i>, <i>sherry</i>, <i>skerry</i>, <i>steril{e|ize}</i>, <i>terrier</i>, <i>terribl{e|y}</i>, <i>terror</i>, <i>terrif{y|ied}</i>, <i>Terry</i>, <i>verisimilitude</i>, <i>very</i>, <i>wherry</i> <!--xeriscape, query, care-->
</p>
<p>Hereâ€™s a more complete list from the Britphone dictionary, based on the search pattern â€œËˆÉ› É¹â€ with a few additions from <em>The Routledge Dictionary of Pronunciation for Current English</em>, based on the search pattern â€œÉ›r|â€.</p>
<p style="margin-left:35px; background-color: #BFD5ED; padding:5px; border-radius:7px">
<i>America{s|n|ns}</i>, <i>atmospheric</i>, <i>beret</i>, <i>burial</i>, <i>cerebral</i>, <i>ceremony</i>, <i>chemotherapy</i>, <i>cherish</i>, <i>Cheryl</i>, <i>clerical</i>, <i>Derek</i>, <i>deterren{t|ce}</i>, <i>equerry</i>, <i>Eri{c|k}</i>, <i>Ericsson</i>, <i>experiment(s)</i>, <i>generic</i>, <i>Gerald</i>, <i>Herald</i>, <i>Hereford</i>, <i>Herefordshire</i>, <i>heritage</i>, <i>heroin</i>, <i>heron</i>, <i>inherent</i>, <i>inheritance</i>, <i>Jeremy</i>, <i>knobkerrie</i>, <i>merrily</i>, <i>necessarily</i>, <i>numeric(al)</i>, <i>peril</i>, <i>perish</i>, <i>primarily</i>, <i>prosperity</i>, <i>referral(s)</i>, <i>serif</i>, <i>severity</i>, <i>sheriff</i>, <i>stereo</i>, <i>stereotype</i>, <i>terrace</i>, <i>territor{y|ies}</i>, <i>terrorism</i>, <i>terrorist(s)</i>, <i>therapist</i>, <i>therapy</i>, <i>verif{y|ied}</i>
</p>
</section>
<section id="marry" class="level2">
<h2 class="anchored" data-anchor-id="marry"><sc>marry</sc></h2>
<p>The second of the three, <sc>marry</sc>, is actually the <sc>trap</sc> lexical set. John Wells <a href="http://phonetic-blog.blogspot.com/2010/12/merry-mary-and-hairy-harry.html">points out</a> that the when an <em>a</em> is followed by two <em>r</em>â€™s, itâ€™s a decent indicator of <sc>marry</sc>.</p>
<p>Here are some words that were verified by some folks who do not have the merger.</p>
<p style="margin-left:35px; background-color: #C1EBD1; padding:5px; border-radius:7px">
<i>arable</i>, <i>arid</i>, <i>apparent</i>, <i>Aragon</i>, <i>Areopagus</i>, <i>arid</i>, <i>arrant</i>, <i>arrow</i>, <i>baritone</i>, <i>baron</i>, <i>barren</i>, <i>barricade</i>, <i>barrow</i>, <i>Barry</i>, <i>Caradon</i>, <i>caravan(s)</i>, <i>caret</i>, <i>carob</i>, <i>carol</i>, <i>Carol{e|ine|yn}</i>, <i>carr{y|s|ied|ing|ier}</i>, <i>charabanc</i>, <i>chariot</i>, <i>charity</i>, <i>charitable</i>, <i>Clarence</i>, <i>clarify</i>, <i>clarion</i>, <i>clarity</i>, <i>comparison(s)</i>, <i>circularity</i>, <i>Darrell</i>, <i>Darren</i>, <i>Darrow</i>, <i>Faraday</i>, <i>Farrell</i>, <i>farrier</i>, <i>farrow</i>, <i>Garamond</i>, <i>Gareth</i>, <i>Gary</i>, <i>guarantee</i>, <i>harakiri</i>, <i>harried</i>, <i>harrow</i>, <i>Harry</i>, <i>Iscariot</i>, <i>Jared</i>, <i>larrikin</i>, <i>Karen</i>, <i>Larry</i>, <i>larynx</i>, <i>marabou</i>, <i>Marazion</i>, <i>Marian</i>, <i>Marilyn</i>, <i>Marion</i>, <i>marital</i>, <i>maritime</i>, <i>marronage</i>, <i>marrow</i>, <i>marr{y|ied|s|ing}</i>, <i>narrative</i>, <i>narrow(ly)</i>, <i>para<em>(-</em>bolic<em>, -</em>chute<em>, -</em>graph<em>, -</em>llel<em>, -</em>noid<em>, -</em>normal<em>, -</em>lyze* etc), *parr{y|ied}</i>, <i>parody</i>, <i>parrot</i>, <i>Raritan</i>, <i>saraband</i>, <i>Saracen</i>, <i>scarify</i>, <i>Sharon</i>, <i>taradiddle</i>, <i>tarry</i>, <i>varicose</i>, <i>yarrow</i>, <i>Zara</i>
</p>
<p>And hereâ€™s a longer list from the Britphone dictionary, based on the search pattern â€œËˆÃ¦ É¹â€ with a few additions from <em>The Routledge Dictionary of Pronunciation for Current English</em>, based on the search pattern â€œar|â€.</p>
<p style="margin-left:35px; background-color: #C1EBD1; padding:5px; border-radius:7px">
<i>apparel</i>, <i>Arab</i>, <i>Arabic</i>, <i>barracks</i>, <i>barrel</i>, <i>barrier(s)</i>, <i>caribou</i>, <i>carriage</i>, <i>Carrie</i>, <i>carrier(s)</i>, <i>Carroll</i>, <i>carrot(s)</i>, <i>character{s|ize}</i>, <i>charit{y|ies|able}</i>, <i>comparative(ly)</i>, <i>Daryl</i>, <i>disparage</i>, <i>embarrass{ed|ing|ment}</i>, <i>garage(s)</i>, <i>gharry</i>, <i>glengarry</i>, <i>harass(ment)</i>, <i>Haringey</i>, <i>Harold</i>, <i>Harriet</i>, <i>Harris</i>, <i>Harrison</i>, <i>Harrogate</i>, <i>karri</i>, <i>Larry</i>, <i>marathon</i>, <i>marriage(s)</i>, <i>Marriott</i>, <i>Maryland</i>, <i>Marylebone</i>, <i>miscarriage(s)<em>, </em>paradigm</i>, <i>paradise</i>, <i>paradox</i>, <i>Paraguay</i>, <i>Paris</i>, <i>parish</i>, <i>popularity</i>, <i>similarit{y|ies}</i>, <i>solidarity</i>, <i>tariff</i>, <i>tarot</i>, <i>transparen{t|cy}</i>
</p>
</section>
<section id="mary" class="level2">
<h2 class="anchored" data-anchor-id="mary"><sc>Mary</sc></h2>
<p>Finally, thereâ€™s <sc>mary</sc>, which is actually the <sc>square</sc> lexical set. John Wells <a href="http://phonetic-blog.blogspot.com/2010/12/merry-mary-and-hairy-harry.html">points out</a> that the when an <em>a</em> is followed by just one <em>r</em>, itâ€™s a decent indicator of <sc>mary</sc> (though not always).</p>
<p>Here are some words that were verified by some folks who do not have the merger.</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>Aaron</i>, <i>aerate</i>, <i>aerial</i>, <i>airing</i>, <i>area</i>, <i>baring</i>, <i>bear{ing|er}</i>, <i>Bering</i>, <i>carer(s)</i>, <i>Carey</i>, <i>caring</i>, <i>chairing</i>, <i>Charing</i>, <i>Clary</i>, <i>dare{e|ing}</i>, <i>dairy</i>, <i>fairy</i>, <i>far{e|ing}</i>, <i>flare-up</i>, <i>flaring</i>, <i>glaring</i>, <i>(nom de) guerre</i>, <i>hairy</i>, <i>hare</i>, <i>haring</i>, <i>lair</i>, <i>lairy</i>, <i>mare</i>, <i>Mary</i>, <i>mayoral</i>, <i>Nair</i>, <i>nary</i>, <i>pair(ing)</i>, <i>Pharaoh</i>, <i>precarious</i>, <i>rare</i>, <i>raring</i>, <i>Sara(h)</i>, <i>scar{y|ing}</i>, <i>shar{er|ing}</i>, <i>sparing</i>, <i>squaring</i>, <i>staring</i>, <i>swearing</i>, <i>tear(ing)</i>, <i>Vair</i>, <i>variable(s)</i>, <i>varian{t|ce}</i>, <i>var{y|ying|ied|ies}</i>, <i>wary</i>
</p>
<p>And here are some other ones based on the <a href="https://github.com/JoseLlarena/Britfone">Britphone dictionary</a>, based on the search pattern â€œËˆÉ›É™ É¹â€.</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>aerosol</i>, <i>aerospace</i>, <i>air{y|ing}</i>, <i>apparent(ly)</i>, <i>aquarium</i>, <i>Averham</i>, <i>Barham</i>, <i>Bulgaria(n)</i>, <i>canary</i>, <i>comparing</i>, <i>contrary</i>, <i>eire</i>, <i>Faeroes</i>, <i>hilarious</i>, <i>humanitarian</i>, <i>Hungarian</i>, <i>invariably</i>, <i>librarian</i>, <i>malaria</i>, <i>Ontario</i>, <i>parent{s|ing}</i>, <i>pharaoh(s)</i>, <i>prairie</i>, <i>preparing</i>, <i>secretariat</i>, <i>sierra</i>, <i>variegated</i>, <i>various</i>, <i>vegetarian</i>, <i>wearing</i>, <i>whereabouts</i>
</p>
<section id="word-final-and-pre-consonantal-tokens" class="level3">
<h3 class="anchored" data-anchor-id="word-final-and-pre-consonantal-tokens">Word-final and pre-consonantal tokens</h3>
<p>It occured to me that the search patterns that I used only included words that, in UK English, are pronounced with /É¹/ (i.e.&nbsp;the /É¹/ is intervocalic). So youâ€™ll notice that <em>caring</em> is on the list of <sc>Mary</sc> words but <em>care</em> is not. So I searched for tokens in Britphone with â€œËˆÉ›É™â€ that are <em>not</em> followed by an /É¹/ (so, preconsonantal and word-final) to produce the following list.</p>
<p>This list includes words that I thought were from different lexical sets. For example, <em>care</em> and <em>hair</em> are on this list, which are presumably part of <sc>Mary</sc> since <em>caring</em> and <em>hairy</em> are too, but then the word <em>square</em> is also in this list, which is, by definition, part of <sc>merry</sc>, since <sc>merry</sc> is just <sc>square</sc>. But, when I asked for clarification on Twitter, I was told that these are all <sc>square</sc>â€”and therefore <sc>Mary</sc>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Okay, so what about "pair", "pear", and "pare"? Is that a minimal triplet for the non-MMM-mergers out there? <br><br>Britphone doesn't differentiate the classes word-finally, so "care" and "square" are both ËˆÉ›É™ even though I'm pretty sure they're respectively DRESS and SQAURE. <a href="https://t.co/3esqw2l4FO">https://t.co/3esqw2l4FO</a>
</p>
â€” Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/1308442632306057217?ref_src=twsrc%5Etfw">September 22, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Anyway, so hereâ€™s the fuller list:</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>affair(s)</i>, <i>air</i>, <i>aircraft</i>, <i>airfare</i>, <i>airline(s)</i>, <i>airlines</i>, <i>airplane</i>, <i>airport(s)</i>, <i>airways</i>, <i>aware</i>, <i>awareness</i>, <i>Ayrshire</i>, <i>bare(ly)</i>, <i>bear(s)</i>, <i>beware</i>, <i>Blair</i>, <i>blare</i>, <i>care{s|d}</i>, <i>careful(ly)</i>, <i>chair(s)</i>, <i>Clair(e)</i>, <i>clare</i>, <i>compare(d)</i>, <i>dare</i>, <i>declare(d)</i>, <i>despair</i>, <i>downstairs</i>, <i>fair(ly)</i>, <i>fare(s)</i>, <i>flair</i>, <i>flare</i>, <i>glare</i>, <i>hair{s|ed}ed)</i>, <i>haircut</i>, <i>hairdresser(s)</i>, <i>hare</i>, <i>heir</i>, <i>heirloom</i>, <i>hilaire</i>, <i>impaired</i>, <i>lair</i>, <i>mare</i>, <i>mayor</i>, <i>pair(s)</i>, <i>pare</i>, <i>pear</i>, <i>Pierre</i>, <i>prayer(s)</i>, <i>prepare(d)</i>, <i>questionnaire</i>, <i>rare(ly)</i>, <i>repair(s)</i>, <i>scarce(ly)</i>, <i>scare(d)</i>, <i>share{s|d}</i>, <i>shareholder(s)</i>, <i>shareware</i>, <i>snare</i>, <i>spare</i>, <i>square{s|d}</i>, <i>stair(s)</i>, <i>staircase</i>, <i>stare(d)</i>, <i>swear</i>, <i>tear(s)</i>, <i>their(s)</i>, <i>there</i>, <i>therefore</i>, <i>unaware</i>, <i>unfair</i>, <i>upstairs</i>, <i>ware</i>, <i>warehouse</i>, <i>wear(s)</i>, <i>where</i>, <i>wherewhithal</i>
</p>
</section>
<section id="supplemental-mary-words" class="level3">
<h3 class="anchored" data-anchor-id="supplemental-mary-words">Supplemental <sc>Mary</sc> words</h3>
<p>Finally, when I searched the <em>The Routledge Dictionary of Pronunciation for Current English</em>, I found these 695 words containing the search pattern â€œÉ›:râ€. I didnâ€™t bother incorporating them into the above list because many of them are very infrequent words. But I wanted to include them for the sake of completeness.</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>Aaron</i>, <i>abecedarian</i>, <i>Abertillery</i>, <i>actuarial</i>, <i>actuarially</i>, <i>adversarial</i>, <i>aerial</i>, <i>aerialist</i>, <i>aeriality</i>, <i>aerially</i>, <i>aeriated</i>, <i>aerie</i>, <i>aeriform</i>, <i>aero</i>, <i>aerobatic</i>, <i>aerobe</i>, <i>aerobiologist</i>, <i>aerobiology</i>, <i>aerodrome</i>, <i>aerodynamic</i>, <i>aerodynamically</i>, <i>aerodynamicist</i>, <i>aerodyne</i>, <i>aero-engine</i>, <i>Aeroflot</i>, <i>aerofoil</i>, <i>aerogram</i>, <i>aerogramme</i>, <i>aerolite</i>, <i>aerological</i>, <i>aeromagnetic</i>, <i>aeronaut</i>, <i>aeronautic</i>, <i>aeronautical</i>, <i>aeronautically</i>, <i>aeroplane</i>, <i>aerosol</i>, <i>aerospace</i>, <i>aerostat</i>, <i>aerostatic</i>, <i>aerostatically</i>, <i>aerotow</i>, <i>aerotrain</i>, <i>aery</i>, <i>affair</i>, <i>agrarian</i>, <i>Ahasuerus</i>, <i>airer</i>, <i>airily</i>, <i>airiness</i>, <i>airing</i>, <i>airy</i>, <i>Althusserean</i>, <i>Althusserian</i>, <i>Antares</i>, <i>antimalarial</i>, <i>antiquarian</i>, <i>antiquarianism</i>, <i>antisabbatarian</i>, <i>antitrinitarian</i>, <i>aorist</i>, <i>apiarian</i>, <i>Apollinaris</i>, <i>aquaria</i>, <i>Aquarian</i>, <i>aquarium</i>, <i>Aquarius</i>, <i>araucaria</i>, <i>area</i>, <i>areal</i>, <i>areaway</i>, <i>areometer</i>, <i>Ares</i>, <i>Arian</i>, <i>Arianism</i>, <i>ariel</i>, <i>Aries</i>, <i>Arius</i>, <i>armamentaria</i>, <i>armamentarium</i>, <i>armillaria</i>, <i>aroid</i>, <i>arum</i>, <i>Aryan</i>, <i>authoritarian</i>, <i>authoritarianism</i>, <i>Azeri</i>, <i>Balearic</i>, <i>ballbearing</i>, <i>Ballesteros</i>, <i>barbarian</i>, <i>baric</i>, <i>barite</i>, <i>barium</i>, <i>Bavaria</i>, <i>Bavarian</i>, <i>bearability</i>, <i>bearable</i>, <i>bearably</i>, <i>bearer</i>, <i>bearing</i>, <i>bearish</i>, <i>bearishness</i>, <i>Behrens</i>, <i>Behring</i>, <i>Belisarius</i>, <i>Berengaria</i>, <i>Bering</i>, <i>billionairess</i>, <i>bolero</i>, <i>Buenos Aires</i>, <i>Bulgaria</i>, <i>Bulgarian</i>, <i>burglarious</i>, <i>burglariously</i>, <i>bursarial</i>, <i>caballero</i>, <i>caesarean</i>, <i>caesarian</i>, <i>calcareous</i>, <i>calcareousness</i>, <i>calceolaria</i>, <i>caldaria</i>, <i>caldarium</i>, <i>caldera</i>, <i>Canaries</i>, <i>canary</i>, <i>Cancerian</i>, <i>carabiniere</i>, <i>carabinieri</i>, <i>carer</i>, <i>Carew</i>, <i>Carey</i>, <i>Caria</i>, <i>caries</i>, <i>caring</i>, <i>carious</i>, <i>Carpentaria</i>, <i>Carreras</i>, <i>Cary</i>, <i>cassowary</i>, <i>centenarian</i>, <i>cercaria</i>, <i>cercariae</i>, <i>certiorari</i>, <i>cesarean</i>, <i>cesarian</i>, <i>charily</i>, <i>chariness</i>, <i>Charing Cross</i>, <i>Charon</i>, <i>chary</i>, <i>cheeseparing</i>, <i>childbearing</i>, <i>ciguatera</i>, <i>cineraria</i>, <i>cinerarium</i>, <i>clairaudience</i>, <i>clairaudient</i>, <i>Clara</i>, <i>clary</i>, <i>columbaria</i>, <i>columbarium</i>, <i>commissarial</i>, <i>commissariat</i>, <i>communitarian</i>, <i>condottiere</i>, <i>condottieri</i>, <i>contrarily</i>, <i>contrariness</i>, <i>contrariwise</i>, <i>contrary</i>, <i>cordillera</i>, <i>costmary</i>, <i>covariance</i>, <i>cruzeiro</i>, <i>cupbearer</i>, <i>daguerreotype</i>, <i>daguerrotype</i>, <i>dairy</i>, <i>dairying</i>, <i>dairymaid</i>, <i>dairyman</i>, <i>dairymen</i>, <i>darer</i>, <i>Dari</i>, <i>Darien</i>, <i>daring</i>, <i>daringly</i>, <i>Darius</i>, <i>de-aerate</i>, <i>declarable</i>, <i>declarant</i>, <i>declaredly</i>, <i>declarer</i>, <i>Demerara</i>, <i>denarii</i>, <i>denarius</i>, <i>despairingly</i>, <i>de Valera</i>, <i>dinero</i>, <i>disciplinarian</i>, <i>doctrinairism</i>, <i>doctrinarian</i>, <i>dolphinarium</i>, <i>Dun Laoghaire</i>, <i>egalitarian</i>, <i>egalitarianism</i>, <i>âˆšÃ¢ire</i>, <i>equalitarian</i>, <i>equalitarianism</i>, <i>establishmentarian</i>, <i>establishmentarianism</i>, <i>Europarliamentarian</i>, <i>eyrie</i>, <i>eyry</i>, <i>faerie</i>, <i>Faeroe Islands</i>, <i>Faeroes</i>, <i>Faeroese</i>, <i>faery</i>, <i>fairing</i>, <i>fairish</i>, <i>fairy</i>, <i>fairyland</i>, <i>Fareham</i>, <i>faro</i>, <i>Faro</i>, <i>Faroe</i>, <i>Faroese</i>, <i>filaria</i>, <i>filariae</i>, <i>filarial</i>, <i>filariasis</i>, <i>Fleet Air Arm</i>, <i>forastero</i>, <i>forbearance</i>, <i>forbearingly</i>, <i>frigidaria</i>, <i>frigidarium</i>, <i>fruitarian</i>, <i>fusaria</i>, <i>fusarium</i>, <i>futilitarian</i>, <i>garish</i>, <i>garishly</i>, <i>garishness</i>, <i>gharial</i>, <i>Gibraltarian</i>, <i>glaireous</i>, <i>glairiness</i>, <i>glairy</i>, <i>glaringly</i>, <i>glaringness</i>, <i>glary</i>, <i>glossarial</i>, <i>godparent</i>, <i>grammarian</i>, <i>Gran Canaria</i>, <i>grandparent</i>, <i>gregarious</i>, <i>gregariously</i>, <i>gregariousness</i>, <i>Guarneri</i>, <i>Guarnerius</i>, <i>Guerrero</i>, <i>GutiâˆšÂ©rrez</i>, <i>habanera</i>, <i>hairily</i>, <i>hairiness</i>, <i>hairy</i>, <i>Halmahera</i>, <i>Hanoverian</i>, <i>hardwearing</i>, <i>harem</i>, <i>harum-scarum</i>, <i>heiress</i>, <i>herbaria</i>, <i>herbarium</i>, <i>Herero</i>, <i>Herrera</i>, <i>hilarious</i>, <i>hilariously</i>, <i>hilariousness</i>, <i>honoraria</i>, <i>honorarium</i>, <i>houseparent</i>, <i>humanitarian</i>, <i>humanitarianism</i>, <i>Hungarian</i>, <i>Indo-Aryan</i>, <i>inegalitarian</i>, <i>infralapsarian</i>, <i>insectaria</i>, <i>insectarium</i>, <i>invariability</i>, <i>invariable</i>, <i>invariableness</i>, <i>invariably</i>, <i>invariance</i>, <i>invariant</i>, <i>Inveraray</i>, <i>Karaite</i>, <i>lairage</i>, <i>lairy</i>, <i>lares</i>, <i>latitudinarian</i>, <i>latitudinarianism</i>, <i>Lehrer</i>, <i>leprosaria</i>, <i>leprosarium</i>, <i>libertarian</i>, <i>libertarianism</i>, <i>librarian</i>, <i>librarianship</i>, <i>Lilliburlero</i>, <i>llanero</i>, <i>Lothario</i>, <i>lumpenproletariat</i>, <i>lupus vulgaris</i>, <i>mace-bearer</i>, <i>Mainwaring</i>, <i>majoritarian</i>, <i>malaria</i>, <i>malarial</i>, <i>malarian</i>, <i>malarious</i>, <i>Marian</i>, <i>mariolatry</i>, <i>Mariology</i>, <i>Marist</i>, <i>Mary</i>, <i>Mary Celeste</i>, <i>Maryland</i>, <i>Mary Magdalene</i>, <i>Maryport</i>, <i>Maseru</i>, <i>mayoral</i>, <i>mayoralty</i>, <i>mayoress</i>, <i>miliaria</i>, <i>militaria</i>, <i>millenarian</i>, <i>millenarianism</i>, <i>millenarianist</i>, <i>millionairess</i>, <i>miserere</i>, <i>multifarious</i>, <i>multifariously</i>, <i>multifariousness</i>, <i>multivariate</i>, <i>nareal</i>, <i>nares</i>, <i>narial</i>, <i>nary</i>, <i>necessarian</i>, <i>necessarianism</i>, <i>necessitarian</i>, <i>necessitarianism</i>, <i>nectarean</i>, <i>nectareous</i>, <i>nefarious</i>, <i>nefariously</i>, <i>Nehru</i>, <i>nightmarish</i>, <i>nightmarishness</i>, <i>nonagenarian</i>, <i>notarial</i>, <i>notarially</i>, <i>Nyerere</i>, <i>obituarial</i>, <i>oceanaria</i>, <i>oceanarium</i>, <i>octogenarian</i>, <i>octonarian</i>, <i>octonarii</i>, <i>octonarius</i>, <i>Old Sarum</i>, <i>Oâ€™Meara</i>, <i>omnifarious</i>, <i>Ontario</i>, <i>ovarian</i>, <i>ovariectomy</i>, <i>ovariotomy</i>, <i>pairing</i>, <i>pallbearer</i>, <i>pampero</i>, <i>pareira</i>, <i>parent</i>, <i>parentage</i>, <i>parenthood</i>, <i>parentless</i>, <i>parer</i>, <i>Parian</i>, <i>paring</i>, <i>parliamentarian</i>, <i>Perak</i>, <i>pereira</i>, <i>Pharaoh</i>, <i>Pharaonic</i>, <i>Pharoah</i>, <i>pharos</i>, <i>Pierian</i>, <i>Pinero</i>, <i>planarian</i>, <i>planetaria</i>, <i>planetarium</i>, <i>platitudinarian</i>, <i>plein-airist</i>, <i>potrero</i>, <i>prairie</i>, <i>precarious</i>, <i>precariously</i>, <i>precariousness</i>, <i>predestinarian</i>, <i>prelapsarian</i>, <i>preparedness</i>, <i>preparer</i>, <i>primavera</i>, <i>proletarian</i>, <i>proletarianisation</i>, <i>proletarianise</i>, <i>proletarianism</i>, <i>proletarianization</i>, <i>proletarianize</i>, <i>proletariat</i>, <i>pulmonaria</i>, <i>quadragenarian</i>, <i>quinquagenarian</i>, <i>quodlibetarian</i>, <i>radiolaria</i>, <i>radiolarian</i>, <i>ranchero</i>, <i>rara avis</i>, <i>raree-show</i>, <i>rarefaction</i>, <i>rarefactive</i>, <i>rarefication</i>, <i>rarefy</i>, <i>rarify</i>, <i>raring</i>, <i>rarity</i>, <i>Rarotonga</i>, <i>Rarotongan</i>, <i>Rastafarian</i>, <i>Rastafarianism</i>, <i>repairable</i>, <i>repairer</i>, <i>retiarii</i>, <i>retiarius</i>, <i>riparian</i>, <i>Ripuarian</i>, <i>Rivera</i>, <i>Riviera</i>, <i>Romero</i>, <i>rosaria</i>, <i>rosarian</i>, <i>rosarium</i>, <i>Rotarian</i>, <i>sabbatarian</i>, <i>sabbatarianism</i>, <i>sacramentarian</i>, <i>sacraria</i>, <i>sacrarium</i>, <i>Sagittarian</i>, <i>Sagittarius</i>, <i>salariat</i>, <i>Salieri</i>, <i>Samaria</i>, <i>samarium</i>, <i>sanataria</i>, <i>sanatarium</i>, <i>sanitaria</i>, <i>sanitarian</i>, <i>sanitarium</i>, <i>Sara</i>, <i>Sarah</i>, <i>sarify</i>, <i>Saros</i>, <i>Sarum</i>, <i>Sauveterrian</i>, <i>scarer</i>, <i>scarification</i>, <i>scarificator</i>, <i>scarifier</i>, <i>scarify</i>, <i>scarily</i>, <i>scariness</i>, <i>scarious</i>, <i>scaroid</i>, <i>scarus</i>, <i>scary</i>, <i>scenario</i>, <i>seafarer</i>, <i>seafaring</i>, <i>secretarial</i>, <i>secretariat</i>, <i>sectarian</i>, <i>sectarianise</i>, <i>sectarianism</i>, <i>sectarianize</i>, <i>sederunt</i>, <i>seminarian</i>, <i>senarii</i>, <i>senarius</i>, <i>septenarii</i>, <i>septenarius</i>, <i>septuagenarian</i>, <i>sexagenarian</i>, <i>shareable</i>, <i>share-out</i>, <i>sharer</i>, <i>Sharon</i>, <i>sharon fruit</i>, <i>snarer</i>, <i>solaria</i>, <i>solarium</i>, <i>sombrero</i>, <i>sparer</i>, <i>sparerib</i>, <i>sparing</i>, <i>sparingly</i>, <i>sparingness</i>, <i>square-eyed</i>, <i>squarer</i>, <i>Squarial</i>, <i>squarish</i>, <i>starer</i>, <i>step-parent</i>, <i>Stradivarius</i>, <i>sublapsarian</i>, <i>sub-librarian</i>, <i>sudaria</i>, <i>sudarium</i>, <i>Sumerian</i>, <i>supralapsarian</i>, <i>swearer</i>, <i>swordbearer</i>, <i>talaria</i>, <i>talebearer</i>, <i>talebearing</i>, <i>tearable</i>, <i>tearaway</i>, <i>tearer</i>, <i>tear-off</i>, <i>temerarious</i>, <i>tepidaria</i>, <i>tepidarium</i>, <i>termitaria</i>, <i>termitarium</i>, <i>terraria</i>, <i>terrarium</i>, <i>therabouts</i>, <i>thereabout</i>, <i>thereafter</i>, <i>thereanent</i>, <i>thereat</i>, <i>therein</i>, <i>thereinafter</i>, <i>thereinbefore</i>, <i>thereinto</i>, <i>thereof</i>, <i>thereon</i>, <i>thereout</i>, <i>thereunder</i>, <i>thereunto</i>, <i>thereupon</i>, <i>time-sharing</i>, <i>Tipperary</i>, <i>Tocharian</i>, <i>Tokharian</i>, <i>topiarian</i>, <i>torch-bearer</i>, <i>torero</i>, <i>totalitarian</i>, <i>totalitarianism</i>, <i>tractarian</i>, <i>Tractarian</i>, <i>Tractarianism</i>, <i>transparence</i>, <i>transparency</i>, <i>transparent</i>, <i>transparently</i>, <i>transparentness</i>, <i>Trinitarian</i>, <i>Trinitarianism</i>, <i>Trocadero</i>, <i>turbellarian</i>, <i>ubiquitarian</i>, <i>ubiquitarianism</i>, <i>unbearable</i>, <i>unbearableness</i>, <i>unbearably</i>, <i>unbury</i>, <i>uncaring</i>, <i>uncaringly</i>, <i>uniformitarian</i>, <i>uniformitarianism</i>, <i>Unitarian</i>, <i>Unitarianism</i>, <i>unpreparedly</i>, <i>unpreparedness</i>, <i>unrepairable</i>, <i>unsectarian</i>, <i>unsparing</i>, <i>unsparingly</i>, <i>unsparingness</i>, <i>untearable</i>, <i>unvaried</i>, <i>unvarying</i>, <i>unvaryingly</i>, <i>unvaryingness</i>, <i>unwarily</i>, <i>unwariness</i>, <i>unwary</i>, <i>unwearable</i>, <i>urticaria</i>, <i>utilitarian</i>, <i>utilitarianism</i>, <i>vagarious</i>, <i>Valera</i>, <i>valerian</i>, <i>valetudinarian</i>, <i>valetudinarianism</i>, <i>vaquero</i>, <i>varia</i>, <i>variability</i>, <i>variable</i>, <i>variably</i>, <i>variance</i>, <i>variant</i>, <i>variate</i>, <i>variation</i>, <i>variational</i>, <i>variationally</i>, <i>variationist</i>, <i>varices</i>, <i>varicolored</i>, <i>varicoloured</i>, <i>varied</i>, <i>variedly</i>, <i>variegate</i>, <i>variegation</i>, <i>varifocal</i>, <i>variform</i>, <i>variolate</i>, <i>variole</i>, <i>variolite</i>, <i>variolitic</i>, <i>varioloid</i>, <i>variolous</i>, <i>variometer</i>, <i>variorum</i>, <i>various</i>, <i>variously</i>, <i>variousness</i>, <i>varix</i>, <i>varus</i>, <i>vary</i>, <i>varyingly</i>, <i>vegetarian</i>, <i>vegetarianism</i>, <i>veterinarian</i>, <i>vicarial</i>, <i>vicariate</i>, <i>vicarious</i>, <i>vicariously</i>, <i>vicariousness</i>, <i>vivaria</i>, <i>vivarium</i>, <i>vulgarian</i>, <i>Wareham</i>, <i>Wareing</i>, <i>warily</i>, <i>wariness</i>, <i>Waring</i>, <i>wary</i>, <i>wayfarer</i>, <i>wayfaring</i>, <i>wearability</i>, <i>wearable</i>, <i>wear-and-tear</i>, <i>wearer</i>, <i>wearing</i>, <i>wearingly</i>, <i>welfarism</i>, <i>welfarist</i>, <i>whereabouts</i>, <i>whereabouts</i>, <i>whereâ€™er</i>, <i>whereupon</i>, <i>worksharing</i>
</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>I hope this list is useful to other folks who have the merger but need to distinguish them for whatever reason. Iâ€™m starting to remember which class words belong to a little bit, though this is just learned knowledge rather than intuition. Also, if anyone has different intuitions than what this page shows, please let me know!</p>


</section>

 ]]></description>
  <category>Lexical Sets</category>
  <category>Side Projects</category>
  <category>Teaching</category>
  <guid>https://new.joeystanley.com/blog/mary-merry-marry/index.html</guid>
  <pubDate>Mon, 28 Sep 2020 15:25:00 GMT</pubDate>
</item>
<item>
  <title>I got a job at BYU!</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/I-got-a-job/index.html</link>
  <description><![CDATA[ 




<p>I canâ€™t believe I get to say this, but in June Iâ€™ll start a new job as an Assistant Professor in the Department of Linguistics at Brigham Young University!</p>
<p>First off, I canâ€™t believe my odds. There are so many amazingly talented grad students out there. Seriously. Several times during the past few years, Iâ€™ve seen and met some super accomplished folks, and Iâ€™m shocked theyâ€™re only grad students. Unfortunately, the academic job market is fierce and not all of them go on to get academic jobs. <em>Especially</em> this year. Iâ€™m convinced that once you get to a certain level, it mostly comes down to luck after that. I was dealt good cards this year and thatâ€™s really the only reason I get to write this right now and other people canâ€™t.</p>
<section id="byu-is-going-to-be-awesome" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="byu-is-going-to-be-awesome">BYU is going to be awesome!</h2>
<p>Iâ€™m really excited for BYU for several reasons. First, itâ€™s where I got my undergrad. Iâ€™ll be teaching in the same rooms where I myself learned linguistics. In fact, during my campus visit, my teaching demonstration was in the very room that my Intro to Linguistics course was. Iâ€™ll also be colleagues with my former professors. (Calling them by first name will take some getting used to!) The campus is beautiful and <a href="https://www.google.com/maps/@40.2484442,-111.6505925,3a,75y,76.5h,79.84t/data=!3m8!1e1!3m6!1sAF1QipOBMIwDvScaTBg5Hty8UEr2SXhGIjLXlAjzIMKG!2e10!3e11!6shttps:%2F%2Flh5.googleusercontent.com%2Fp%2FAF1QipOBMIwDvScaTBg5Hty8UEr2SXhGIjLXlAjzIMKG%3Dw203-h100-k-no-pi-0-ya8.229047-ro-0-fo100!7i2508!8i1254">right in the foothills of an enormous mountain</a>. The Humanities building is big and beautiful. Itâ€™ll be great to be there again.</p>
<div class="page-columns page-full"><p>What I didnâ€™t know as a student, but what I can really appreciate now as a future teacher, is the flexibility in teaching that BYU Linguistics offers. Iâ€™m slated to teach sociolinguistics, dialectology, phonetics &amp; phonology, and quantitative methods this year. I donâ€™t know if too many schools could have offered me such a <em>perfect</em> assortment of courses. Plus, theyâ€™ve got several courses on the books that are specifically designed for faculty interests. I probably wonâ€™t be able to teach those for a few years, but if thereâ€™s some cool topic I want to try out, I wonâ€™t need to go through too many hoops in trying it out once.</p><div class="no-row-height column-margin column-container"><span class="">Update: By the end of my third year, I already been able to <a href="../../teaching.html">teach</a> African American English, and team-taught Linguistic Data Analysis and Sociolinguistic Fieldwork!</span></div></div>
<p>In fact, Iâ€™ve already started some work for BYU Linguistics. Iâ€™m helping to prepare some course material to be used online during a study abroad next year. Iâ€™ll also get started a little earlier than normal (end of June) so I can teach a course this summer. Itâ€™s crazy to think that my family and I will be moving in less than three months!</p>
<p>Iâ€™m also excited to begin research in Utah! Iâ€™ve always been interested in dialectology, especially in the American West. How many dialectologists land jobs in the heart of the geographic region that most interests them?? I have so many research questions that have to do with Utah English and Mormon English, not to mention surrounding areas like Wyoming and Idaho. To think that a few years ago I had to get a grant to collect fieldwork in Utahâ€”now all Iâ€™ll need to do is go get groceries! Iâ€™m looking forward to collecting some data as soon as I get there.</p>
</section>
<section id="the-job-hunt" class="level2">
<h2 class="anchored" data-anchor-id="the-job-hunt">The Job Hunt</h2>
<p>I wanted to post this chart summarizing my job hunt over the past two (or three-ish) academic years. I applied to basically everything I could possibly see myself doing. Iâ€™ve heard stories of people applying to over 100 jobs. Well, for a sociolinguist, there really arenâ€™t 100 jobs out thereâ€”this was pretty much all of them.</p>
<p><img src="https://new.joeystanley.com/blog/I-got-a-job/job_hunt.png" class="img-fluid" style="width:85.0%"></p>
<p>Of the 41 jobs I applied for, 26 were tenure-track, six were visiting professor positions, six were post-docs, two were lecturer positions, and one was Alt-Ac. I got 10 Skype interviews, one campus visit, and one offer. It has never crossed my mind to apply for an industry job (heck, I donâ€™t even know <em>how</em> to!), so there arenâ€™t any there. If things hadnâ€™t worked out this year, I would have started down that route. I think finally did get the hang of applying for jobs towards the end, but Iâ€™m just so glad I donâ€™t need to apply for jobs anymore. (Grants though, thatâ€™s a different storyâ€¦)</p>
<p>Again, Iâ€™m aware that I basically won the lottery this year. So many grad students wonâ€™t be able to get academic jobsâ€”especially with COVID-19 destroying the economy right now. I canâ€™t imagine how bummed I would have been if nothing had panned out. And itâ€™s depressing to think that many of my grad student colleagues will have to open that crushing final rejection letter. I express my deepest sympathy for them.</p>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next steps</h2>
<p>Today I submitted the revisions for my dissertation to my advisor, and I anticipate submitting the final version to UGA next week. Iâ€™ve still got some loose ends to tie up with my assistantship with the Linguistic Atlas Project that Iâ€™ll work on this month. After that, itâ€™ll be course prep, house-hunting, and (gulp!) a 28 hour drive to Provo, UT. At least the weather will be nicer there!</p>


</section>

 ]]></description>
  <category>Personal</category>
  <guid>https://new.joeystanley.com/blog/I-got-a-job/index.html</guid>
  <pubDate>Fri, 03 Apr 2020 23:13:00 GMT</pubDate>
</item>
<item>
  <title>Full house at my first LaTeX workshop!</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/full-house-at-my-first-latex-workshop/index.html</link>
  <description><![CDATA[ 




<p>Today I had the opportunity to teach LaTeX for the first time. <a href="https://twitter.com/calebcrumley">Caleb Crumley</a>, an RA for the <a href="https://digi.uga.edu">DigiLab</a> at UGA, has been working on a dissertation template in LaTeX that conforms with UGAâ€™s formatting check. He finished it, and itâ€™s got the stamp of approval from the Graduate School. To advertise the template, Caleb, Jonathan Crum, and I put on a three-part series to introduce the template and teach a little LaTeX as well.</p>
<p>As always, marketing these workshops is tricky and itâ€™s rare to get more than about a dozen attendees. But, with some persistence from the DigiLabâ€™s coordinator, <a href="https://emilymcginn.com">Emily McGinn</a>, the Grad School agreed to advertise a little for us, and sent out the information to the approximately 6000 grad students at UGA!</p>
<p>Within minutes, we had dozens of people registering for the workshop. After day or two, we doubled, and then tripled the registration cap! Sure enough, the DigiLab was fuller than I had ever seen it, and we decided to host repeat sessions of the three workshops as soon as the first cycle is over.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/full-house-at-my-first-latex-workshop/latex_workshop.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Action shot of me showing how to make a bulletted list!</figcaption>
</figure>
</div>
<div class="page-columns page-full"><p>Knowing there would be so many people there, I was a little nervous prepping the workshop because Iâ€™m not as comfortable with LaTeX as I am with R. Iâ€™ve been dabbling with it for a couple year but Iâ€™ve only been using it seriously for about a year.  All things considered, I think it went well, and I enjoyed it a quite a lot.</p><div class="no-row-height column-margin column-container"><span class="">I began using it when I switched my <a href="../../blog/dissertation">dissertation</a> over from Word. It took about 20 hours to do so, but seriously, best decision ever.</span></div></div>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
This'll be my first time teaching LaTeX, but I had a lot of fun putting this workshop together with <a href="https://twitter.com/CalebCrumley?ref_src=twsrc%5Etfw"><span class="citation" data-cites="CalebCrumley">@CalebCrumley</span></a> and Jonathan Crum. The materials for today's workshop can be found at <a href="https://t.co/uyGNAq1EMe">https://t.co/uyGNAq1EMe</a> <a href="https://t.co/uhnz7sptRz">https://t.co/uhnz7sptRz</a>
</p>
â€” Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/1223325382218153984?ref_src=twsrc%5Etfw">January 31, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>You can see more details about the workshop series <a href="../../pages/latex">here</a>, the handout for the workshop <a href="https://github.com/JoeyStanley/LaTeX_workshops">on my github</a>, and the UGA LaTeX dissertation template that Caleb made on the DigiLabâ€™s <a href="https://github.com/DigiUGA/UGA-Dissertation-LaTeX-Template">github</a>.</p>



 ]]></description>
  <category>Github</category>
  <category>LaTeX</category>
  <category>Presentations</category>
  <guid>https://new.joeystanley.com/blog/full-house-at-my-first-latex-workshop/index.html</guid>
  <pubDate>Fri, 31 Jan 2020 20:45:00 GMT</pubDate>
</item>
<item>
  <title>UGA Linguistics Colloquium 2020</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/colloquium-2020/index.html</link>
  <description><![CDATA[ 




<p>For the fourth time in six years, I presented some of my research at the UGA Linguistics Colloquium. I talked about some findings from my <a href="../../blog/dissertation">dissertation</a>, though I focused on just the low vowels <sc>trap</sc>, <sc>lot</sc>, and <sc>thought</sc>.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/200110-colloquium.pdf">here</a></p>
</div>
</div>
<section id="these-are-relatively-old-changes" class="level2">
<h2 class="anchored" data-anchor-id="these-are-relatively-old-changes">These are relatively old changes</h2>
<p>The gist of the talk is that <sc>trap</sc> has been gradually lowering over the course of four generations in Cowlitz County Washington, with men consistently lagging behind the women and with the first half of the trajectory doing most of the lowering. Meanwhile, <sc>lot</sc> and <sc>thought</sc> have been in a near-merged state since at least the 1930s, with no apparent conditioning by sex or generation. Considering that Cowlitz County was settled by English speakers since only the 1850s, these are relatively old changes for this area.</p>
<p>The interesting part is that while the <em>position</em> of <sc>trap</sc> is consistently lower for the women, the <em>shape</em> of the trajectory is the same within a generation. That is, when it comes to the vowelâ€™s dynamics, the men are keeping up with the women. Itâ€™s just that the global position of that vowel is less advanced.</p>
<p>For me, this opens up a lot of questions about vowel trajectories. Iâ€™m curious about what kinds of social conditioning can be found in the <em>trajectory</em> of a vowel, rather than its relative position in the F1-F2 space. In fact, Iâ€™ve got some experimental work in motion to answer just thatâ€¦</p>
</section>
<section id="interpreting-difference-smooths" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="interpreting-difference-smooths">Interpreting Difference Smooths</h2>
<p>One thing I included in this presentation is an animation to help learn how to interpret difference smooths.<span class="sidenote-left">Iâ€™ve been meaning to include this animation in a presentation for a bit now, and with the 40 minute afforded me in this presentation, I finally had the time to do so.</span> Difference smooths are a type of plot that aid in the interpretation of GAMs and you can learn more about them in <a href="http://eprints.whiterose.ac.uk/113858/2/1703_05339v1.pdf">MÃ¡rtin SÃ³skuthyâ€™s tutorial on GAMs</a>. Unfortunately for those of us that fit GAMs to vowel formant data, they look awfully like vowel formant curves, so they can be tricky to interpret. Iâ€™ll probably expand this into a full blog post later on, but for now, hereâ€™s a brief explanation of (my interpretation of) difference smooths.</p>
<p>Letâ€™s say we have some data, a blue curve and a red curve, sampled at 11 time points. Here, these 11 data points are plotted, with lines connecting the dots.</p>
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/raw.jpg" class="img-fluid" style="width:85.0%"></p>
<p>When you fit a generalized additive model to this data, you can get two fit lines (left, below), which is basically a smoothed version of the jagged line above. Itâ€™s as if you had sampled continuously rather than at 11 discrete timepoints. When you plot a difference smooth, you get the plot on the right (below), which is essentially one curve â€œminusâ€ the other curve.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/raw_fit.jpg" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/smooth.jpg" class="img-fluid"></p>
</div>
</div>
</div>
<p>Now, it may not be completely transparent how the difference smooth relates to the two fit lines. So, to help out, the two plots below show the exact same curves, only several vertical lines have been added. On the fit lines, the vertical lines connect the two curves, with the height (and color) of the line representing the distance between them. On the right, the vertical lines connect the difference smooth and a horizontal line. The kicker: the height of the vertical lines in both plots is identical.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/raw_vlines.jpg" class="img-fluid"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/smooth_vlines.jpg" class="img-fluid"></p>
</div>
</div>
</div>
<p>If youâ€™re like me, it still might not be clear how they connect. The following animation may help. It starts with the two curves with the vertical lines between them. Since Iâ€™m getting the <em>difference</em> between the two, Iâ€™m â€œsubtractingâ€ the bottom from the top. This has the effect of flattening out the bottom one to a perfectly straight, horizontal line. In order to keep the vertical lines the same height, the amount of â€œbendâ€ that has to happen to the bottom line has to apply equally to the top line. The result is a new curve called the difference smooth.</p>
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/diff_smooth_anim.gif" class="img-fluid" style="width:85.0%"></p>
<div class="page-columns page-full"><p>Once youâ€™ve grasped that, you can then add some additional information to the plot. Typically, difference smooths come with confidence intervals, which I highlight in gray below. Wherever the confidence interval does <em>not</em> overlap with the horizontal (zero) line, the curves are interpreted as being statistically significantly different from each other.</p><div class="no-row-height column-margin column-container"><span class="">Exactly how these confidence intervals are calculated is something Iâ€™m still learning.</span></div></div>
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/smooth_ci.jpg" class="img-fluid" style="width:85.0%"></p>
<p>In this case, since the original red line is subtracted from the original blue one, with the confidence intervals on this difference smooth, I can say that the blue line is significantly higher than the red for some region.</p>
<div class="page-columns page-full"><p> Finally, the plot below is the version of the difference smooths I use in this presentation, my dissertation, and anywhere else Iâ€™ve needed them so far.</p><div class="no-row-height column-margin column-container"><span class="">There are R packages that can create difference smooths (I think itsadug might be most well-known). Iâ€™m not a huge fan of the aesthetics of that plot, so Iâ€™ve created my own version using the same data, and in ggplot2. Iâ€™d like to release it in a package sometime soon so you can use them too if youâ€™d like.</span></div></div>
<p><img src="https://new.joeystanley.com/blog/colloquium-2020/smooth_full.jpg" class="img-fluid" style="width:85.0%"></p>
<p>Iâ€™ve just added some additional annotation to better highlight the region of statistical significance:</p>
<ul>
<li><p>The center line is blue and slightly thicker in contrast with the gray, thinner lines.</p></li>
<li><p>The horizontal axis is blue in the region of statistical significance.</p></li>
<li><p>At the point where the confidence interval intersects 0 (the horizontal axis), Iâ€™ve added vertical dotted lines.</p></li>
<li><p>Iâ€™ve also added the timepoint where that intersection happens. In this case, the time spans from 0 to 1, so these two lines are statistically significantly different from one another between 0.122s and 0.526s. NOTE: Itâ€™s important that you take these ranges with a grain of salt and perhaps interpret them very broadly rather than paying too much attention to the exact number.</p></li>
</ul>
<p>I just kinda like the look of this style of plot, so thatâ€™s the one Iâ€™ve been using.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Iâ€™ve at least benefited from interpreting difference smooths in this way. Hopefully the attendees of my talk today (and now you!) will have slightly better understanding of them as well.</p>


</section>

 ]]></description>
  <category>Animations</category>
  <category>Dissertation</category>
  <category>Pacific Northwest</category>
  <category>Presentations</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/colloquium-2020/index.html</guid>
  <pubDate>Thu, 09 Jan 2020 11:20:00 GMT</pubDate>
  <media:content url="https://new.joeystanley.com/blog/colloquium-2020/smooth_full.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>LSA and ADS 2020</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/ads-and-lsa-2020/index.html</link>
  <description><![CDATA[ 




<p>For the first time in a few years, I did not attend the ADS/LSA annual meetings. It would have been nice to hang out in New Orleans this weekend. However, my research will still be represented: my colleagues presented some research focusing on Southern American English vowels that Iâ€™ve been a part of this year.</p>
<p><br></p>
<section id="fridays-ads-poster-on-southern-american-english-vowels" class="level2">
<h2 class="anchored" data-anchor-id="fridays-ads-poster-on-southern-american-english-vowels">Fridayâ€™s ADS poster on Southern American English vowels</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/200103-ads2020.pdf">here</a>!</p>
</div>
</div>
<p>Friday morning at the American Dialect Society poster session, Bill Kretzschmar presented some research on behalf of the entire Linguistic Atlas research team at UGA (Peggy Renwick, Katie Kuiper, Lisa Lipani, Mike Olsen, Rachel Olsen, and me). In it he presents findings from our now-complete dataset from the <em>Digital Archive of Southern Speech</em>. With a dataset this size, we can make comparisons to other varieties of American English regarding the distribution of vowels in the F1-F2 space.</p>
</section>
<section id="sundays-lsa-presentation-on-formant-trajectories" class="level2">
<h2 class="anchored" data-anchor-id="sundays-lsa-presentation-on-formant-trajectories">Sundayâ€™s LSA presentation on formant trajectories</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/200105-lsa2020.pdf">here</a>!</p>
</div>
</div>
<p>Sunday, <a href="http://faculty.franklin.uga.edu/mrenwick/">Peggy Renwick</a> presented our research on formant dynamics of back vowels in Southern American English vowels. Focusing on just the White Americans in the <em>Digital Archive of Southern Speech (DASS)</em>, we wanted to see how formant trajectory shapes and their relative positions vary across male and female speakers in different generations. Many of our findings can be summarized in this animation:</p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2020/lsa2020.gif" class="img-fluid"></p>
<p><sc>goose</sc> doesnâ€™t change much, especially for the women, suggesting <sc>goose</sc> fronting is an old shift and was nearing completion by the time our speakers acquired language. Meanwhile <sc>goat</sc> lowers between the Lost and GI generations of women, and then a generation later for the men. <sc>foot</sc> doesnâ€™t change much, suggesting it doesnâ€™t pattern with <sc>goose</sc>-fronting. The low vowels <sc>lot</sc> and <sc>thought</sc> are near each other, but not merged because of their different positions in the F1-F2 space and their different formant shapes.</p>
<p>Something that stands out to me is that each vowelâ€™s trajectory didnâ€™t change all that much over time. This wasnâ€™t a product of how our GAMM was specified: each combination of vowel, sex, and generation was interacted and therefore, fit independently of the other. So the fact that the trajectories show remarkable stability is really interesting to me. So, at least among these DASS speakers, Southern American English vowels appear to shift the nucleus and glide in tandem.</p>


</section>

 ]]></description>
  <category>Animations</category>
  <category>Conferences</category>
  <category>Linguistic Atlas</category>
  <category>Research</category>
  <category>South</category>
  <guid>https://new.joeystanley.com/blog/ads-and-lsa-2020/index.html</guid>
  <pubDate>Thu, 02 Jan 2020 11:20:00 GMT</pubDate>
</item>
<item>
  <title>Dissertation</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/dissertation/index.html</link>
  <description><![CDATA[ 




<p>Iâ€™m happy to report that I successfully defended my dissertation today! The <a href="../../downloads/191209-dissertation_defense.pdf">defense</a> was held in the DigiLab (300 Main Library). The study itself is called â€œVowel Dynamics of the Elsewhere Shift: A sociophonetic analysis of English in Cowlitz County, Washington.â€</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/dissertation/dissertation_defense.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">Me with my committee: Chad Howe, Peggy Renwick, and Bill Kretzschmar (Skyping in).</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>You can download my dissertation <a href="../../downloads/200417-dissertation-revised.pdf">here</a>!</p>
</div>
</div>
<p>The version linked above is a revision that Iâ€™ve made after correcting some small typos. Click <a href="https://search.proquest.com/docview/2412335574/398995AF274140D8PQ/1?accountid=4488">here</a> to view the official, submitted version.</p>



 ]]></description>
  <category>Dissertation</category>
  <category>Pacific Northwest</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/dissertation/index.html</guid>
  <pubDate>Wed, 04 Dec 2019 13:00:00 GMT</pubDate>
</item>
<item>
  <title>Why do people use BAT instead of TRAP?</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/why-do-people-use-bat-instead-of-trap/index.html</link>
  <description><![CDATA[ 




<p>In English sociolinguistics, youâ€™ll often see vowel phonemes represented by a single word in small caps. For example, <sc>trap</sc> represents /Ã¦/. However, in a lot of American dialectology papers, youâ€™ll see authors use the label <sc>bat</sc> instead. In this post, I explain why I think these competing labels are usedâ€¦ and why I prefer <sc>trap</sc> over <sc>bat</sc>.</p>
<p>See also: <a href="../../blog/thoughts-on-allophonic-extensions-to-wells-lexical-sets">â€œThoughts on allophonic extensions to Wellsâ€™ lexical sets.â€</a></p>
<section id="wells-lexical-sets" class="level2">
<h2 class="anchored" data-anchor-id="wells-lexical-sets">Wells Lexical Sets</h2>
<p>As it turns out the <sc>trap</sc> label came first. In fact, <sc>trap</sc> is just one in a set of 24 labels, one for each English vowel. The creator of this lexical set is John C. Wells, who established them in his 1982 three-volume series, <a href="https://www.amazon.com/Accents-English-Introduction-J-Wells/dp/0521297192/"><em>Accents of English</em></a>. In the preface of each volume, Wells explains a notation system that has since been called the â€œWells Lexical Sets.â€ Because it is brief, Iâ€™ll quote it in its entirety (bold and small caps in original):</p>
<blockquote class="blockquote">
<p><strong>Words written in capitals</strong></p>
</blockquote>
<blockquote class="blockquote">
<p>Throughout the work, use is made of the concept of <strong>standard lexical sets</strong>. These enable one to refer concisely to large groups of words which tend to share the same vowel, and to the vowel which they share. They are based on the vowel correspondences which apply between British Received Pronunciation and (a variety of) General American, and make use of <strong>keywords</strong> intended to be unmistakable no matter what accent one says them in. Thus â€˜the <sc>kit</sc> wordsâ€™ refers to â€˜ship, bridge, milkâ€¦â€™; â€˜the <sc>kit</sc> vowelâ€™ refers to the vowel these words have (in most accents, /Éª/); both may just be referred to as <sc>kit</sc>.</p>
</blockquote>
<p>Wells then provides this table:</p>
<table class="table">
<caption>Table 1: Wellsâ€™ original lexical sets. From Wells (1982:xviiiâ€“xix).</caption>
<colgroup>
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 18%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">RP</th>
<th style="text-align: center;">GenAm</th>
<th style="text-align: right;"></th>
<th style="text-align: center;"></th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Éª</td>
<td style="text-align: center;">Éª</td>
<td style="text-align: right;">1.</td>
<td style="text-align: center;"><sc>kit</sc></td>
<td>ship, sick, bridge, milk, myth, busyâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">e</td>
<td style="text-align: center;">É›</td>
<td style="text-align: right;">2.</td>
<td style="text-align: center;"><sc>dress</sc></td>
<td>step, neck, edge, shelf, friend, readyâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Ã¦</td>
<td style="text-align: center;">Ã¦</td>
<td style="text-align: right;">3.</td>
<td style="text-align: center;"><sc>trap</sc></td>
<td>tap, back, badge, scalp, hand, cancelâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">É’</td>
<td style="text-align: center;">É‘</td>
<td style="text-align: right;">4.</td>
<td style="text-align: center;"><sc>lot</sc></td>
<td>stop, sock, dodge, romp, possible, qualityâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ÊŒ</td>
<td style="text-align: center;">ÊŒ</td>
<td style="text-align: right;">5.</td>
<td style="text-align: center;"><sc>strut</sc></td>
<td>cup, suck, budge, pulse, trunk, bloodâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">ÊŠ</td>
<td style="text-align: center;">ÊŠ</td>
<td style="text-align: right;">6.</td>
<td style="text-align: center;"><sc>foot</sc></td>
<td>put, bush, full, good, look, wolfâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">É‘Ë</td>
<td style="text-align: center;">Ã¦</td>
<td style="text-align: right;">7.</td>
<td style="text-align: center;"><sc>bath</sc></td>
<td>staff, brass, ask, dance, sample, calfâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">É’</td>
<td style="text-align: center;">É”</td>
<td style="text-align: right;">8.</td>
<td style="text-align: center;"><sc>cloth</sc></td>
<td>cough, broth, cross, long, Bostonâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ÉœË</td>
<td style="text-align: center;">Éœr</td>
<td style="text-align: right;">9.</td>
<td style="text-align: center;"><sc>nurse</sc></td>
<td>hurt, lurk, urge, burst, jerk, termâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">iË</td>
<td style="text-align: center;">u</td>
<td style="text-align: right;">10.</td>
<td style="text-align: center;"><sc>fleece</sc></td>
<td>creep, speak, leave, feel, key, peopleâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">eÉª</td>
<td style="text-align: center;">eÉª</td>
<td style="text-align: right;">11.</td>
<td style="text-align: center;"><sc>face</sc></td>
<td>tape, cake, raid, veil, steak, dayâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">É‘Ë</td>
<td style="text-align: center;">É‘</td>
<td style="text-align: right;">12.</td>
<td style="text-align: center;"><sc>palm</sc></td>
<td>psalm, father, bra, spa, lagerâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">É”Ë</td>
<td style="text-align: center;">É”</td>
<td style="text-align: right;">13.</td>
<td style="text-align: center;"><sc>thought</sc></td>
<td>taught, sauce, hawk, jaw, broadâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">É™ÊŠ</td>
<td style="text-align: center;">o</td>
<td style="text-align: right;">14.</td>
<td style="text-align: center;"><sc>goat</sc></td>
<td>soap, joke, home, know, so, rollâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">uË</td>
<td style="text-align: center;">u</td>
<td style="text-align: right;">15.</td>
<td style="text-align: center;"><sc>goose</sc></td>
<td>loop, shoot, tomb, mute, huge, viewâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">aÉª</td>
<td style="text-align: center;">aÉª</td>
<td style="text-align: right;">16.</td>
<td style="text-align: center;"><sc>price</sc></td>
<td>ripe, write, arrive, high, try, buyâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">É”Éª</td>
<td style="text-align: center;">É”Éª</td>
<td style="text-align: right;">17.</td>
<td style="text-align: center;"><sc>choice</sc></td>
<td>adroit, noise, join, toy, royalâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">aÊŠ</td>
<td style="text-align: center;">aÊŠ</td>
<td style="text-align: right;">18.</td>
<td style="text-align: center;"><sc>mouth</sc></td>
<td>out, house, loud, count, crowd, cowâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">ÉªÉ™</td>
<td style="text-align: center;">Éª(r</td>
<td style="text-align: right;">19.</td>
<td style="text-align: center;"><sc>near</sc></td>
<td>beer, sincere, fear, beard, serumâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">É›É™</td>
<td style="text-align: center;">É›(r</td>
<td style="text-align: right;">20</td>
<td style="text-align: center;"><sc>square</sc></td>
<td>care, fair, pear, where, scarce, varyâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">É‘Ë</td>
<td style="text-align: center;">É‘(r</td>
<td style="text-align: right;">21</td>
<td style="text-align: center;"><sc>start</sc></td>
<td>far, sharp, bark, carve, farm, heartâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">É”Ë</td>
<td style="text-align: center;">É”(r</td>
<td style="text-align: right;">22</td>
<td style="text-align: center;"><sc>north</sc></td>
<td>for, war, short, scorch, born warmâ€¦</td>
</tr>
<tr class="odd">
<td style="text-align: center;">É”Ë</td>
<td style="text-align: center;">o(r</td>
<td style="text-align: right;">23</td>
<td style="text-align: center;"><sc>force</sc></td>
<td>four, wore, sport, porch, borne, storyâ€¦</td>
</tr>
<tr class="even">
<td style="text-align: center;">ÊŠÉ™</td>
<td style="text-align: center;">ÊŠ(r</td>
<td style="text-align: right;">24.</td>
<td style="text-align: center;"><sc>cure</sc></td>
<td>poor, tourist, pure, plural, juryâ€¦</td>
</tr>
</tbody>
</table>
<p>Later on in the book (p.&nbsp;122â€“124), Wells compares Received Pronunciation and General American English and goes into more detail about the principle behind the lexical sets:</p>
<blockquote class="blockquote">
<p>When we compare the pronunciation of particular words in the two accents, we find that in many respects there is a good match: for example, almost all words that have /iË/ in RP have the corresponding /i/ in GenAm, and vice versa: thus <em>creep</em>, <em>sleeve</em>, <em>key</em>, <em>people</em> and hundreds of other words. Likewise /aÉª/, transcribed identically for the two accents, and used in both cases for <em>ripe</em>, <em>arrive</em>, <em>high</em>, <em>try</em> and many other wordsâ€¦</p>
</blockquote>
<blockquote class="blockquote">
<p>Investigation shows thatâ€¦ we can successfully match the vowels in RP and GenAm forms of particular words for the vast bulk of the vocabularyâ€¦</p>
</blockquote>
<blockquote class="blockquote">
<p>This matching furnishes us with the framework of <strong>standard lexical sets</strong> which we use not only for comparing RP and GenAm but also for describing the lexical incidence of vowels in all the many accents we consider in this work. It turns out that for vowels in strong (stressed or stressable) syllables there are twenty-four matching pairs of RP and GenAm vowels. We identify each pair, and each standard lexical set of words whose stressed syllable exhibits the correspondence in question, by a keyword, which we shall always write in <sc>small capitals</sc>. Thus the correspondence between RP /iË/ and GenAm /i/ is the basis for the standard lexical set <sc>fleece</sc>â€¦</p>
</blockquote>
<blockquote class="blockquote">
<p>In the rest of this work standard lexical set keywords will also be used to refer to (i) any or all of the words belonging to the standard lexical set in question; and (ii) the vowel sound used for the standard lexical set in question in the accent under consideration. Rather than using expressions such as â€™short <em>i</em>/ for example, we shall speak of the <sc>kit</sc> vowel or simply of <sc>kit</sc>.</p>
</blockquote>
<p>If youâ€™re unfamiliar with these labels, I encourage you to look at Wellsâ€™ book. He explains each of these lexical sets in greater detail on pages 122â€“168 of Volume I.</p>
<!--http://phonetic-blog.blogspot.com/search?q=lexical+set-->
</section>
<section id="an-alternative-lexical-set-the-b_t-frame" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="an-alternative-lexical-set-the-b_t-frame">An Alternative Lexical Set: the <sc>b_t</sc> frame</h2>
<p>The Wells sets are very useful, but for some reason, they have not become adopted universally. Several researchers have opted to use an alternative set of labels that take advantage of a large minimal set in English, the <sc>b_t</sc> frame.</p>
<div class="page-columns page-full"><p>I did some digging in old <em>American Speech</em> and volumes of the <em>Publications of the American Dialect Society</em> to see when these labels were first used. The earliest instance I could find goes all the way back to  Sumner Ivesâ€™ 1954 study called <em>The Phonology of the Uncle Remus Stories</em>, which was the 22nd volume in the <em>PADS</em> series. On page 6, the author states that the following words are to refer to English vowels: <em>beet</em>, <em>bit</em>, <em>bait</em>, <em>bet</em>, <em>bat</em>, <em>not</em>, <em>bought</em>, <em>boat</em>, <em>put</em>, <em>boot</em>, <em>but</em>, <em>curt</em>, <em>bite</em>, <em>bout</em>, <em>boy</em>, and <em>above</em>. This set is remarkably close to what some researchers use today!</p><div class="no-row-height column-margin column-container"><span class="">Sumner Ives. 1954. The Phonology of the Uncle Remus Stories. <em>Publication of the American Dialect Society</em> 22(1): 3â€“59. <a href="https://doi.org/10.1215/-22-1-3" class="uri">https://doi.org/10.1215/-22-1-3</a></span></div></div>
<div class="page-columns page-full"><p> In contemporary sociolinguistics, I believe the <sc>b_t</sc> frame was popularized by Erik Thomas &amp; Malcah Yaeger-Drorâ€™s 2009 edited volume, <em>African American English Speakers and Their Participation in Local Sound Changes: A Comparative Study</em>. In the introduction, starting on page 8 and spilling into page 9, they say that they</p><div class="no-row-height column-margin column-container"><span class="">Erik Thomas &amp; Malcah Yaeger-Dror, eds.&nbsp;2009. African American English Speakers and Their Participation in Local Sound Changes: A Comparative Study. <em>Publication of the American Dialect Society</em> 94. Available <a href="https://read.dukeupress.edu/pads/issue/94/1">here</a>.</span></div></div>
<blockquote class="blockquote">
<p>â€¦found that it would be helpful to formulate a convention to unify the text and simplify the readerâ€™s task; with that thought in mind, we have suggested that authors use neither a phonological / / nor a variable ( ) presentation, both of which differ in conventions from author to author. We have chosen instead to refer to a given vowel class using keywords, following the principle behind Wells (1982). To further simplify, we turned to Ladefogedâ€™s (2005) choice of keyword paradigm, which uses words that are as untrammeled by their consonantal environment as possible. To obtain these keywords, he chose an <sc>h_d</sc> frame, to have his speakers â€œsay <sc>heed</sc> again.</p>
</blockquote>
<blockquote class="blockquote">
<p>To minimize the need for varying the â€œcarrierâ€ environment, in each case, the vowel being focused on here will be a <sc>b_t</sc> paradigm.</p>
</blockquote>
<table class="table">
<caption>Table 2: The lexical set based on the <sc>b_t</sc> frame. This is a subset of the table by Thomas &amp; Yaeger-Dror (2009:6).</caption>
<thead>
<tr class="header">
<th style="text-align: center;">IPA</th>
<th style="text-align: center;">Keyword</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">/i/</td>
<td style="text-align: center;"><sc>beet</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">/Éª/</td>
<td style="text-align: center;"><sc>bit</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">/e/</td>
<td style="text-align: center;"><sc>bait</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">/É›/</td>
<td style="text-align: center;"><sc>bet</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">/Ã¦/</td>
<td style="text-align: center;"><sc>bat</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">/É‘/</td>
<td style="text-align: center;"><sc>bot</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">/É”/</td>
<td style="text-align: center;"><sc>bought</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">/o/</td>
<td style="text-align: center;"><sc>boat</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">/ÊŒ/</td>
<td style="text-align: center;"><sc>but</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">/ÊŠ/</td>
<td style="text-align: center;"><sc>book</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">/u/</td>
<td style="text-align: center;"><sc>boot</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">/aÉª/</td>
<td style="text-align: center;"><sc>bite</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">/aÊŠ/</td>
<td style="text-align: center;"><sc>bout</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">/É”Éª/</td>
<td style="text-align: center;"><sc>boy</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">/Éš/</td>
<td style="text-align: center;"><sc>bird</sc></td>
</tr>
</tbody>
</table>
<p><br></p>
<p>They end with this statement:</p>
<blockquote class="blockquote">
<p>We hope that this convention will permit the reader to follow all the authors without difficult transitioning between chapters.</p>
</blockquote>
<div class="page-columns page-full"><p> It appears that their goal for continuity has beyond their volume because the set was used in later volumes of the <em>Publications of the American Dialect Society</em>. For instance, here are the remarks by the editors of <em>Speech in the Western States: Volume 1: The Coastal States</em> (Fridland <em>et al.</em> 2016):</p><div class="no-row-height column-margin column-container"><span class="">Valerie Fridland, Tyler Kendall, Betsy E. Evans, &amp; Alicia Beckford Wassink, eds.&nbsp;2016. Speech in the Western States, Vol 1., The Coastal States. <em>Publication of the American Dialect Society</em> 101. Available <a href="https://read.dukeupress.edu/pads/issue/101/1">here</a>.</span></div></div>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="">The description in <em>Speech in the <a href="https://read.dukeupress.edu/pads/issue/102/1">Speech in the Western States: Volume 2: The Mountain West</a></em> (Fridland et al.&nbsp;2017) is almost identical.</span></div></div>
<blockquote class="blockquote">
<p>For the purpose of clarity and continuity, authors use the conventions of the International Phonetic Alphabet throughout the chapters, though, in many cases, keywords in the <sc>b_t</sc> frame are used to highlight particular word classes and subclasses, following other recent PADS volumes (Thomas &amp; Yaeger-Dror 2009). These frames are built upon those made for comparative study of English dialects by Wells (1982) but have been adapted to allow representation of the particular vowel changes and conditioning environments of interest to the present study of the U.S. West.</p>
</blockquote>
<table class="table">
<caption>Table 3: The lexical set used in the <i>Speech in the Western States</i> volumes. From Fridland et al.&nbsp;2016:3 and Fridland et al.&nbsp;2016:5; Table 1.1 in both. The columns have been rearranged for consistency within this blog post.</caption>
<thead>
<tr class="header">
<th style="text-align: center;">IPA</th>
<th style="text-align: center;">Wells Keyword</th>
<th style="text-align: center;">b_t Keyword</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Éª</td>
<td style="text-align: center;"><sc>kit</sc></td>
<td style="text-align: center;"><sc>bit</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">É›</td>
<td style="text-align: center;"><sc>dress</sc></td>
<td style="text-align: center;"><sc>bet</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Ã¦</td>
<td style="text-align: center;"><sc>trap</sc></td>
<td style="text-align: center;"><sc>bat</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">É‘ ~ a</td>
<td style="text-align: center;"><sc>lot</sc></td>
<td style="text-align: center;"><sc>bot</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">É” ~ a</td>
<td style="text-align: center;"><sc>cloth</sc>/<sc>thought</sc></td>
<td style="text-align: center;"><sc>bought</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">ÊŒ</td>
<td style="text-align: center;"><sc>strut</sc></td>
<td style="text-align: center;"><sc>but</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">ÊŠ</td>
<td style="text-align: center;"><sc>foot</sc></td>
<td style="text-align: center;"><sc>book</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">Éš</td>
<td style="text-align: center;"><sc>nurse</sc></td>
<td style="text-align: center;"><sc>burt</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">i</td>
<td style="text-align: center;"><sc>fleece</sc></td>
<td style="text-align: center;"><sc>beet</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">e</td>
<td style="text-align: center;"><sc>face</sc></td>
<td style="text-align: center;"><sc>bait</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">o</td>
<td style="text-align: center;"><sc>goat</sc></td>
<td style="text-align: center;"><sc>boat</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">u</td>
<td style="text-align: center;"><sc>goose</sc></td>
<td style="text-align: center;"><sc>boot</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">aÉª</td>
<td style="text-align: center;"><sc>price</sc></td>
<td style="text-align: center;"><sc>bite</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">É”Éª</td>
<td style="text-align: center;"><sc>choice</sc></td>
<td style="text-align: center;"><sc>boy</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">aÊŠ</td>
<td style="text-align: center;"><sc>mouth</sc></td>
<td style="text-align: center;"><sc>bout</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">ÉªÉ¹ ~ iÉ¹</td>
<td style="text-align: center;"><sc>near</sc></td>
<td style="text-align: center;"><sc>beer</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">ÉšÉ¹</td>
<td style="text-align: center;"><sc>square</sc></td>
<td style="text-align: center;"><sc>bare</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">É‘É¹</td>
<td style="text-align: center;"><sc>start</sc></td>
<td style="text-align: center;"><sc>bar</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">É”r / or</td>
<td style="text-align: center;"><sc>north</sc>/<sc>force</sc></td>
<td style="text-align: center;"><sc>bore</sc></td>
</tr>
<tr class="even">
<td style="text-align: center;">ÊŠÉ¹</td>
<td style="text-align: center;"><sc>cure</sc></td>
<td style="text-align: center;"><sc>burr</sc></td>
</tr>
<tr class="odd">
<td style="text-align: center;">É™É¹</td>
<td style="text-align: center;"><sc>letter</sc></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">É™</td>
<td style="text-align: center;"><sc>comma</sc></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
<p>The only difference is that <sc>bird</sc> was changed to <sc>burt</sc>.</p>
<p>Outside of the <em>PADS</em> volumes, this frame was also used in <a href="https://journals.sagepub.com/doi/abs/10.1177/0075424210384226">McCarthy (2011)</a>, which explicitly states that these labels were used because of Thomas &amp; Yaeger-Dror (2009).</p>
<p>I donâ€™t know the reason why the <sc>b_t</sc> frame was designed when the Wells lexical sets were already established. Perhaps the draw of the nearly complete minimal set to contrast all English vowels was useful. Maybe itâ€™s because the words in the <sc>b_t</sc> frame are shorter, which makes for less cluttered visualizations and written prose. Thomas &amp; Yaeger-Dror did say that the use of the consonants /b/ and /t/ in the keywords helped reduce the effects of surrounding consonants on the vowels themselves. Ultimately though, Iâ€™m not sure.</p>
</section>
<section id="my-thoughts-on-the-b_t-frame" class="level2">
<h2 class="anchored" data-anchor-id="my-thoughts-on-the-b_t-frame">My thoughts on the <sc>b_t</sc> frame</h2>
<p>Hot take: I donâ€™t think this the <sc>b_t</sc> is any more useful than IPA. Hear me out:</p>
<p>Imagine youâ€™re at a conference talking about the low back merger and you yourself have the merger. Since you donâ€™t naturally differentiate the words <em>bot</em> and <em>bought</em>, you struggle to explain the differences that may exist in your study. Even if you do distinguish the sounds, many people in your audience may not, so theyâ€™ll have a hard time understanding. This was one of the reasons Wells came up with his lexical sets: neither you nor your audience would have much difficulty understanding the words <em>lot</em> or <em>thought</em> since, as far as I know, /lÉ”t/ and /Î¸É‘t/ are not English words.</p>
<p>Even if youâ€™re not talking about a merger, if you are someone with particularly shifted vowels, when you say an isolated, ambiguous token like [bÉ›Ìt] or [bÃ¦Ì™t], it may not be immediately clear to listeners of other dialects which vowel youâ€™re talking about.</p>
<p>The words in the <sc>b_t</sc> frame may be â€œuntrammeled by their consonantal environment,â€ but I donâ€™t know if the lack of transition formants make for the most effective label in speech or writing. Keywords are labels to refer to large lexical sets, so while they may not make for ideal tokens when collecting phonetic data, they need to still serve the purpose of unambiguously identifying a vowel phoneme.</p>
<p>In fact, Wells specifically designed his original set so that it specifically would <em>not</em> use the <sc>b_t</sc> frame:</p>
<blockquote class="blockquote">
<p>The keywords have been chosen in such a way that clarity is maximized: whatever accent of English they are spoken in, they can hardly be mistaken for other words. Although <em>fleece</em> is not the commonest of words, it cannot be mistaken for a word with some other vowel; whereas <em>beat</em>, say, if we had chosen it instead, would have been subject to the drawback that one manâ€™s pronunciation of <em>beat</em> may sound like anotherâ€™s pronunciation of <em>bait</em> or <em>bit</em>. (Wells 1982:123)</p>
</blockquote>
<p>I question the usefulness of the <sc>b_t</sc> frame. Itâ€™s convenient that a common enough English word can be created by filling in almost any vowel into the template, but I donâ€™t know if this large minimal set makes for the most unambiguous lexical set. When he introduces his keywords, Wells says that they are â€œintended to be unmistakable no matter what accent one says them in.â€ This property is not retained in the <sc>b_t</sc> set of keywords. In fact, creating a set based on minimal pairs defeats the very purpose of a lexical set.</p>
<p>To put it another way, just because we call something the <em>cot-caught</em> merger doesnâ€™t mean we should refer to the entire lexical sets as <sc>cot</sc> and <sc>caught</sc>. In fact, I think we should actively <em>avoid</em> referring to them as <sc>cot</sc> and <sc>caught</sc> for the very reason that they <em>do</em> form a minimal pair.</p>
<p>Itâ€™s my impression that researchers on non-American varieties of English use Wellsâ€™ original lexical sets without any problems. Using a different set is potentially confusing and may alienate ourselves from studies on other World Englishes.</p>
<p>To be clear, I am in no way criticizing the researchers who came up with or use the <sc>b_t</sc> frame. If youâ€™re familiar with what I do youâ€™ll know that their work is <em>highly</em> relevant to my own studies, and I cite <em>a lot</em> of studies that use the <sc>b_t</sc> frame. Their work is excellent and I model my own work after their theirs. I just think the labels could be clearer.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p><span class="sidenote">This reminds me of how some people use the Labovian transcription system instead of standard IPA. See <a href="http://val-systems.blogspot.com/2018/07/why-does-labov-have-such-weird.html">Josef Fruehwaldâ€™s blog post</a> on those.</span> There are two competing systems of lexical sets being used in American dialectology: the Wells lexical set and the <sc>b_t</sc> frame. To answer my titular question of why people use <sc>bat</sc> instead of <sc>trap</sc>â€¦ I donâ€™t really know. I think it may largely depend on what university the work is coming out of. But, I think Wellsâ€™ original set may be a little better.</p>
<p>PS: Regardless of which system you use, I think we should make sure we use <sc>small caps</sc> instead of ALL CAPS or even <sc>Capitalized Small Caps</sc>. Itâ€™s truer to Wellsâ€™ original notation and I think they just look a lot better typographically.</p>
<p>PPS: To my knowledge, Wells never intended for the lexical set labels (or even the example words in the original explanation) to be ideal tokens for eliciting the vowels they represent. So, while the <sc>b_t</sc> labels might be â€œuntrammeled by their consonantal environment,â€ the Wells labels are not. So, thereâ€™s probably no need to eliciting the words <em>fleece</em>, <em>kit</em>, <em>face</em>, <em>dress</em>, etc. when getting tokens of these vowels.</p>
<p><br></p>
<p>Update: <a href="../../blog/thoughts-on-allophonic-extensions-to-wells-lexical-sets">Click here for further musings, ramblings, and recommendations for non-canonical extensions to Wellsâ€™ lexical sets when referring to allophones.</a></p>


</section>

 ]]></description>
  <category>Lexical Sets</category>
  <category>Methods</category>
  <guid>https://new.joeystanley.com/blog/why-do-people-use-bat-instead-of-trap/index.html</guid>
  <pubDate>Tue, 29 Oct 2019 01:48:00 GMT</pubDate>
</item>
<item>
  <title>LCUGA6</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/lcuga6/index.html</link>
  <description><![CDATA[ 




<p>I presented at the 6th annual Linguistics Conference at UGA today! My presentation, which was called â€œReal Time Vowel Shifts in Georgia Englishâ€ compared Georgians born around the 1890s to those born in the 1990sâ€”100 years of change! The gist: nearly every vowel has changed, and it seems like the trajectory of that change is in the direction of the Elsewhere Shift, rather than just a simple recession of Southern features.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/191004-lcuga6.pdf">here</a>!</p>
</div>
</div>
<p>The data came from two very different sources. The older speakers, were born between 1887 and 1903, were recorded doing Linguistic Atlas interviews and are part of the <em>Digital Archive of Southern Speech</em>. The younger speakers, who were born between 1994 and 1997) were UGA undergraduates that I recorded as they read sentences in a lab. Two very different datasets, but theyâ€™re all Georgian natives, so it starts to give us a glimpse into how things have changed around here.</p>
<p>Hereâ€™s a summary of the changes I found.</p>
<ul>
<li><p><sc>price</sc> was monophthongal for older speakers and definitely a diphthong in the younger speakers.</p></li>
<li><p>The Euclidean distance between <sc>fleece</sc> and <sc>kit</sc> and between <span class="smallcaps">face</span> and <sc>dress</sc> was grew over 100 years, suggesting the younger speakersâ€™ vowels are not as â€œSouthernâ€ sounding.</p></li>
<li><p>While the older speakersâ€™ <sc>lot</sc> and <sc>thought</sc> were close, the younger speakersâ€™ were almost entirely merged.</p></li>
<li><p>The front lax vowels, <sc>trap</sc>, <sc>dress</sc>, and <sc>kit</sc> were front and monophthongal in the older speakers while the younger speakers realized them more centralized and more diphthongal. <sc>trap</sc> underwent the most change, then <sc>dress</sc>, and then <sc>kit</sc>.</p></li>
<li><p><span class="smallcaps">goose</span> was centralized even in the older speakers, but the younger speakers took it further by using an even more fronted onset.</p></li>
</ul>
<p>This animation basically sums up the entire talk. Plus I just had fun making animations! Hereâ€™s the change for the women.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/lcuga6/georgia_animation_female.gif" class="img-fluid figure-img"></p>
</figure>
</div>
<p>And hereâ€™s the change for the men.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/lcuga6/georgia_animation_male.gif" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Overall, it appears that itâ€™s not just that the younger speakers lack features associated with the South, itâ€™s that theyâ€™re also using realizations characteristic of other regions like California and Canada. It makes sense, since Atlanta is a large metropolitan area and is kind of known as a non-Southern city in the middle of the South. But this might be an indication that the Elsewhere Shift has made its way into the South.</p>



 ]]></description>
  <category>Animations</category>
  <category>Conferences</category>
  <category>Linguistic Atlas</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>South</category>
  <guid>https://new.joeystanley.com/blog/lcuga6/index.html</guid>
  <pubDate>Fri, 04 Oct 2019 04:30:00 GMT</pubDate>
</item>
<item>
  <title>Thank You</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/thank-you/index.html</link>
  <description><![CDATA[ 




<p>Some of you may have noticed that at the bottom of a lot of the pages on my website, Iâ€™ve got this button:</p>
<center>
  <script type="text/javascript" src="https://ko-fi.com/widgets/widget_2.js"></script><script type="text/javascript">kofiwidget2.init('Buy me a Coffee', '#376092', 'E1E1OQ2R');kofiwidget2.draw();</script> 
</center>
<br>
<br>
<p>Iâ€™ve created an account on <a href="https://ko-fi.com">ko-fi.com</a>, which is a platform that, in their words, provides â€œa friendly way for fans to support your work for the price of a coffee.â€ To put it more bluntly, Iâ€™ve created a way for people to give me money for my tutorials and stuff. At the risk of sounding arrogant, Iâ€™ll brag for just a little bit before geeking out about the new books Iâ€™ve gotten because of that little button.</p>
<section id="let-me-brag-for-just-a-sec" class="level2">
<h2 class="anchored" data-anchor-id="let-me-brag-for-just-a-sec">Let me brag for just a sec</h2>
<p>So Iâ€™ve put together half a dozen tutorials and another dozen or so workshops. The most popular ones are the tutorials on how to make vowel plots, how do formant extraction, measuring vowel overlap, and my series of R workshops. You can find them all on my <a href="../../resources">Resources</a> page.</p>
<p>These were skills that arenâ€™t typically taught in a linguistics course, but theyâ€™re expected of sociophoneticians, and I knew I had to learn how to do them. So, I hunkered down, did <em>lots</em> of googling, and figured out this stuff on my own by frankensteining what I could find from lots of other pages online. After a while, word spread among my peers that I had acquired some skills, and I ended up helping lots of people do these things on their own data.</p>
<p>Eventually, I realized that there was a niche to be filled: my peers could benefit from a clear tutorial on some basic scripting techniques in sociophonetics. So, I started to write the tutorials that I wish I had had when I was learning this stuff. When I finish them, I share them on Twitter, and theyâ€™ve consistently remained among my most visited pages on my website. People from about ten different countries on four continents have contacted me for various reasons, explaining how useful theyâ€™ve found the tutorials. And there are likely many more anonymous folks too.</p>
<p>Since then, lots of other people have produced excellent tutorials that cover some of the same topics mine have. And thatâ€™s awesome! Iâ€™m just glad that people have so many resources available to them to learn these skills.</p>
</section>
<section id="so-whats-this-ko-fi-thing" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="so-whats-this-ko-fi-thing">So whatâ€™s this Ko-fi thing?</h2>
<p>So someone (I forget who) offhandedly mentioned that I should charge people for my tutorials. There was no way I was going to do that. I got this information for free, so I give it for free.</p>
<div class="page-columns page-full"><p>But, I figured if people wanted to <em>donate</em> money, well, who was I to stop them? So I looked around and settled on Ko-fi as a way to give people that opportunity if they wanted to take it. It seems simple enough: the button above will take you to my Ko-fi page, and from there you can donate $3, or about the price of a coffee.  The money gets sent to my PayPal account and I can deposit into my bank account.</p><div class="no-row-height column-margin column-container"><span class="">Ironically, I donâ€™t drink coffee, so you can think of it as a fancy glass bottle of Coca-Cola or something.</span></div></div>
<p>So I set it up, put and put it at the bottom of my tutorials, and didnâ€™t think anything of it because I didnâ€™t expect much to happen. But slowly, here and thereâ€”and much to my surpriseâ€”the donations came in. Itâ€™s not bumping me up to the next tax bracket or anything, but it does make me feel that the work I put into the tutorials is appreciated.</p>
<p><em>Update: Now that Iâ€™m faculty, I have a real salary, and I feel back taking money from people, especially grad students. But, Iâ€™ve been told that sometimes people appreciate having a way to express their appreciation.</em></p>
</section>
<section id="what-am-i-doing-with-the-money" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="what-am-i-doing-with-the-money">What am I doing with the money?</h2>
<p>Instead of just dumping it into my bank account, I figure I should do something special with the money. I decided to get a couple books. In particular, I wanted to get some books on data visualization, since thatâ€™s relevant to the tutorials themselves.</p>
<p>My first goal was <em>Data Visualization</em> by Kieren Healy. I had been following the book as it was approaching publication and was excited to see itâ€™s positive reception. Yes, itâ€™s pretty much all available online, but I wanted the physical copy for two reasons. For one, itâ€™s a beautiful book and a paragon of excellence in typography. But also, I should return the favor of financially supporting someone who produces tutorials online. Thanks to one large donation that bumped me well past my goal, Iâ€™m now a proud owner of Healyâ€™s book!</p>
<p><img src="https://new.joeystanley.com/blog/thank-you/joey_healy.jpg" class="img-fluid" style="width:85.0%"></p>
<p>So I tweeted about it and did a small humble brag. And again, much to my surprise, some more donations came in! So in the same week, I met my second goal of purchasing <em>Fundamentals of Data Visualization</em> by Claus O. Wilke.</p>
<div class="page-columns page-full"><p> <img src="https://new.joeystanley.com/blog/thank-you/joey_wilke.jpg" class="img-fluid" style="width:85.0%"></p><div class="no-row-height column-margin column-container"><span class="">Iâ€™m now realizing the front phone on my camera is quite fuzzy.</span></div></div>
<p>With these two books in hand, I hope my knowledge of data visualization will increase and that this percolates into future tutorials and workshops.</p>
<p>So I didnâ€™t think this whole thing would work. Apparently it has. Iâ€™ve now started to compile a list of additional books Iâ€™d like to get, including Edward Tufteâ€™s quartet of data visualization books, some linguistics books Iâ€™ve been meaning to get, and a couple statistics manuals.</p>
</section>
<section id="thank-you" class="level2">
<h2 class="anchored" data-anchor-id="thank-you">Thank You</h2>
<p>The reason for all this is to say thank you. Iâ€™m so thrilled to hear that people seem to find some utility in my tutorials, and Iâ€™m humbled that some folks went out of their way to send me a little extra pocket money as a token of their appreciation. Iâ€™m honored to be helping the linguistics community in a small way. Thank you.</p>


</section>

 ]]></description>
  <category>Data Viz</category>
  <category>Meta</category>
  <category>Statistics</category>
  <guid>https://new.joeystanley.com/blog/thank-you/index.html</guid>
  <pubDate>Sun, 18 Aug 2019 12:00:00 GMT</pubDate>
</item>
<item>
  <title>Jealousy List 3</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/jealousy-list-3/index.html</link>
  <description><![CDATA[ 




<p>This is the third iteration of my <a href="https://fivethirtyeight.com/features/damn-we-wish-wed-done-these-11-stories/">Jealousy List</a>, which is a list of articles so good I wish I had been the one to write them. My first two lists were posted about a year ago (see the list of lists <a href="../../blog/#category=Jealousy Lists">here</a>) and this one is long overdue, so I apologize for some of the posts being a little less recent. Regardless, here are a list of posts Iâ€™ve found in the past few weeks and months that I found exceptional in some way, entertaining, informative, or just plain cool.</p>
<ol type="1">
<li><p><strong><a href="https://twitter.com/trashystats">Saskia Freytag</a></strong>. <a href="http://rpubs.com/Saskia/520216">â€œWorkshop: Dimension reduction with Râ€</a>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
</p><p>So I wrote a tutorial on dimension reductions in <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a>. It has actually turned out to be fairly comprehensive. It uses a fun example dataset on cereals (ğŸ‰ - not looking for at iris) I would love some feedback: <a href="https://t.co/VsiHX2KYdT">https://t.co/VsiHX2KYdT</a></p>
<p></p>
<p>â€” Saskia Freytag (<span class="citation" data-cites="trashystats">@trashystats</span>) <a href="https://twitter.com/trashystats/status/1162234718504411136?ref_src=twsrc%5Etfw">August 16, 2019</a></p>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>You may have heard of PCA (Principle Components Analysis) as a way to reduce a bunch of variables down to a more manageable number. As it turns out, this is just one way to do a <em>dimension reduction</em> on your data. Freytagâ€™s workshop does a really nice job at explaining some of the different dimension reduction techniques that are out there, including helpful plots for the visual learners out there. It also goes into detail about the pros and cons of each method, and gives some sample R code showing you how to run the analysis yourself. I wish there were more workshops like there floating around! Plus, it uses data from a bunch of cereals, and Iâ€™m pretty sure Iâ€™ve used that dataset before in my workshopsâ€¦</p>
<p><br></p></li>
<li><p><strong><a href="https://austinwehrwein.com">Austin Wehrwein</a></strong>. <a href="https://austinwehrwein.com/data-visualization/housing/">â€œBurden of roof: Revisiting housing costs with tidycensusâ€</a>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
</p><p>In this episode I use the A+ tidycensus <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> package to examine housing costs along with income data AND stretch wordplay as far as it will go. Burden of roof: revisiting housing costs with tidycensus. <a href="https://t.co/gDVlOb9N9H">https://t.co/gDVlOb9N9H</a> <a href="https://t.co/i3gxzz6C8G">pic.twitter.com/i3gxzz6C8G</a></p>
<p></p>
<p>â€” Austin Wehrwein (<span class="citation" data-cites="awhstin">@awhstin</span>) <a href="https://twitter.com/awhstin/status/1157290104416849921?ref_src=twsrc%5Etfw">August 2, 2019</a></p>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This is a short blog post, but I really like it because is succinctly shows how to quickly produce a really complelling story with some data and a nice visual. It uses the <a href="https://walkerke.github.io/tidycensus/">tidycensus</a> package by <a href="http://personal.tcu.edu/kylewalker/">Kyle Walker</a> to extract some information about median income and housing prices per US county, and then creates a stunning map to display the data. I also learned that the county I live in now, Clarke County, Georgia, was among the top 25 <em>worst</em> counties in the country in this regard. I guess thatâ€™s where all my money is going!</p>
<p><br></p></li>
<li><p><strong><a href="https://www.garrickadenbuie.com">Garrick Aden-Buie</a></strong>. <a href="https://www.garrickadenbuie.com/blog/custom-discrete-color-scales-for-ggplot2/">â€œCustom Discrete Color Scales for ggplot2â€</a>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
</p><p>I wrote up a short blog post on creating custom ggplot2 color scales. I focused on discrete color scales to demo a setup that makes binary colors easy, but I hope the post is helpful if you're working on a <a href="https://twitter.com/hashtag/ggplot2?src=hash&amp;ref_src=twsrc%5Etfw">#ggplot2</a> theme for your org or brand. <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> <a href="https://t.co/jQDxE61K3W">https://t.co/jQDxE61K3W</a></p>
<p></p>
<p>â€” Garrick Aden-Buie (<span class="citation" data-cites="grrrck">@grrrck</span>) <a href="https://twitter.com/grrrck/status/1162419274566262784?ref_src=twsrc%5Etfw">August 16, 2019</a></p>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Iâ€™ve become a bit of a color snob, so I appreciate a good post on colors in data visualization. This one is less about the colors themselves, and more about how to more easily implement your own custom color scheme in ggplot2. Aden-Buie even goes so far as to provide helpful tips for when you compile all these custom commands into an R package. Iâ€™ll definitely be using this whenever I get my package off the ground.</p>
<p><br></p></li>
<li><p><strong><a href="http://rafalab.github.io//">Rafael Irizarry</a></strong>. <a href="https://simplystatistics.org/posts/2019-02-21-dynamite-plots-must-die/">â€œDynamite Plots must Dieâ€</a>. From <em><a href="https://simplystatistics.org">Simply Statistics</a></em>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
</p><p>Open letter to journal editors: dynamite plots must die. Dynamite plots, also known as bar and line graphs, hide important information. Editors should require authors to show readers the data and avoid these plots. <a href="https://t.co/0GNKEIUCJL">https://t.co/0GNKEIUCJL</a> <a href="https://t.co/OS9ytEFRZN">pic.twitter.com/OS9ytEFRZN</a></p>
<p></p>
<p>â€” Rafael Irizarry (<span class="citation" data-cites="rafalab">@rafalab</span>) <a href="https://twitter.com/rafalab/status/1098973538260840449?ref_src=twsrc%5Etfw">February 22, 2019</a></p>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Data visualization must have been on my mind for a while now, because five months ago I bookmarked this blog post so that itâ€™d make it on my next Jealousy List. This is a nice critique about <em>Dynamite Plots</em>, or basically bar plots with those little error bars at the top. Basically, they obscure the underlying distribution and can be replaced by a very small table. Fortunately, the complaint comes with a few recommendations for alternative visuals.</p>
<p><br></p></li>
<li><p><strong><a href="https://juliasilge.com">Julia Silge</a></strong>. <a href="https://juliasilge.com/blog/introducing-tidylo/">â€œIntroducing Tidyloâ€</a>.</p>
<p>There will probably always be at least one Julia Silge post on my Jealousy Lists. This one introduces a new R package, tidylo, which calculates weighted log odds using within the framework of the tidyverse. The post itself is, as always, a fun read and there are some great visuals. Thisâ€™ll make it really easy to choose a baby name characteristic of like the 1920s for my next kid or something.</p></li>
</ol>
<p><br></p>
<p>So thatâ€™s it for my long-overdue Jealousy List: statistical procedures, succinct tutorials, color, data visualization, and more statistics. Again, a decent representation of what Iâ€™ve been reading recently.</p>



 ]]></description>
  <category>Jealousy Lists</category>
  <category>Data Viz</category>
  <category>R</category>
  <category>Skills</category>
  <category>Statistics</category>
  <guid>https://new.joeystanley.com/blog/jealousy-list-3/index.html</guid>
  <pubDate>Sat, 17 Aug 2019 04:25:00 GMT</pubDate>
</item>
<item>
  <title>DH 2019</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/dh2019/index.html</link>
  <description><![CDATA[ 




<p>At the Digital Humanities 2019 conference in Utrecht, the Netherlands, I presented with Bill Kretzschmar on ways to visualize a lot of phonetic data.</p>
<section id="the-gazetteer-of-southern-vowels" class="level2">
<h2 class="anchored" data-anchor-id="the-gazetteer-of-southern-vowels">The Gazetteer of Southern Vowels</h2>
<p>The first half of the presentation was essentially me showcasing the <em>Gazetteer of Southern Vowels</em> (or <em>GSV</em>), a website I created in Shiny to help visualize 1.3 million acoustic measurements from the <em>Digital Archive of Southern Speech</em>.<span class="sidenote-left">The full web address is <a href="http://lap3.libs.uga.edu/u/jstanley/vowelcharts/">http://lap3.libs.uga.edu/ u/jstanley/vowelcharts/</a>, but Iâ€™ve got a redirect at <a href="joeystanley.com/gsv">joeystanley.com/gsv</a> thatâ€™s easier to type.</span> In the talk I spend most of the time in the â€œVowel Plot Comparisonâ€ tab (below) and show how you can interact with the data.</p>
<p><img src="https://new.joeystanley.com/blog/dh2019/side_by_side.png" class="img-fluid"></p>
<p>First, you can subset the data by demographic factors. The <em>Speaker Selection</em> tab has menu items for speakersâ€™ sex, age, ethnicity, home state, social class, and a couple other variables. When you select one or more of these, the plot automatically updates to reflect that subset.</p>
<p><img src="https://new.joeystanley.com/blog/dh2019/tab_speaker.png" class="img-fluid"></p>
<p>You can also subset the data by linguistic factors. In the <em>Words</em> tab, youâ€™ll see that a list of stopwords is displayed and that those are excluded by default. You can add to or remove words from that stoplist, or switch it so display only those words (or some other set of words like numbers or colors).</p>
<p><img src="https://new.joeystanley.com/blog/dh2019/tab_words.png" class="img-fluid"></p>
<p>In the <em>Vowels</em> tab, youâ€™ve got a whole bunch of options. First, you can choose what vowel is being displayed, what kind of stress it can have, and what its phonetic environment is(based on following segment only). There are some methodological choices too, like ways of filtering and normalizing the data. You can also choose what transcription system is being used.</p>
<p><img src="https://new.joeystanley.com/blog/dh2019/tab_vowels.png" class="img-fluid"></p>
<p>Then, there are ways for you to customize the plot. The <em>Plot Style</em> tab as four main options (points, ellipses, means, and words), that act independently with their own controls for size and opacity. So if you want means and ellipses but no dots, you can do that. If you want to display the words themselves, but in a small font and transparent, be my guest.</p>
<p><img src="https://new.joeystanley.com/blog/dh2019/tab_plot_style.png" class="img-fluid"></p>
<p>The <em>Plot Customization</em> tab lets you change things like the zoom, axes, aspect ratio, and (some control over) colors. Iâ€™m hoping to add more options to this tab in the future. With these two tabs, I feel like you can make a lot of very different plots, all based on the same data, which is pretty cool.</p>
<p><img src="https://new.joeystanley.com/blog/dh2019/tab_plot_customization.png" class="img-fluid"></p>
<p>Finally, the <em>Download Options</em> is the newest tab. You could always take a screenshot, but youâ€™re limited to how your web browser displays the image and your computerâ€™s screensize. In this tab, you can set the height, width, quality, and format, so you can make publication-quality images. In fact, the plots in this blog post were all created using this download button, so you can recreate them yourself!</p>
<p><img src="https://new.joeystanley.com/blog/dh2019/tab_download.png" class="img-fluid"></p>
<p>So thatâ€™s it! My goal in creating these options was to allow users to create any type of plot using any conceivable subset of DASS, and I think the GSV does a pretty good job at that. Hereâ€™s a quick gallery of six different plots:</p>
<p><img width="50%" style="float:left;" src="https://new.joeystanley.com/blog/dh2019/sample_points_big.jpeg"> <img width="50%" style="float:right;" src="https://new.joeystanley.com/blog/dh2019/sample_ellipse_means.jpeg"> <img width="50%" style="float:left;" src="https://new.joeystanley.com/blog/dh2019/sample_words_ellipse_means.jpeg"> <img width="50%" style="float:right;" src="https://new.joeystanley.com/blog/dh2019/sample_points_trans_means.jpeg"> <img width="50%" style="float:left;" src="https://new.joeystanley.com/blog/dh2019/sample_points_ellipse.jpeg"> <img width="50%" style="float:right;" src="https://new.joeystanley.com/blog/dh2019/sample_words_ellipse.jpeg"></p>
</section>
<section id="point-pattern-analysis" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="point-pattern-analysis">Point Pattern Analysis</h2>
<p>In the second half of the presentation, Bill Kretzschmar took over and discussed using point pattern analysis in the visualization of vowel data. He has found that when you overlay a grid on the F1-F2 space (just as geographers do with geospatial data), you can see the central tendency of vowels by which â€œcellsâ€ in this new grid are the densest. They roughly follow the 80-20 rule, with a few cells being heavy concentrated, some having some tokens, and many with very few. Hereâ€™s just one image of a Georgia manâ€™s <sc>fleece</sc> vowel.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="">Incidentally, because the grid itself is new element, there are additional controls in the <em>Plot Customization</em> tab, like how many cells and the opacity or size of the labels. And since thereâ€™s only one color being used, Iâ€™ve got controls over whether the shading is discrete or continuous, if itâ€™s discrete then how many levels, and you can even put a custom color in hex notation. Also, Iâ€™m still working on getting the ranges in the legend to display integers only, since 54.6 data points in a cell is somewhat nonsensical.</span></div></div>
<p><img src="https://new.joeystanley.com/blog/dh2019/point_pattern.jpeg" class="img-fluid"></p>
<p>Bill finds that if you plot them in order of density, the resulting curve is an asymptotic hyperbolic curve, or just A-curve for short. And, as it turns out, this distribution is fractal in nature, so regardless of how much you subset the data, youâ€™ll find the same distribution. The <em>GSV</em> makes it easy to see this distributions interactively.</p>
<p>At the very end, we hinted at some additional visualizations weâ€™d like to develop to make it easier to view trajectory data, taking advantage of a third-dimension in the plot itself. Hopefully, weâ€™ll have more to say about that in the future.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>So thatâ€™s our presentation! Weâ€™ve got a lot of data and we needed lots of plots to make sense of it all. Instead of saving plot after plot, we decided an interactive Shiny app might be a better option. Most importantly, I think weâ€™ve learned a little more about how language works because of the size of the data and the interactivity of this tool.</p>


</section>

 ]]></description>
  <category>Conferences</category>
  <category>Linguistic Atlas</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>South</category>
  <guid>https://new.joeystanley.com/blog/dh2019/index.html</guid>
  <pubDate>Mon, 08 Jul 2019 22:30:00 GMT</pubDate>
</item>
</channel>
</rss>
