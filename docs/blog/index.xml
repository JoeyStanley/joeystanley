<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Joey Stanley</title>
<link>https://new.joeystanley.com/blog/index.html</link>
<atom:link href="https://new.joeystanley.com/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.353</generator>
<lastBuildDate>Mon, 25 Sep 2023 04:12:00 GMT</lastBuildDate>
<item>
  <title>Website Version 3</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/website-version-3/index.html</link>
  <description><![CDATA[ 




<p>After exactly seven years with my old website, I’ve decided to change it to what you are seeing now.</p>
<section id="what-was-wrong-with-the-old-one" class="level2">
<h2 class="anchored" data-anchor-id="what-was-wrong-with-the-old-one">What was wrong with the old one?</h2>
<p>I built my old website in September 2016. I had a research assistantship at the DigiLab at UGA, and Emily McGinn, the supervisor, suggested I find ways to increase my online presence. I learned some <a href="../../blog/making-a-website-is-fun">web design and CSS skills</a> skills and eventually made Version 1 of my website. That version was essentially the same as what I built in the tutorial I followed, so a few months later I rewrote everything from scratch and made Version 2. (Let’s be honest though, it’s still obviously heavily based on the tutorial.) Other than very minor tweaks to a few things, that’s how my website has been since then.</p>
<p>However, it got a bit unwieldy. The blog was organized just fine, but I also added pages here and there to go along with workshops and other presentations I gave. It got more confusing when I gave the same workshop a second time and had multiple similar pages floating around. Since I didn’t foresee some of these additions, its growth was reminiscent of unplanned suburban sprawl. For examples, sometimes images were just dumped into a folder, others were better organized. Non-blog pages were hidden and were sometimes a top-level page and other times within a dedicated subdirectory. Each individual addition wasn’t a big deal, but once I stepped back and looked at it all, it was a mess.</p>
<p>The format of my tutorials wasn’t consistent either. I have lots of handouts on my website, tucked away here and there. If they were associated with a workshop, they were separate R Markdown files that didn’t fit in with the rest of the site. Some of my earliest ones are PDFs of Word files!If they weren’t associated with a workshop, they’re regular blog posts. But because the site wasn’t connected to R, I had to do a <em>lot</em> of copying and pasting R Markdown code and careful insertion of images to get those tutorials to look right. In some cases, the extra work made it possible to do things like syntax highlighting in Praat and highlighting specific lines of code. But that was all done by manually inserting HTML tags and updating my CSS.</p>
<p>Also, as careful as I was about my CSS, it wasn’t perfect. I think there were some issues if like a list had only one element, and there were things with hyperlinks. Some one-off portions of blogs or tutorials sometimes didn’t look right. I had a disclaimer at the top of every page, something like, “This website is built from scratch. Pardon the flaws; I am not a web designer.” Which was a humble brag if anything. But as the site grew I didn’t want to change the CSS because it might change some blog post from years ago in unexpected ways.</p>
<p>Ultimately, I didn’t mind the mess because it’s what made my site unique. But, what made me finally decide to migrate to Quarto was the underlying architecture. It was built using Jekyll, which involves a programming language called Ruby in some way. After seven years I still have no idea what either of those are. I did this because it’s what the tutorial I followed used. When the site worked, it was great. But sometimes, the Ruby dependencies (called “gems”) would update or break or whatever and I had to google around trying to find a fix. I had no idea what I was doing and it led to a lot of frustrated late nights trying to get my website up and running again.</p>
<p>Then Quarto comes along, which makes it easy to make a blog entirely within R Studio. I have been very familiar with the R world for a while. In 2017, I was an early adopter of <a href="https://www.rstudio.com/products/shiny/">Shiny</a> (at least in linguistics, I think), so I was able to integrate all my html, CSS, and R skills into the <a href="http://lap3.libs.uga.edu/u/jstanley/vowelcharts/">Gazetteer of Southern Vowels</a>. In 2020, I also started dabbling with creating my own R Packages and using the amazing <a href="https://pkgdown.r-lib.org">pkgdown</a> to make dedicated websites for them (see <a href="https://joeystanley.github.io/joeyr/">joeyr</a>, <a href="https://github.com/JoeyStanley/futurevisions">futurevisions</a>, <a href="https://joeystanley.github.io/barktools/">barktools</a>, and <a href="https://joeystanley.github.io/joeysvowels/">joeysvowels</a>). Finally, I have a side project that involves collecting and analyzing data about what hymns are sung in LDS congregations, and in 2023 I decided to build the <a href="hymnstats.joeystanley.com">site</a> entirely in Quarto.</p>
<p>So, I’ve gradually built up to web development in R over the years and Quarto seems like the logical place to migrate to. Plus, it has some features that I’ve always wanted, like scrolling table of contents and a search feature. After some encouragement from folks on Twitter, I decided it’s time to bite the bullet and go for it.</p>
</section>
<section id="what-does-it-take-to-migrate" class="level2">
<h2 class="anchored" data-anchor-id="what-does-it-take-to-migrate">What does it take to migrate?</h2>
<p>I’m doing this page by page. Here’s the order I took:</p>
<ul>
<li>My homepage and any links on it. I didn’t clean up the linked pages, but at least there weren’t any dead links.</li>
<li>My blogs.</li>
</ul>
</section>
<section id="things-that-are-the-same" class="level2">
<h2 class="anchored" data-anchor-id="things-that-are-the-same">Things that are the same</h2>
<p>I’ve tried to keep as much of the original structure of the site the same as I could. However, as I migrate</p>
</section>
<section id="changes" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="changes">Changes</h2>
<p>Here’s a list of the changes I’ve made.</p>
<ul>
<li><p>Each blog is now in its own self-contained folder. The previous structure had all posts in a single folder and all images in another folder. This time, the images associated with a blog post are contained within that folder. So, instead of this:</p>
<pre><code>├──📁blog
|  ├──📄blog post 1.md
|  ├──📄blog post 2.md
├──📁images
|  ├──🌅image1.png
|  ├──🌅image2.png</code></pre>
<p>It’s now this:</p>
<pre><code>├──📁blog
|  ├──📁blog post 1
|  |  ├──  📄index.qmd
|  |  ├──  🌅image1.png
|  ├──📁blog post 2
|  |  ├──  📄index.qmd
|  |  ├──  🌅image2.png</code></pre>
<p>It shouldn’t affect any urls to existing blog posts because the url <code>blog/blog post 1</code> in the old format would go to the <code>blog post 1.md</code> file and in the new one it’ll go to the <code>blog post 1</code> directory, which’ll display <code>index.qmd</code> by default. I was concerned about changing the url because I know some people have cited my turorials in published work and I didn’t want those urls to break. I think this’ll work <em>and</em> it’ll keep the site better organized.</p></li>
</ul>


<div class="no-row-height column-margin column-container"><span class="">By the way, I’m stealing this way of visualizing file structure directly from <a href="https://github.com/tjmahr/quarto-blog/blob/main/posts/migrating-from-jekyll-to-quarto/index.qmd">TJ Mahr’s Migrating-to-Quarto page.</a>.</span></div></section>

 ]]></description>
  <category>Meta</category>
  <guid>https://new.joeystanley.com/blog/website-version-3/index.html</guid>
  <pubDate>Mon, 25 Sep 2023 04:12:00 GMT</pubDate>
</item>
<item>
  <title>Kohler Tapes</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/kohler-tapes/index.html</link>
  <description><![CDATA[ 




<p>So, I just acquired a goldmine of data that I can use for linguistic analysis. Sitting in my office are 452 cassette tapes, each containing at least 30 minutes of recorded interviews with an older folks from Heber City, Utah. And that’s about half of the collection: the other half is with a historian in Midway, Utah. So, I’m looking at roughly 400–500 hours of audio. Not sure how I’m going to process it all, but I wanted to kick off the beginning of this long-term project with a blog post describing the history of the tapes, why I’m interested in them, and speculations about the future.</p>
<p><img src="https://new.joeystanley.com/images/photos/kohler_tapes.png" width="85%"></p>
<center style="font-size: 75%;">
<p>(452 tapes sitting on my shelf!) <br> <br></p>
</center>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I first heard about the tapes a little over three years ago. In January 2018, the LSA annual meeting was in Salt Lake City. Wanting to take advantage of the trip out there, I applied for and received a grant from the University of Georgia to collect audio in Heber City, aiming for multiple generations within a family to track language change over time. I decided on Heber partly because it was a region of Utah that had never been the subject of acoustic (let alone linguistic) analysis, as far as I know. My parents were living there at the time too, so they could hook me up with some potential contacts.</p>
<p>So on the morning of the first day of my fieldwork,<span class="sidenote">Side note, it’s amazing that I heard about this goldmine <i>literally</i> through the first person I talked to while doing fieldwork? Who knew that there’d be such an amazing collection of audio sitting in someone’s basement nearby? In fact, there could be lots of collections like these, just collecting dust in people’s basements. All it takes is to find the right person!</span> the first thing I did was go to the Heber Valley Visitor’s Center as a way to potentially find some contacts. Literally the first person I talked to told me about a man who had a huge collection of tapes. One person led me to another, and I was talking to an elderly man named Norm Kohler in his nursing home.</p>
<p>Norm was a beloved middle school teacher in Heber City in the 1980s and 1990s. As a history project, he had each of his students get a cassette tape and interview a grandparent. I don’t know what the interview questions were, but I think they mostly concerned life in Heber Valley. He kept all the tapes his students turned in and, over the course of two decades, he ended up with over 1200 interviews! Norm intended to compile them and put together an oral history of the town, but unfortunately was unable to do so. So, just weeks before I met him, he decided it was best to return the tapes to the family members’ of his students and the people they interviewed. So he put an ad in the paper and hundreds of people claimed their tapes and were able to hear their ancestors’ voices, perhaps for the first time.</p>
<p>However, not all the tapes were claimed. I was told a few hundred remained. So, after Norm passed away a few months later, his family held on to them for a while before finally donating them to the Midway Historical Society. (Midway is the town next door to Heber.) Several complications made it difficult for me to get access to the tapes, including outdated contact information on Midway’s website, the society going on an extended hiatus, me living in Georgia, and then covid. But I did my best to reach out to anyone who might know about where the tapes were being stored.</p>
<p>Finally, on Thursday this week, I was contacted by the historian in custody of the tapes. She asked if I was still interested in them, and I most definitely am! So we had a nice chat about what my goals were for them and what the goals were for the Historical Society, and we think there’s mutual interest in getting them digitized and transcribed. So, the next day, yesterday, she happened to be in Provo so she dropped off about half of the tapes—452 of them!—at my office!</p>
<p>So after three years of following tenuous leads, I finally have the tapes!</p>
</section>
<section id="why-am-i-so-interested" class="level2">
<h2 class="anchored" data-anchor-id="why-am-i-so-interested">Why am I so interested?</h2>
<p>I am a linguist, so why should I care about these tapes? Well, the obvious reason is that it’s a <em>lot</em> of audio. For my dissertation I analyzed about 40 hours of interviews and that was already a lot of data. This is at least 10 times the amount of audio. In fact, it’s about the size of the <em>Digital Archive of Southern Speech</em>, a subset of the <em>Linguistic Atlas of the Gulf States</em>, that I spent four years in grad school analyzing. So having access to this much audio is absolutely incredible</p>
<p>But it’s not just the amount of audio. There are dozens of oral history projects even in Utah. This particular set is attractive for several reasons:</p>
<ol type="1">
<li><p>The nature of the homework assignment ensured good metadata. A few tapes have already been digitized and they all start off introducing the interviewer (the middle-schooler) and the interviewee, with information like the date of interview, their age, and where they grew up.</p></li>
<li><p>Because these were all students in the same smallish town in Utah<span class="sidenote">There were about 4500 people living in Heber in the 1980s and 1990s, which means this sample represents like a significant chunk of the community!</span> the sample will be relatively homogeneous geographically. While it doesn’t ensure that the interviewees (the grandparents) were from Heber or Heber Valley generally, my guess is that a significant number of them are.</p></li>
<li><p>Typically, interviews happen with a historian or someone that the interviewer is unfamiliar with. In sociolinguistics, it’s generally accepted that the degree of familiarity with the interviewer can have an influence on a person’s speech. In all cases with these tapes, the interviewer is a teenager and a grandchild of the interviewee. So that lowers the formality of the situation and will likely mean that the interviewees’ speech will be more casual.</p></li>
<li><p>Heber Valley has been the focus of very little acoustic research. There may be occasional interviews as parts of the Linguistic Atlas Project or the <em>Dictionary of Regional American English</em>, but no study, as far as I know, has focused on Heber. Instead, most research looks at people from Utah Valley and Salt Lake Valley. This collection of interviews will offer a new spot on the map of Utah dialectology and a nice point of comparison between more urban and more rural areas of the state.</p></li>
<li><p>I have virtually no metadata about the interviewees right now, but if their grandchildren were about 14 years old in the 1980s and 1990s, then the speakers in these tapes were born perhaps sometime between 1900 and 1940. There has been some research on the development of Utah English, mostly by David Bowie, but he acknowledges that it was based on public sermons given by upper-class white men. This collection offers a unique look into how other Utahns born around that time talked. And since I have some comparable data from contemporary Heber City residents, I can begin to look at language change in real time.</p></li>
</ol>
<p>So there are lots of reasons for why I’m really interested in this collection of tapes. And that’s on top of the oral history the Midway Historical Society wants to create based on them.</p>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>Luckily, I’ve had some experience working on a project of this size. For four years at the University of Georgia, I was a part of the team that processed the <a href="http://www.lap.uga.edu/Site/DASS.html"><em>Digital Archive of Southern Speech</em></a>, which is a 367-hour subset of the <em>Linguistic Atlas of the Gulf States</em>. So I’ve sat in on transcriber training sessions, seen what kinds of obstacles get in the way of processing, managed thousands of files, and analyzed spreadsheets with a couple million acoustic measurements in them. However, that was only as a graduate student. I’m sure there’s a lot that goes on behind the scenes as a PI that I didn’t see.</p>
<p><em>Transcribers</em>—Some back-of-the-envelope calculations suggest that I’ll need a sizable grant to get this all processed. Again, I don’t have definite numbers for anything, I know my 452 tapes are a little over half of them, so let’s say there are 700 tapes total. They’re all at least 30 minutes long and I know many went longer, so if I average say 40 minutes per tape, that’s 28,000 minutes or roughly 467 hours. I think the the transcribers for <em>DASS</em> averaged about 13 hours per 50 minutes of audio or so, but this audio is newer and I presume Utah transcribers will be more familiar with Utah speakers I think, so I’ll estimate 10 hours of work per tape. That’s 4670 hours of transcription. At $15 per hour, I’m looking at about $70,000 in student wages. Obviously, I can’t get that much coin internally so it sounds like this is only going to happen with an external grant.</p>
<p><em>Grad student workers</em>—That’s of course assuming that the only wages I’ll need to pay for are transcribers. This might be getting into “If you give a mouse a cookie” territory, but it would be nice to have some grad students helping out with the project. At UGA, we had at least four and as many as six grad students involved in the project at a time. There was a lot of overlap between our duties, but very roughly speaking, one managed the transcribers, one managed the spot-checks, one managed the acoustic analysis, and one did miscellaneous duties. We were all involved in analysis, and a few others popped in for a semester or two to do additional analysis or perform other duties. To lighten my load, it would be handy to have perhaps three grad students manage the transcribers, check their work, and do the acoustic analysis. I’m fuzzy on what costs are associated with RA-ships at BYU, but I do know it’ll add significantly to the total cost of the project.</p>
<p><em>Time</em>—How long will transcriptions take? I’ve done transcriptions and they’re soul-sucking work. Even when I was highly motivated to process my own dissertation data, that I collected myself, and under a bit of a time crunch, I could barely put in more than about two hours a day. I surely don’t expect undergraduate transcribers to do more than 10 hours a week. When motivated by money, I’ve seen some at UGA do more, but those students were exceptional. I’ll estimate five hours of work per transcriber per week. So under the assumption of 4670 hours of work total, that’s 934 transcriber-weeks. If a semester is fifteen weeks, that’s 62 transcriber-semesters. If I set a goal of getting all the work done in two years (six semesters if you include summers), it would take ten or eleven transcribers to do it in two years. Of course, these are all very rough estimates, but managing several tens of thousands of dollars and almost a dozen workers for two years is not something I expected to do right away!</p>
<p><em>Digitizing</em>—Regardless of the cost, number of workers, and time involved, the first step of the process will be digitization. Fortunately, it sounds like the Office of Digital Humanities can take care of that for me! Wow! So my short term goal is to get a batch—maybe 30 or 50 tapes—done first. While they work on digitizing the next batch, I can get started on listening to the first few minutes of the completed tapes and extracting whatever metadata I can from them. Eventually, all the tapes will be digitized and I can have a more concrete idea of how much audio (and consequently, people, time, hours, and money) I’m looking at.</p>
<p><em>Metadata</em>—After digitizing all of them, my next step will be to finish collecting the metadata. It’ll be nice to have a clear picture of birth years, genders, and birthplaces for all 700 or so people. The most likely scenario is that I <em>won’t</em> get an external grant because they’re extremely competitive, so I’ll have to prioritize which ones to transcribe first. The Historical Society would like to start with some of the prominent members of the community and descendants of the town’s founders. I’d like to find a balance of genders and birth years too, so we’ll probably settle on a subset that satisfies both of our needs. How big? I’m thinking between 35 and 70 (5% to 10% of the tapes). That’s a more reasonably-sized project that I could possibly get funded internally. It could provide me at least a beginning look at the speech community which would help seed an external grant.</p>
<p><em>Follow-up project?</em>—In case I just need more data to analyze (ha!) wouldn’t it be cool to track down some of the tapes that were given away? Presumably, if an ad in the paper is what it took for the families to get them, then an ad might be a good place to start to find them. We’d digitize the tapes right there for people, give them a copy and return the tape to them of course, but then also add that to the collection for the oral history. I think it would be especially cool to interview those people themselves! That way we can get some contemporary data to compare the tapes to, as well as track change within the family. That’ll have to wait until I get NSF grant number two!</p>
<p><em>Publications</em>—What’s the end goal? Well, I’ll obviously start cranking out some papers as soon as a reasonable amount of data has been processed. There is a <em>lot</em> going on in Utah English. Many of the stereotyped features are dying out, so these people may provide good acoustic data for what would otherwise be hard to study phonetically today. But there are also lots of other features that I believe are recent innovations, so if they’re infrequent or missing from these speakers, it’ll help establish the timing of when they did develop. Even before I had the tapes, I’ve been thinking a full analysis of this collection deserves a book-length treatment. It likely won’t get done before I’m up for tenure, but maybe it’ll go towards my application for full professor.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The history of the Kohler Tapes is pretty cool, and I’m lucky to be a part of the creation of an oral history of Heber City. It’s so satisfying teaming up with a historical society and finding ways to help the community I’m studying too. Linguistically, they’re interesting to me for lots of reasons, but I think everyone benefits from seeing these tapes get processed. As far as how I’m going to go about processing all of them, I really have no idea what I’m doing so there will be a lot of learning involved. But I’m excited to be involved and to have a clear research trajectory for the next decade or so!</p>


</section>

 ]]></description>
  <guid>https://new.joeystanley.com/blog/kohler-tapes/index.html</guid>
  <pubDate>Sat, 13 Feb 2021 21:16:00 GMT</pubDate>
</item>
<item>
  <title>Dissertation</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/dissertation/index.html</link>
  <description><![CDATA[ 




<p>I’m happy to report that I successfully defended my dissertation today! The <a href="../../downloads/191209-dissertation_defense.pdf">defense</a> was held in the DigiLab (300 Main Library). The study itself is called “Vowel Dynamics of the Elsewhere Shift: A sociophonetic analysis of English in Cowlitz County, Washington.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/dissertation/dissertation_defense.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Me with my committee: Chad Howe, Peggy Renwick, and Bill Kretzschmar (Skyping in).</figcaption>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>You can download my dissertation <a href="../../downloads/200417-dissertation-revised.pdf">here</a>!</p>
</div>
</div>
<p>The version linked above is a revision that I’ve made after correcting some small typos. Click <a href="https://search.proquest.com/docview/2412335574/398995AF274140D8PQ/1?accountid=4488">here</a> to view the official, submitted version.</p>



 ]]></description>
  <category>Dissertation</category>
  <category>Pacific Northwest</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/dissertation/index.html</guid>
  <pubDate>Wed, 04 Dec 2019 13:00:00 GMT</pubDate>
</item>
<item>
  <title>Brother Joseph</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/brother-joseph/index.html</link>
  <description><![CDATA[ 




<p>I had the fun opportunity to be a guest in a podcast today! <em><a href="http://faithpromotingrumors.com">Faith Promoting Rumors</a></em> is a new podcast that my brother and dad started that explores Mormon myths and culture. Having published on an interesting linguistic quirk about Mormon culture—the alternation between calling someone either as “Brother Jones” or as “Bob”—I was asked to talk about my research and about this convention in Mormon culture generally.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Listen to the interview <a href="http://faithpromotingrumors.com/12">here</a>!</p>
</div>
</div>
<section id="background" class="level2">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>There is a robust practice of using titles among Mormons. Kids and teenagers are expected to refer to all adults using the appropriate title (usually <em>Brother</em> or <em>Sister</em>, though in some cases <em>Elder</em>, <em>Bishop</em>, or <em>President</em>—see below), plus their last name. Adults reciprocate by calling minors by their first name, establishing a clear superiority between kids and adults, though this can be flouted for comedic, sarcastic, or reverential effects.</p>
<p>But between adults the rules are less straightforward. Sometimes adults use first name for each other and other times they use titles. Familiarity is the strongest factor but age and status within the congregation play a role as well. I had a hunch that things like situation, audience, family make up, and place in the social network had to do with it too. This is essentially the same as how some languages have their T-V distinction in pronouns. This is a classic sociolinguistic variable since it doesn’t appear to be a conscious decision by speakers and it’s an extremely common linguistic feature.</p>
<p>So what started off as a mild curiosity during Sunday meetings ended up being a term paper in both my sociolinguistics and social network analysis courses, two conference presentations, a spot in the 2016 <a href="http://repository.upenn.edu/pwpl/vol22/iss1/31/">Penn Working Papers in Linguistics</a>, and my first qualifying paper—I got a lot of mileage out of that study. I was just getting into quantitative methods, so it’s a little statistics-heavy, but I did find some interesting results.</p>
</section>
<section id="summary-of-the-study" class="level2">
<h2 class="anchored" data-anchor-id="summary-of-the-study">Summary of the Study</h2>
<p>Essentially, what I did to answer this question was give a survey out to members of my own congregation and ask them to indicate what they would call other members of the congregation in four different situations. I also asked them to tell me how well they knew each person.</p>
<p>As I mention in the podcast, some of the main findings are pretty intuitive. The better someone knows another person, the more likely they are to use their first name. There was more first name among people of the same sex, especially women. Holding all other variables constant, more peripheral members of the social network of the congregation generally use more titles and get called by titles more than the core members. There were some differences between the sexes and the situation: men use more titles for present company while women use more first name in face-to-face situations.</p>
<p>One thing I tested was whether southerners use more titles. It’s a pretty common stereotype that southerners are more polite and call people “Miss Betty” more often. It turns out this carries over into Mormon circles as well: southerners generally used titles slightly more than northerners or Utahns.</p>
<p>Surprisingly, age wasn’t a factor. I thought there would be a clear effect of increased usage of titles for older people, but this didn’t pan out. What did appear to be the case was that people roughly within a couple years of each other use more titles for each other, but this was more an effect of familiarity than anything else: people are friends with others their age so they use fewer titles.</p>
<p>One of the more interesting findings was that people who have children were called by their titles more than those that didn’t. I’ve heard anecdotes where unmarried people get titles far less often than married people their same age, and it seems like having kids moves a person up another step in the “adult” category. One of my conclusions was that it seems like a Mormon is truly considered an adult until they are married and have children. Interestingly, the number of kids didn’t matter, just whether someone <em>had</em> kids. This is explainable by the family-centered religion and culture that Mormons are a part of, and it seems to made manifest in how people address each other—at least in my Georgia congregation.</p>
</section>
<section id="titles-first-name" class="level2">
<h2 class="anchored" data-anchor-id="titles-first-name">Titles + First Name?</h2>
<p>The title of the episode, “Brother Joseph”, alludes to the practice that early church leaders had in calling people by a title and their <em>first</em> name. I don’t know exactly when the change from first to last name happened, but it appears to be sometime in the mid-to-late 1800s. It also might be that certain individuals had this special use of the title: Brother Brigham [Young], Brother Joseph [Smith], Brother John [Taylor], Brother George [Cannon], and Sister Eliza [Snow] were some of the top hits in the mid 1800s. Though Brother [John] Taylor and Brother [George] Cannon were also common in the corpus I looked through. There are a lot of unknowns about forms of address in the early days of Mormonism, but we try to look into it a little bit.</p>
</section>
<section id="other-titles" class="level2">
<h2 class="anchored" data-anchor-id="other-titles">Other Titles</h2>
<p>As we mention in the podcast, there are other titles too that you might hear occasionally. <em>Elder</em> is reserved for male full-time missionaries, whether they be the young guys you might see on the streets or for men in global leadership positions. Women who serve missions retain their generic title of <em>Sister</em>. What’s interesting about the women though is that in some languages this is a unique title: in Portuguese for example the title is <em>Síster</em> rather than the generic <em>Irmã</em> (‘sister’) that other women have.</p>
<p><em>President</em> is for leaders of specifically organized groups of men. This can apply to the president of the church, the leader of the greater local area (what we call “stakes”), or the group of 14–15-year old boys. This is a case when calling a 15-year-old boy “President Jones” is attested in certain circumstances. This title can also be used for the president’s assistants or “counselors”, though this applies more to the larger groups and is much less common at the local level.</p>
<p><em>Bishop</em> is for the presiding authority of a congregation. This title, as well as those for full-time missionaries, have a unique position syntactically: they can stand on their own. In other words, it’s perfectly acceptable to approach to missionaries and say “Hey, Sisters!” or to approach a bishop and say “Hey, Bishop” instead of “Hey, Bishop Jones.” <em>President</em> can be used sometimes in this way though it’s less common.</p>
</section>
<section id="conclusions" class="level2">
<h2 class="anchored" data-anchor-id="conclusions">Conclusions</h2>
<p>This is an interesting part of Mormonism, and in the podcast we discuss some of the cultural implications of it. Linguistically though I still think there’s a lot more to be said and I’d be curious to see other research on this.</p>


</section>

 ]]></description>
  <category>Side Projects</category>
  <guid>https://new.joeystanley.com/blog/brother-joseph/index.html</guid>
  <pubDate>Mon, 10 Apr 2017 19:42:00 GMT</pubDate>
</item>
<item>
  <title>Mount St. Helens and Vowels</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/mount-st-helens-and-vowels/index.html</link>
  <description><![CDATA[ 




<p>Today in our Linguistics Colloquium here at UGA, I got to present on some of my ongoing research on English in a smaller town in Washington. For the past few months I’ve mostly looked at vowel mergers and using lots of statistical tests to show some very subtle changes. Over the past week or so as I’ve prepared for this presentation, I’ve discovered something pretty awesome about my data. And it has to do with Mount St.&nbsp;Helens!</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/170407-Colloquium.pdf">here</a>!</p>
</div>
</div>
<p>In the presentation, I focus on a couple linguistic variables. The first is what linguists call /æg/-raising, which is where words like <em>bag</em>, <em>flag</em>, and <em>dragon</em> to sound more like <em>bayg</em>, <em>flayg</em>, or <em>draygon</em>. The other variable is what we call /o/-fronting and /o/-monophthongization, which is where vowel sounds in words like <em>go</em>, <em>snow</em>, or <em>show</em> sound kinda like they would in stereotypical “Minnesohhta”. These have been studied extensively by researchers in the West regarding Pacific Northwest English and surrounding regions. So, nothing new here.</p>
<p>But looking at the data in relation to speaker age, I noticed a striking pattern: there’s a clear difference between the speech of people born before 1970 and those born after. I mean really clear. In my sample, /æg/ raising virtually disappears after 1970, and /o/ is suddenly diphthongal. /o/ admittedly gradually fronts, so the 1970 date isn’t quite as drastic in that regard.</p>
<p>So what happened in 1970? Well, not much. But in 1980, Mount St.&nbsp;Helens erupted and seriously affected the logging-based economy of Longview. Up until then, it was easy to find work in the logging industry with only a high school degree, if that. And the salary was relatively good considering it was blue collar work. But when some of the mills started to close, there was a drastic change in the dynamics of the town. Now you need a college education to get a job and even then it’s not paying well.</p>
<p>So though nothing happened in 1970, those who were born around then were teenagers at the time of this change, and were the first affected by the lack of easy-to-get, high-paying jobs. This marks a paradigm shift in the culture of Longview, and I believe it had to do with the clear changes in the speech. In other words, I think Mount St.&nbsp;Helens played a role in linguistic change in Longview. (The title of the talk was “Volcanic Vocalic Changes”—a title I’m quite proud of!)</p>
<p>This is super exciting for me because up until now most of my work has been phonetic-based and focused on vowel mergers. This the first clearly sociolinguistic project I’ve done—something I’ve been meaning to do this whole time—and I think the results are cool. It’s uncharacteristically qualitative and the statistics don’t play a huge role, which is weird for me. I like this change and I hope I can do more with this research.</p>



 ]]></description>
  <category>Pacific Northwest</category>
  <category>Presentations</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/mount-st-helens-and-vowels/index.html</guid>
  <pubDate>Sat, 08 Apr 2017 15:15:00 GMT</pubDate>
</item>
<item>
  <title>SECOL 2017</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/secol2017/index.html</link>
  <description><![CDATA[ 




<p>I was unable to attend this year, but my colleagues presented two papers I was a part of at the 84th Southeastern Conference on Linguistics (<a href="http://conf2017.secol.org">SECOL84</a>) in Charleston, South Carolina.</p>
<p>The first presentation was with Bill Kretzschmar and Katie Kuiper and was called “Automated Large-Scale Phonetic Analysis: DASS” wherein we introduce the NSF-funded project—with Drs. Kretzschmar and Peggy Renwick as PIs—that I am involved in. A PDF of the slide show is are available <a href="../../downloads/170310-SECOL84a-slides.pdf">here</a>.</p>
<p>The second presentation was with Rachel Olsen, Mike Olsen, and Peggy Renwick and was called “Transcribing the Digital Archive of Southern Speech: Methods and Preliminary Analysis” wherein we talked about the nuts and bolts of how to get a project of this size running. A PDF of the slide show is available <a href="../../downloads/170310-SECOL84b-slides.pdf">here</a>.</p>
<p>This work is part of an ongoing project at the Linguistic Atlas Office at the University of Georgia. We have several hundred hours of recordings from the 1970s of speakers all across the South. We have around 40 undergraduate workers transcribing for us with another couple grad students (including myself) doing the less soul-sucking work. Eventually we’ll have all this data freely available online, but in the meantime we’re figuring out how to process such scratchy recordings and doing linguistic analysis on it. It’s been a lot of fun and I’m glad we were able to show others our work.</p>



 ]]></description>
  <category>Conferences</category>
  <category>Linguistic Atlas</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>Skills</category>
  <guid>https://new.joeystanley.com/blog/secol2017/index.html</guid>
  <pubDate>Thu, 09 Mar 2017 23:12:00 GMT</pubDate>
</item>
<item>
  <title>Updated mvnorm.etest() function</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/updated_mvnorm.etest-function/index.html</link>
  <description><![CDATA[ 




<div class="page-columns page-full"><p>In Levshina’s <em>How to do Linguistics with R</em>, the function <code>mvnorm.etest()</code> from the <code>energy</code> library is used. This runs what’s called the “E-statistic (Energy) Test of Multivariate Normality” which used to test whether multivariate data is normally distributed. This is important because it’s an assumption that should be met for several statistical tests like MANOVA and for testing statistical significance of a correlation. Well, the code from the book is broken.</p><div class="no-row-height column-margin column-container"><span class="">Levshina, Natalia. 2015. <a href="https://benjamins.com/sites/z.195/">How to do Linguistics with R: Data exploration and statistical analysis</a>. Amsterdam: John Benjamins Publishing Company.</span><span class="">Maria L. Rizzo and Gabor J. Szekely (2016). energy: E-Statistics: Multivariate Inference via the Energy of Data. R package version 1.7-0. <a href="https://cran.r-project.org/web/packages/energy/index.html">https://CRAN.R-project.org/package=energy</a></span></div></div>
<p>I looked into it and it turns out that the book was based on an older version of the <code>energy</code> package (&lt;1.7). But if you’ve updated the package since August 2016 to version 1.7 or later, the code breaks. What happened? Here’s the old code:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mvnorm.etest</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(x, y))</span></code></pre></div>
<p>While this worked with the old versions, in the newer versions this returns a <em>p</em>-value of “NA”. This function does some bootstrapping meaning it runs some function on the data over and over some number of times. In the old version of the package, the default was 999 replicates. In the new version there is no default, so you have to specify the number of replicates with the <code>R=999</code> argument:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mvnorm.etest</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(x, y), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">R=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">999</span>)</span></code></pre></div>
<p>You can of course change this number to whatever you want, but 999 was the default before so I figure it’s a good number to keep. Just thought you ought to know.</p>



 ]]></description>
  <category>Statistics</category>
  <category>R</category>
  <category>Skills</category>
  <guid>https://new.joeystanley.com/blog/updated_mvnorm.etest-function/index.html</guid>
  <pubDate>Tue, 28 Feb 2017 23:12:00 GMT</pubDate>
</item>
<item>
  <title>Website Version 2</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/website-version-2/index.html</link>
  <description><![CDATA[ 




<p>Today I finally rolled out a new version of my website! The previous version was great and was an excellent stepping stone into web design, but it was mostly borrowed code. Unsatisfied with some of the way it was designed, I decided to go ahead and just write a new site completely from scratch. It has taken about a month or so to get it going, but I think it’s a lot better than before.</p>
<section id="new-site" class="level2">
<h2 class="anchored" data-anchor-id="new-site">New Site?</h2>
<p>As I’ve mentioned <a href="../../blog/making-a-website-is-fun">previously</a>, I went through a course on <a href="http://lynda.com">Lynda.com</a>, called “Jekyll for Web Designers” that showed me the basics in how to get that website up. I was still in unfamiliar territory though as I navigated my way around CSS and HTML and any changes I wanted to make to the site were difficult to do. I liked the instructor for that course (James Willliamson) though, so when I looked up some of his other ones and saw that he did several others that would be relevant to me, I decided to go ahead an take them as well.</p>
<p>I first took his “CSS Core Concepts” where I learned all about CSS and how it works. At a whopping 9 hours long, I knew I was going to get a thorough treatment of CSS. Essentially I learned how to make things look the way I want on a webpage. I learned how to do anything I want to text like change the font, size, and color as well as add things like bold, italic, and small caps. I also learned how to add space around text or between elements on a webpage.</p>
<blockquote class="twitter-tweet blockquote" data-cards="hidden" data-lang="en">
<p lang="en" dir="ltr">
I learned about <a href="https://twitter.com/hashtag/Web?src=hash">#Web</a> on <a href="https://t.co/n13drggo1T">https://t.co/n13drggo1T</a>. I completed CSS: Core Concepts by <a href="https://twitter.com/jameswillweb"><span class="citation" data-cites="jameswillweb">@jameswillweb</span></a> <a href="https://t.co/at3VlMgyPD">https://t.co/at3VlMgyPD</a> via <a href="https://twitter.com/lynda"><span class="citation" data-cites="lynda">@lynda</span></a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/828293046538207234">February 5, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>When I finished that, I continued on to the next course called “CSS Page Layouts” which I’m pretty close to finishing. This is more about web design and how to get from a sketch book drawing of a webpage to the screen. Most of the time was in CSS still (as opposed to the HTML) but I learned how to position things on the webpage.</p>
<p>The layout of site I had before was simply copied from the last tutorial in the first course. Since I didn’t write the HTML or the CSS, I didn’t know exactly what was going on, so if I wanted to make changes it was really hard to do. Now that I’ve written this new site from scratch, I know exactly what’s going on in all the webpages and in CSS.</p>
<p>Of course, the sacrifice is that this new site isn’t quite as clean as the old one was. For example, I know it looks good on my Apple laptop in Safari, but I don’t know all the code I need to watch out for to make it fully compatible with other browsers, let alone other versions of other browsers. The site also doesn’t adapt to smaller screens like phones and tablets. I’m still working on that.</p>
</section>
<section id="so-whats-the-difference" class="level2">
<h2 class="anchored" data-anchor-id="so-whats-the-difference">So what’s the difference?</h2>
<p>I didn’t do any major changes to the overall structure or the general typographic details that I use in everything I do. The fonts are still Iowan Old Style and Avenir and the background is still “whitesmoke” (96% white, 4% black). The blue from before was, coincidentally, very similar to the blue I use in my power point slides, but not exactly, so I went ahead and changed it to <em>my</em> blue to match my slides.</p>
<p>Just to give you an idea of what the site looked like before, here are some screenshots. This first one is my home page from my old site:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/website-version-2/site_old_home.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Old site’s homepage</figcaption>
</figure>
</div>
<p>And this is my new home page:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/website-version-2/site_new_home.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">New site’s homepage</figcaption>
</figure>
</div>
<p>A couple layout changes. First, I’ve widened it from something like 70% of the screen to a standard 960 pixels. That gave me the option of keeping my ideal width at roughly 66 characters still while giving me room for a sidebar.</p>
<p>I changed the header as well. I felt like it was the weakest part of my page, and I didn’t like how it looked. I knew I wanted my social media links to be somewhere prominent, and of course the navigation links should be there too. But I wanted to include temporary links to recent presentations so people can download the slideshow if they visit my site, and those didn’t quite fit up there. And I didn’t have anywhere to put a photo.</p>
<p>One solution was to have the top just include my name and the navigation buttons, which are now more descriptive. A sidebar could then have my photo, social media, and temporary links to recent presentations. There was also room to put an excerpt of my most recent blog post too, which I figured out how to do dynamically, which is pretty cool.</p>
</section>
<section id="a-new-research-tab" class="level2">
<h2 class="anchored" data-anchor-id="a-new-research-tab">A new Research tab!</h2>
<p>I also added a Research tab. I’ve seen this on lots of other people’s pages and I thought I’d include one in my own. I guess I figured everyone would clearly see what my research was by skimming through my CV, but putting it in prose like that makes a lot more sense.</p>
<p>The layout was a blatant copy from the UGA DigiLab <a href="https://digi.uga.edu/projects/">projects tab</a>. I think adding images, even if they’re simple like mine, contribute a lot to the page.</p>
<p>Eventually, I’d like to create a separate page for each of these. There I’d go into more detail on my findings, put a list of publications, and have links to any relevant blog posts. I’ll get there eventually. For now, I’ll just make the the excerpts a little longer.</p>
</section>
<section id="blogi-mean-news" class="level2">
<h2 class="anchored" data-anchor-id="blogi-mean-news">Blog—I mean, “News”</h2>
<p>My blog is now relabeled “News” just because it sounds less, well, blog-like. Here’s the old one:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/website-version-2/site_old_blog.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Old site’s blog</figcaption>
</figure>
</div>
<p>And here’s the new one:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/website-version-2/site_new_blog.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">New site’s blog</figcaption>
</figure>
</div>
<p>I also redesigned the blog page itself. First off, I didn’t like that you could only see 4 at a time and that you’d have to scroll back to see older entries. I don’t like it that way. I’ve still got the code still there, but it’ll only create a second page once I’ve got 50 posts. I’ve got like 15 for now so I don’t think it’ll slow anyone down by loading this page.</p>
<p>The rest of the page was completely revamped. To be quite honest, I googled around for great examples of blog layouts and I found <a href="http://johnhenry.ie">this one</a>, which I copied quite a bit of. I think it works well for my site.</p>
<p>Another big thing I didn’t like about the old layout was that the “Archive” tab didn’t make sense as its own page and the label didn’t really make sense.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/website-version-2/site_old_tags.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Old site’s “archive” page</figcaption>
</figure>
</div>
<p>Instead, I moved it to a separate sidebar on the blog. That way it’s clear that the tags and the blog work together.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/website-version-2/site_new_tags.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">New site’s “tags” page</figcaption>
</figure>
</div>
<p>If I could change one thing on the main “news” page, it would be that sidebar though. Right now, if you click on a tag, it’ll take you to a page where it lists all the blog posts by category. I don’t like that separate page. I wanted to do something fancy like you click on a tab and a list of posts will expand down. Turns out I couldn’t do that without Java scripting and I don’t know how to do any of that. I also looked into just having pages for each category created on the spot, with blog excerpts instead of just the titles for that one category, but I couldn’t figure out how to do that.</p>
</section>
<section id="anything-else" class="level2">
<h2 class="anchored" data-anchor-id="anything-else">Anything else?</h2>
<p>Nope. That’s about it. My CV page has remained essentially the same. I added “Resources” and “Teaching” tabs, but those are blank for now. I’ll add content to them eventually. There are still a few layout things I need to work on, but I thought I’d launch the site anyway—imperfect as it is for now—because it’s a major improvement over the last one.</p>


</section>

 ]]></description>
  <category>CSS</category>
  <category>Skills</category>
  <category>Meta</category>
  <category>Github</category>
  <category>How-to Guides</category>
  <guid>https://new.joeystanley.com/blog/website-version-2/index.html</guid>
  <pubDate>Sun, 26 Feb 2017 21:29:00 GMT</pubDate>
</item>
<item>
  <title>Excel Workshop</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/excel_workshop/index.html</link>
  <description><![CDATA[ 




<p>Today I had the opportunity to give a workshop in the <a href="https://digi.uga.edu">DigiLab</a> in UGA’s main library. It was a packed with librarians and grad students from across campus. In just over an hour, I started with the absolute basics and showed more and more tricks that I think would help people with their research projects.</p>
<p>This was the first time I’ve ever given a presentation without powerpoint slides. As I was preparing though, it seemed silly to include detailed descriptions and screenshots when I could just switch over the Excel and show it live. I ended up putting together a handout instead, which had all of the information on it instead. The presentation (and handout) went through the following topics.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the handout <a href="../../downloads/170127-ExcelWorkshop.pdf">here</a>!</p>
</div>
</div>
<section id="the-basics" class="level2">
<h2 class="anchored" data-anchor-id="the-basics">The Basics</h2>
<p>I started off by explaining what the differences were between Microsoft Office 2016, 365, and Online. Essentially, Office 2016 is stand-alone software that you buy once and keep forever but doesn’t upgrade. Office 365 is a subscription service where you have the software as long as you subscribe to it, but it upgrades all the time. Office Online is a free cloud-based version. Through UGA, we can get Office 365 for free, and a heavily reduced priced Office 2016.</p>
<p>I then opened up Excel and covered the absolute basics. Data entry. Moving around the spreadsheet. Cell formatting. Borders. Text formats. I’m pretty sure everyone there knew this basic stuff, but I thought I’d cover it anyway because, you never know, there might be someone who’s never seen it before.</p>
<p>After that, into topics that make it easier to play around with your data. Search and replace, with some extras like matching the entire cell. I also covered sorting and filtering and showed that you can filter multiple columns to get a really specific subsets of your data.</p>
</section>
<section id="pivot-tables" class="level2">
<h2 class="anchored" data-anchor-id="pivot-tables">Pivot Tables</h2>
<p>This is where I wanted to spend the most time. Pivot tables are things that a lot of people had heard of (and from the show of hands, about half the people in the room), but for some reason—and I don’t say this to be all high and mighty—I have never met <em>anyone</em> who knows how to use them. I learned them in my Intro to Linguistic Computing class with Monte Shelley at BYU and have used them a <em>ton</em> since then, but I guess people just haven’t had the chance to learn about them.</p>
<p>Pivot tables are dang useful. They can summarize your data in tons of fancy ways. At the very basic level, you can at least see all the unique values in a particular column in your dataset, which is good for checking typos or for copying and pasting into lookup tables (see below). But when you add columns, you can then see how many row of your data frame there are that match the row and column. In the presentation we looked at come census data and saw how many people were from each city within that county. By adding columns, we could see how many men and women there were in each city. We could then add additional columns (like fabricated favorite color data) so that we could see how many men and women liked each color within that city.</p>
<p>There are different ways of viewing the data as well. Instead of the raw count, we looked at how to view the <em>proportion</em> of men to women there were in each town. We switched to a numerical data type (fabricated weight and height data), and were able to see the average weight and height for men and women in each city, as well as the tallest, shortest, heaviest, and lightest man and women in each town. I heard some audible <em>whoa</em>’s from people as I showed some of this stuff, which was great to hear.</p>
</section>
<section id="functions" class="level2">
<h2 class="anchored" data-anchor-id="functions">Functions</h2>
<p>I then looked at some Excel functions. We started with some basic math, but quickly went into some functions. I showed how some can just stand on their own, like <code>pi()</code>, <code>today()</code>, and <code>now()</code>. We looked at how to reference other cells in functions and how they update automatically. I showed how to create a sequential list of numbers using functions that reference each other. There are some functions like <code>year()</code>, <code>month()</code>, <code>weekday()</code>, and <code>datedif()</code> that work on dates and others like <code>concat()</code>, <code>upper()</code>, <code>lower()</code>, <code>left()</code>, and <code>right()</code> are for manipulating strings. Then there are some that make reference to ranges, like <code>sum()</code> and <code>average()</code>. I showed how the <code>concat()</code> function can be useful to string together last name and first name to create a “Last, First” column. I know there are much more complicated and useful functions than the ones I covered, but I didn’t want to intimidate anyone.</p>
<p>We then looked at some conditionals and how they work. As an example, I created a new column in the census data that essentially collapsed the birth state down to two: Washington or not Washington.</p>
</section>
<section id="lookup-tables" class="level2">
<h2 class="anchored" data-anchor-id="lookup-tables">Lookup Tables</h2>
<p>The <code>lookup()</code> function is one that I use all the time, and I wanted to make sure I covered it in the workshop. When preparing for the workshop, I looked at some other site and they all mention that <code>lookup()</code> is essential. What this function can do is basically link together multiple spreadsheets so it starts to act like a database. You set up a table that acts like a dictionary: alphabetic, unique values in one column, with paired information in another. You can then “lookup” some value in this table, and the function will return the information associated with it.</p>
<p>Why is this useful? I use it for two main purposes: a converter, and a collapser. I use it as a converter for things like turning ARPABET representations of vowels into IPA. In one column is the ARPABET pair of letters, and the other column are the IPA symbols. It’s perfect for that. I use it also to collapse data down to fewer categories. We did this in the workshop by collapsing the 50 states down to 4–5 regions. We used this lookup table to add a “region” column to the census data, and then made a pivot table with it. Pretty cool.</p>
<p>For the last part of this section, I showed how to handle the places where <code>lookup()</code> fails, like blank cells or cells not in the dictionary. For blanks, it returns an error, and you can overcome that by wrapping the <code>lookup()</code> function in <code>if(isblank())</code>. But for those pesky typos, <code>lookup()</code> returns the closest value, which I only discovered recently and was not happy with it. I didn’t have to demonstrate, but in the handout I show that if you do something like <code>=IF(COUNTIF(A1:A5,C2)&gt;0, LOOKUP(C2, A1:A5, B1:B5), "ERROR")</code> it’ll work great.</p>
</section>
<section id="visualizations" class="level2">
<h2 class="anchored" data-anchor-id="visualizations">Visualizations</h2>
<p>Next was how to do quick and dirty visualizations in Excel. I explained briefly (probably too briefly) that not all visualizations work for all kind of data, which I feel is important for people to know. I then showed how to make a bar chart, pie chart, line graph, and scatterplot. I of course used pivot tables to help summarize the data for visualization. I did say though that I don’t use Excel’s visualizations for anything because I find them ugly, not customizable enough, and not robust enough to handle what I want to do.</p>
</section>
<section id="bonus-tips-and-tricks" class="level2">
<h2 class="anchored" data-anchor-id="bonus-tips-and-tricks">Bonus Tips and Tricks</h2>
<p>In the last four minutes, I tried to cover some bonus little tips and tricks that I’ve picked up along the way. There are little things like anchoring and freezing/splitting the table. I did show conditional formatting because I use that all the time (my tables look a little psychedelic actually). In the handout I cover how to convert text-to-columns, which can be useful when importing data from somewhere else or for just splitting things up like “Last, First” into two columns. I covered paste special and how you can transpose, paste multiply, and overwriting functions.</p>
<p>It was a real whirlwind of a presentation but I think some people got a lot out of it. I don’t know if too many people walked away with any new skills per se, but at least people were exposed to what kinds of things Excel can do, and were given the resources (<em>i.e.</em> this handout) to learn how to do it themselves. I enjoyed giving the presentation, and even though I use R for most of my work nowadays, knowing the ins and outs of Excel sure is useful.</p>
</section>
<section id="downloads" class="level2">
<h2 class="anchored" data-anchor-id="downloads">Downloads</h2>
<p>Again, you can download this handout <a href="../../downloads/170127-ExcelWorkshop.pdf">here</a>. Feel free to also download the three datasets I used: the vowels for <a href="../../data/vowels_oneSpeaker.xlsx">one speaker</a> and the vowels subset of <a href="../../data/vowels_1.xlsx">larger dataset</a>, which both come from the <a href="http://www.lap.uga.edu">Linguistic Atlas of the Gulf States</a>, and the Cowlitz County <a href="../../data/cowlitzData.xlsx">1930 census data</a>, which I gathered myself. Please also visit the accompanying blog post on the <a href="https://digi.uga.edu/news/be-a-data-magician/">DigiLab website</a>.</p>


</section>

 ]]></description>
  <category>How-to Guides</category>
  <category>Presentations</category>
  <category>Skills</category>
  <guid>https://new.joeystanley.com/blog/excel_workshop/index.html</guid>
  <pubDate>Sat, 28 Jan 2017 00:12:00 GMT</pubDate>
</item>
<item>
  <title>Tweeting LSA2017</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/tweeting_LSA2017/index.html</link>
  <description><![CDATA[ 




<p>In addition to the awesome experiences I had overall at the LSA2017 conference (which you can read about <a href="../../blog/lsa2017">here</a>), I made an effort to be active on Twitter during the conference.</p>
<p>I’ve followed conferences in the past (such as LSA and NWAV last year) when I wasn’t able to attend them, and really enjoy them. I livetweeted the Linguistics Conference at the University of Georgia (LCUGA) in October, which was my first experience as a livetweeter, though I didn’t do much other than introduce who was presenting next. So this year, not only did I follow the twitter feed, but I also contributed as much as I could myself. Here are some of my more popular tweets:</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
For anyone at <a href="https://twitter.com/hashtag/LSA2017?src=hash">#LSA2017</a>, you should come to the first session of <a href="https://twitter.com/hashtag/ADS2017?src=hash">#ADS2017</a> ("Vowels, vowels, vowels") and hear me talk about Washington State!
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/817121851512160257">January 5, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This one got a surprising amount of traffic (over 800 people saw it on Twitter) for being self promotion, but it’s because the LSA account retweeted it. I don’t think they retweet everyone’s self-advertising tweets though, so I wonder why mine made the cut… Either way, I didn’t mind the advertising!</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
Thomas &amp; Kendall: “You can't get a full sociolinguistic picture of a community by looking at only one kind of variable.” <a href="https://twitter.com/hashtag/ADS2017?src=hash">#ADS2017</a> <a href="https://twitter.com/hashtag/LSA2017?src=hash">#LSA2017</a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/817467349540409344">January 6, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This one was one of many tweets during Erik Thomas and Tyler Kendall’s presentation, a direct quote from one of their last slides. It’s a really good quote overall and a lot of people seemed to like it.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-lang="en">
<p lang="en" dir="ltr">
Antieau: Double modals. One Utahn used “might usually would”. Nice! <a href="https://twitter.com/hashtag/ADS2017?src=hash">#ADS2017</a> <a href="https://twitter.com/hashtag/LSA2017?src=hash">#LSA2017</a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/817759261266677761">January 7, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This was one of many things that Lamont Antieau found in the <em>Linguistic Atlas of the Middle Rockies</em>. Having lived in Utah, most of his results were surprising to me, but this one was especially so. Apparently others thought so too.</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
<a href="https://twitter.com/BrentPWoo"><span class="citation" data-cites="BrentPWoo">@BrentPWoo</span></a>: "and/or" as a fully lexicalized coordinator with the union set of constraints of on "and" and "or." <a href="https://twitter.com/hashtag/lsa2017?src=hash">#lsa2017</a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/817777627314405377">January 7, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Brent Woo from the University of Washington is doing some really interesting research. We met when he presented at the Linguistics Conference at the University of Georgia in October. He must have some dedicated twitter followers though because anything I tweet at him gets a lot of traffic. I mean, his findings are pretty cool though.</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none" data-lang="en">
<p lang="en" dir="ltr">
Preston: “I grew up in a paint store so I have female-like familiarity with color, and it hasn’t costed me my masculinity.”<a href="https://twitter.com/hashtag/ADS2017?src=hash">#ADS2017</a> <a href="https://twitter.com/hashtag/LSA2017?src=hash">#LSA2017</a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/817834097888399360">January 7, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This was a random side comment Dennis Preston made after explaining the color scheme in is graphs. Instead of red, green, and blue or something, he used lavender, forest green, chartreuse, and a couple others. After explaining which colors represented which variable, he said that line. Even though it had a typo (hasn’t costed <em>me</em> my masculinity), a lot of people liked it. I mean, Dennis Preston seems like a pretty funny guy, so this was great.</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
After <a href="https://twitter.com/hashtag/LSA2017?src=hash">#LSA2017</a> I feel simultaneously intimidated, inspired, and exhausted. A clear sign that this was a fantastic conference.
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/818213558123134976">January 8, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>At the end of conferences, there’s a lot of “I’m so sad the conference is over” tweets. As I’ve mentioned above, I put as much as I could into the conference, and I did feel exhausted. I was intimidated because seeing what great stuff other grad students are doing I suddenly feel less employable. But I was inspired to do more and better research. This tweet succinctly summed up what my conference experience, and it looks like others felt the same way too.</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
This was my first time &amp; it took more multitasking than expected. I have a newfound respect for tweeters and I appreciate 'em even more now. <a href="https://t.co/1HgUFmHzvV">https://t.co/1HgUFmHzvV</a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/818244412417470464">January 8, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This was part of a small thread that was going. Basically, people were thanking all the livetweeters out there, and I got a mention. I thought I’d thank the other livetweeters as well, now that I know how hard it is.</p>
<p>All this tweeting paid off though because I think people are noticing me on twitter now, and I think I’m seen as “one of the live-tweeters”. Not a bad reputation to have. I’m about to get my hundredth follower, now that I’ve gotten about 10 more since this conference. (I got about 10 just by <em>following</em> NWAV and liking tweets, and another half dozen when I tweeted very basic things at the LCUGA conference.) My goal is for my followers to outnumber the people I follow, but I don’t know if that’ll happen anytime soon. I’m not very active on twitter outside of conferences, other than shameless self-promotion. Maybe I should get better at that.</p>
<p>If you’re interested in getting more into twitter, I’d recommend this guide:</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
<a href="https://twitter.com/joey_stan"><span class="citation" data-cites="joey_stan">@joey_stan</span></a> have you seen <a href="https://twitter.com/GretchenAMcC"><span class="citation" data-cites="GretchenAMcC">@GretchenAMcC</span></a>'s excellent guide? <a href="https://t.co/03AjgiGtuq">https://t.co/03AjgiGtuq</a>
</p>
— Rachael Tatman (<span class="citation" data-cites="rctatman">@rctatman</span>) <a href="https://twitter.com/rctatman/status/818254265974145024">January 9, 2017</a>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I enjoy being active on twitter for <a href="../../blog/the-importance-of-twitter">lots of reasons</a>, most of them completely selfish, but starting to get a small following is pretty exciting and it’s a fun group to be a part of.</p>



 ]]></description>
  <category>Conferences</category>
  <category>Twitter</category>
  <guid>https://new.joeystanley.com/blog/tweeting_LSA2017/index.html</guid>
  <pubDate>Sat, 14 Jan 2017 00:12:00 GMT</pubDate>
</item>
<item>
  <title>LSA2017</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/lsa2017/index.html</link>
  <description><![CDATA[ 




<p>Last weekend, I had the opportunity to present at the 2017 Annual Meeting of the American Dialect Society, as well as attend the other meetings of the Linguistic Society of America annual meeting in Austin, TX. There were a lot of really awesome things about the whole thing.</p>
<div class="page-columns page-full"><p>First off, I feel like I had a great experience giving <a href="../../downloads/170105-ADS-slides.pdf">my presentation</a>. I presented Thursday afternoon in the session called “Vowels, Vowels, Vowels” which was chaired by Erik Thomas, and saw other presentations by Charlie Farrington &amp; Tyler Kendall, Matthew Gordon, and Michol Hoffman. There were about 30 people in the room, and I could name about half of them. In fact, while summarizing previous research, I realized that half the people I cited were sitting right there. Afterwards, I had a lot of discussion and great feedback. I couldn’t have asked for a better experience.</p><div class="no-row-height column-margin column-container"><span class="">As part of the presentation, I showed <a href="../../downloads/170105-ADS-video.mov">this video</a>.</span></div></div>
<p>During the course of the next several days, I made a point to introduce myself to people. Networking is an important part of going to conferences, and I haven’t really taken that opportunity in the past. So I was able to meet several of the greats and tell them how much I enjoyed some of the things they’ve written. I also met some grad students that have similar interests as me. I feel a lot more connected to other researchers than I did before.</p>
<p>Going into this conference, I knew I wanted to give it everything I had. I got funding from UGA for the first time, both through the Linguistics Program and the Graduate School, and I wanted to make sure the money I received went to a good cause. The conference was busy, but I attended as many presentations as I could. In fact, I hardly had time to eat, and ended up only eating one meal a day during the four days. I actually lost four pounds attending this conference! I also stayed at an Airbnb for the first time, and I didn’t want to take the bus all the way to the apartment when I knew there were things to do at the conference. I ended up attending 35 presentations and visited about a dozen posters. It made for four very long and busy days, but they were extremely productive.</p>
<p>I also made an effort to be active on Twitter during the conference, but I have a separate blog post about that which you can read <a href="../../blog/tweeting_LSA2017">here</a>.</p>
<p>Overall, a fantastic experience. The best I could have hoped for, and the best conference I’ve been to.</p>



 ]]></description>
  <category>Pacific Northwest</category>
  <category>Conferences</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/lsa2017/index.html</guid>
  <pubDate>Wed, 11 Jan 2017 00:12:00 GMT</pubDate>
</item>
<item>
  <title>Interactive Guarani Dictionary</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/interactive-guarani-dictionary/index.html</link>
  <description><![CDATA[ 




<p>The semester is finishing up, and as usual, the most productive week for me is during finals. Not necessarily productive regarding school work or current research projects, but I always rediscover side projects and hobbies. This week I rekindled my interest in Guarani.</p>
<section id="brazil" class="level2">
<h2 class="anchored" data-anchor-id="brazil">Brazil</h2>
<p>I’ve been working on Guarani off and on since 2009. I was living in Campo Grande, Mato Grosso do Sul, Brazil, as a Mormon missionary at the time. Fairly regularly I would meet people that spoke this language called Guarani, and I had friend (a fellow missionary), who had some pedagogical materials that taught Spanish speakers Guarani. So I had to work through the Spanish (I had only been speaking Portuguese for 9 months or at that point), but I was able to decipher some of the basic Guarani morphology and grammar. A while later my dad sent me a copy of the Book of Mormon in Guarani and said I ought to learn what I could. So I sat there with the Guarani, Portuguese, and English translations and would try to figure out new words and morphology.</p>
<p>Again, I was a Mormon missionary at the time, so I didn’t have a lot of time to spent learning this language. I hadn’t begun studying linguistics yet, so I had no idea what a non-Indo-European language could possibly be like and there were a few things that had me stumped. I also didn’t have access to a computer, so I couldn’t keep track of notes and vocabulary very well. So every couple of weeks I’d sit there with a dozen sheets of paper spread all over my desk, trying in vain to keep things alphabetized as I added vocabulary and translations. My Brazilian buddies all thought I was insane for trying to learn this language, but I found it to be a LOT of fun.</p>
<p>One of the more frustrating things was that I wanted to see how a single word was used in other contexts. If I was looking through a sentence and there were three Guarani words I didn’t know, I often had no way of knowing which word corresponded with the meaning in the English sentence. If only I could control+F the book and find the Guarani words in other contexts and figure out the meaning.</p>
</section>
<section id="self-study" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="self-study">Self-study</h2>
<div class="page-columns page-full"><p>After I came back to the United States and went back to college at BYU, I found that there were some books written about Guarani grammar, but they were mostly older ones. I didn’t know it at the time, but a former Department Chair in the Department of Linguistics and English Language at BYU was Robert W. Blair, who published some Guarani pedagogical material. I found his <em>Guarani Basic Course</em> at the library as well as his student, Charles Graham’s, <em>Guarani Intermediate Course</em>, and did what I could going through those. There were some other more descriptive grammars of the language written in the mid 20th Century, and I even sat in on a Guarani course for a semester.</p><div class="no-row-height column-margin column-container"><span class="">Yes BYU offers a course in Guarani! The class was taught only every once in a while and was intended for Mormon missionaries who had spent time in Paraguay. The class was taught in Spanish (again—not a language I’ve studied) by a native Guarani speaker, and was intended to add some formal instruction to people already familiar with the language. I was overwhelmed with other courses so I couldn’t keep up for more than a few weeks.</span></div></div>
</section>
<section id="translation-program" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="translation-program">Translation Program</h2>
<p>I was in my last year at BYU. I was working as a programmer, creating eBooks for <a href="http://www.wordcruncher.com">WordCruncher</a> and had access to an HTML file of the Guarani Book of Mormon. I had taken a class in Perl already and had gotten pretty proficient through that job. I had also taken Mark Davies’ Corpus Linguistics course. So when I took an NLP course as the capstone to my minor in Linguistic Computing, I decided to write a Guarani translator.</p>
<div class="page-columns page-full"><p>The program worked pretty well and was exactly what I was dreaming of in Brazil. I had paired the Guarani and English text as a “parallel corpus”, meaning each line in one file corresponded to a translated line in the other. What the translator does is it takes an input string (say, <em>mba’apo</em>) and it displays all the Guarani sentences with that word with the English underneath it. Made it very handy to see how words (or parts of words) were used in other contexts.</p><div class="no-row-height column-margin column-container"><span class="">This corpus might actually be the largest Guarani-English parallel dictionary. It had 329K Guarani words when first wrote the translator, but it’s now up to 606K after adding some more translated church material. I’ve got another ≈250K to add to it, whenever I get the time. I could nearly double it even then if I get access to the Guarani Bible, though I don’t know if that’ll happen anytime soon. Granted, these are all translated texts from English, and are religious-based, obviously representing a <em>very</em> different style than naturally occurring, spoken Guarani.</span></div></div>
<p>What it then does it is look at all the words in both the English and Guarani sentences with the word, keeps track of their frequencies, then looks at the frequencies for all words in the entire corpus and compares the two. Words that have nothing to do with the translation will occur with roughly the same frequency in the matched sentences as they do in the full corpus. But words that correspond to the same meaning will occur relatively much more often in the matched sentences compared the corpus as a whole. So say the word <em>work</em> appears once every 1000 words in the whole corpus. If it suddenly appears once every 25 words in the matched words, statistically that’s a big difference, and odds are pretty good that <em>work</em> is a translation for <em>mba’apo</em> (and it is).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/interactive-guarani-dictionary/guarani_search.png" class="img-fluid figure-img" style="width:30em"></p>
<figcaption class="figure-caption">Guarani Search engine</figcaption>
</figure>
</div>
<p>So using this I could find out which English words correlated with which Guarani words. Not a perfect translator, especially since it didn’t use any fancy NLP processing, but not bad.</p>
<p>My interest in Guarani, which was mostly about its nasal harmony, verbal morphology, and trying to document the grammar as a whole, started to wane as I started grad school and focused more on sociolinguistics and dialectology. But my reading comprehension is still… okay let’s face it, not that great, but I’m surprised at how much I was able to learn through self-study and a custom computer program.</p>
</section>
<section id="interactive-dictionary" class="level2">
<h2 class="anchored" data-anchor-id="interactive-dictionary">Interactive Dictionary</h2>
<p>I think what started this recent resurgence in Guarani was, strangely enough, making this website. I’ve acquired some more HTML and CSS skills and realized that I could make something useful with a web browser. So I dusted off my old files and started something fun.</p>
<p>In just a week I was able to make a pretty useful website (locally hosted only for now) with two main pages. The first is the entire corpus. Unlike what I had before, I could take advantage of the formatting to display useful information. All the words I know are in regular black text, but the words I don’t know stand out in blue. That makes it easy to figure out which ones I need to learn next. For the words I do know, the roots are underlined, so I can quickly see the base and what morphology is stemming off of it. The interactive part is that if I mouseover the root, a basic definition shows up in the form of a tooltip. So if I’ve forgotten a word, I can very quickly remind myself of what it means. Very handy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/interactive-guarani-dictionary/guarani_corpus.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Guarani Corpus screenshot</figcaption>
</figure>
</div>
<p>How am I keeping track of what I know and don’t know? The other page on the site is a dictionary. I usually kept all this stuff in a spreadsheet somewhere, but here I can utilize the formatting to make it look like a real dictionary. I’ve got roots, possible word forms, derivatives, translations, parts of speech, etymology, other notes, and the infrastructure to include example sentences and other metadata. All this is stored on a file on my computer, and when I learn a new word, I just add it to the bottom of the file and a Perl script will take care of alphabetizing it and making sure it looks good for the CSS to take over.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/interactive-guarani-dictionary/guarani_dictionary.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Guarani Dictionary screenshot</figcaption>
</figure>
</div>
<p>The result is a slick system where I can quickly see what words I need to learn and I can easily add them to the dictionary. I then run a lightning fast Perl script and refresh my browser, and I’ve got an updated corpus and dictionary.</p>
<p>The system is set up to handle as big of a corpus or dictionary as I’m willing to feed it. For now, I’m only a couple paragraphs in and I’ve got over 100 entries in the dictionary. It will take hundreds of hours to go through my entire corpus. But for the first time I’ll be creating a decent Guarani dictionary, which is kinda what I had in mind to do the whole time.</p>


</section>

 ]]></description>
  <category>CSS</category>
  <category>Guarani</category>
  <category>Side Projects</category>
  <guid>https://new.joeystanley.com/blog/interactive-guarani-dictionary/index.html</guid>
  <pubDate>Sat, 10 Dec 2016 18:21:00 GMT</pubDate>
</item>
<item>
  <title>Brand Yourself</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/brand-yourself/index.html</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Go <a href="../../blog/brand-yourself-2">here</a> to see a more recent version of this talk.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><a href="../../downloads/170413-brand-yourself.pdf">Download the slides here!</a></p>
</div>
</div>
<p>Today <a href="http://emilymcginn.com">Emily McGinn</a> of the Digital Humanities Lab at UGA and I did a workshop called “Brand Yourself: A professionalization workshop for grad students” [Edit: and again by invitation April 13, 2017]. We gave a presentation on different ways grad students can boost their online presence through building a personal webpage, utilizing social media, and finding your field’s conversation. We then let the attendees a chance to work on their own to create a new online profile, using what they learned.</p>
<section id="social-media" class="level2">
<h2 class="anchored" data-anchor-id="social-media">Social Media</h2>
<p><a href="http://academia.edu">Academia.edu</a> is a social networking site for academics. Users can create profiles, upload their papers, and follow particular research topics. They can also follow others that have done the same. It’s a great resource for finding papers that may be behind a paywall, although it has gotten a lot of criticism for this. Papers you upload can be found by Google Scholar, which is a nice perk. The website will keep track of your analytics, and there’s nothing more thrilling than getting an email saying someone has found your profile!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/brand-yourself/academia_email.png" class="img-fluid figure-img" width="300"></p>
</figure>
</div>
<p>The site got some criticism for offering authors the chance to promote their work for a fee. There’s also a chance at any time the site could get shut down because publishers aren’t happy about it, but with 30 million users, I don’t know if that’s going to happen any time soon.</p>
<p>I’m less familiar with <a href="https://www.researchgate.net">ResearchGate</a>, but in my cursory look, there’s a lot of overlap with academia.edu as far as its features. A big difference I noticed is that it seems like it’s more focused on creating networks based on people you cite and your co-authors while academia.edu is more focused on following your field and your interests. One thing I don’t like about ResearchGate is that the number of emails it sends you is borderline spam. It invites me to follow other grad students at my university, but, no offense to the sciences, I’m not particularly concerned with what a microbiologist on the other side of campus is doing.</p>
<p>I would imagine most researchers use <a href="https://scholar.google.com">Google Scholar</a> regularly, but did you know you can create a profile for others to see? You can tell a researcher has done that when you see their name underlined in a search:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/brand-yourself/google_scholar.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>In this screenshot (<a href="https://scholar.google.com/scholar?hl=en&amp;q=American+English%3A+dialects+and+variation&amp;btnG=&amp;as_sdt=1%2C11&amp;as_sdtp=&amp;oq=">live link here</a>), you can see that Walt Wolfram, Natalie Schilling, Sali Tagliamonte have created their profiles, but Shanna Poplack and Penny Eckert have not. I’d like to see what else the last two researchers have written, but I can’t simply click on their names like I can with the first three. When you do click on their links, you can see the full profile including what else they have written and how many times each has been cited.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/brand-yourself/natalie_schilling.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>It does take a bit of work to get a full profile going, because Google’s data can be a bit messy, so you’ll have to add stuff in by hand. But I think the payoff is worth the effort.</p>
<p>There are a handful of other websites out there that can help you build an online presence. <a href="https://profiles.impactstory.org/about">Impact Story</a> is one that can keep track of how much of an impact you have on people by keeping track of when people cite, mention, read you and your work. For $10 a month, it might not be worth it for a grad student, but for a professor applying for tenure this might be.</p>
<p><a href="https://www.linkedin.com">LinkedIn</a> is one I should mention, but I don’t find it terribly useful for academics. It might be worth it to set up a low-maintenance page that gives a good view of you in a nutshell, just in case people look.</p>
</section>
<section id="building-a-personal-webpage" class="level2">
<h2 class="anchored" data-anchor-id="building-a-personal-webpage">Building a Personal Webpage</h2>
<p>Keeping track of all these profiles can be tedious. Do you need to update seven different profiles every time you present at a conference? Is it worth it to invest the time in these sites that don’t communicate with each other? One solution is to keep your top (or only!) three or four papers on the social media sites, but include links to a central page that has your full profile. For this reason, it’s nice to have a personal webpage.</p>
<p>The problem with personal webpages it that they come with a cost, either in money or skills (and sometimes both). You can set up a webpage through <a href="https://wordpress.com">Word Press</a>, <a href="http://www.wix.com">Wix.com</a>, or <a href="https://www.squarespace.com">Square Space</a>, which take little technical skill to get a professional page set up. These can be free, but you can get some extra features for $10 a month or more. To me, that’s a pretty penny to pay for a relatively simple webpage.</p>
<p>Another option, which is what I did for the previous version of this website, is to host the page on <a href="https://github.com">Github</a>. It’s free, but it takes a bit of skill. I’ve had to learn to use Jekyll, Markdown, and CSS, but through some help on <a href="http://programminghistorian.org/lessons/building-static-sites-with-jekyll-github-pages">ProgrammingHistorian.com</a> and <a href="https://www.lynda.com">Lynda.com</a>, <a href="../../blog/making-a-website-is-fun">I was able to get this site up</a>. The benefit of going this route is I have unlimited flexibility in how the site looks, and I really, really like that.</p>
<p>Either way, it’s probably worth it to set up a personal domain name. For as little as $1 a month, you can buy your own domain name (like <span style="white-space: nowrap;">www.joeystanley.com</span>), which looks much more professional than <span style="white-space: nowrap;">www.blogsplot.com/joeystanley</span> or <span style="white-space: nowrap;">www.github.com/joeystanley</span>.</p>
</section>
<section id="finding-your-conversation" class="level2">
<h2 class="anchored" data-anchor-id="finding-your-conversation">Finding Your Conversation</h2>
<p>The last thing we talked about in our workshop is to find where the big names in your field are having their online conversations. This sounds a little weird at first, but every field has some secret space where people are collaborating and sharing ideas informally as well as posting calls for papers, invitations for publications, and job openings. The problem is that where is space is is different for every field.</p>
<p>In some fields, these are a listserv. As far as I know, network analysis and Slavic languages each have a well-known listserv where all the conversation happens. If you’re not on that listserv, you’re out of the loop. Digital Humanities has a space on <a href="https://slack.com">Slack</a> where over 800 researchers get together and talk. For some fields, it might just be at coffee breaks during certain conferences. You may have to ask around established academics in your field to find that space.</p>
<p>One thing I will mention is that a lot of action happens on Twitter. I’ve covered this in more depth in <a href="../../blog/the-importance-of-twitter">an earlier blog post</a>, but basically a lot of good stuff can come out of following the right people and seeing just the right tweets.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Overall, I thought the workshop went very well. Most of the attendees did end up setting up some sort of profile: some did an academia.edu profile, some google scholar, and a few were ambitious and set up a github page. At the very least, I got this very webpage set up as a result of preparing for this workshop, and I learned a <em>lot</em> about all these other pages. It was a great feeling to see a dozen students directly benefiting from our presentation.</p>
<hr>
<p>You can download the old version slideshow we used for this presentation <a href="../../downloads/161111-DigiLab-slides.pdf">here</a>.</p>
<p>I am indebted to the <a href="http://blog.impactstory.org/category/impact-challenge/">Impact Challenge blog series</a>, with the <a href="http://blog.impactstory.org/research-impact-challenge-ebook/">accompanying 200+ page pdf</a>, from which I learned a lot about all this. I would highly recommend that you download it and take a look. Not only does it include much more than what I’ve mentioned here, including step-by-step how-to guides to getting these profiles set up, but also many more topics to get yourself more visible. Thanks, Impact Challenge.</p>


</section>

 ]]></description>
  <category>CSS</category>
  <category>Github</category>
  <category>How-to Guides</category>
  <category>Meta</category>
  <category>Presentations</category>
  <category>Twitter</category>
  <guid>https://new.joeystanley.com/blog/brand-yourself/index.html</guid>
  <pubDate>Sat, 12 Nov 2016 00:23:00 GMT</pubDate>
</item>
<item>
  <title>DiVar</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/divar/index.html</link>
  <description><![CDATA[ 




<p>I’m excited to announce I’ve been accepted to present at the first iteration of the Diversity and Variation in Language Conference (<a href="http://linguistics.emory.edu/home/conferences/divar1/index.html">DiVar1</a>), which will be held at Emory University in Atlanta February 10–11. I’m excited to hear that many of my colleagues at UGA have also been accepted, so it should be a fun day for us.</p>
<p>In a nutshell I’m showing that in word lists people pronounce <em>pull</em> and <em>pole</em> the same but <em>Mary</em> and <em>merry</em> different, but in a minimal pair task, <em>pull</em> and <em>pole</em> are separate while <em>Mary</em> and <em>merry</em> are the same. I spent the summer in Washington state, and I’m only looking at a little less than 3% of everything I recorded for this conference.</p>
<p>I’ll post a summary of the presentation and the slides once the conference is over. Stay tuned.</p>



 ]]></description>
  <category>Conferences</category>
  <category>Pacific Northwest</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/divar/index.html</guid>
  <pubDate>Fri, 04 Nov 2016 00:08:00 GMT</pubDate>
</item>
<item>
  <title>How I Implemented the Links in this Site</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/how-i-implemented-the-links-in-this-site/index.html</link>
  <description><![CDATA[ 




<p>A while ago I stumbled across <a href="http://practicaltypography.com">Butterick’s Practical Typography</a>. I’ve never been <em>that</em> into typography, but I do make sure my documents look good. I’ve yet to implement good typography into this website, but I did find a neat trick that I was able to pull off.</p>
<p>Hyperlinks traditionally are in blue and underlined. It’s been the standard for so long now that we’ve gotten used to it and don’t notice how bad it looks. In Butterick’s book though he has linked text the same color and style as the rest of the page, but there’s a little red circle after it, as if it was a link to a footnote or something. It’s a pretty clever way to soften the look, but still get the point across that that particular text is a link.</p>
<p>I like to write stuff with links everywhere. I figure it might save people a google search if I just do it for them. On my CV, I link readers to the PDF and other documents, my co-authors’ pages, and other pages that might be useful. The result though makes it look like Wikipedia, unless I can find a way to soften how links look.</p>
<p>Thanks to some CSS skills I’ve been learning from Lynda.com, I’ve found out that I can add those little red circles by adding this to my <code>.css</code> file:</p>
<pre><code>a[href*="http"] {
    color: black;
}
a[href*="http"]:after {
    content: 'º';
    color: darkred;
}</code></pre>
<p>What the first block does is it targets just the <code>&lt;a&gt;</code> tags that contain an <code>href</code>, meaning they’re an external link, and it changes the color to black, overwriting the default blue. From there, the <code>:after</code> selector in the next block puts specific text, the little circle, after the hyperlinked text in the tag every time. I may need to change some things later to make sure it does exactly what I want on all the pages, but it works for now.</p>
<p>I don’t know if I’ll keep it the way it is, but it does look a lot better than tons of blue underlined text.</p>



 ]]></description>
  <category>CSS</category>
  <category>How-to Guides</category>
  <category>Meta</category>
  <guid>https://new.joeystanley.com/blog/how-i-implemented-the-links-in-this-site/index.html</guid>
  <pubDate>Tue, 01 Nov 2016 22:53:00 GMT</pubDate>
</item>
<item>
  <title>The Importance of Twitter</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/the-importance-of-twitter/index.html</link>
  <description><![CDATA[ 




<p>I’m preparing a workshop right now for the DigiLab here at UGA on how to increase your web presence. I’ll give a more detailed explanation of that later on, but I just wanted to point how how cool Twitter has been for me.</p>
<p>I don’t remember when or why I got a Twitter account, but I remember early on that I wanted to keep it professional. I don’t follow very many friends or family: just other random linguists I find. That means my feed is nothing but linguistics stuff, and mini posts that other linguists find interesting. Granted, a lot of these folks post non-linguistic stuff as well, so I do have to sift through those sometimes. But there have been some really valuable gems I’ve found because of Twitter.</p>
<section id="fun-stuff" class="level2">
<h2 class="anchored" data-anchor-id="fun-stuff">Fun Stuff</h2>
<p>First, we’ll start with the fun stuff.</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
</p><p>Check out <a href="https://twitter.com/JWGrieve"><span class="citation" data-cites="JWGrieve">@JWGrieve</span></a>’s wordmapper app (before it gets overwhelmed by traffic!) – plots Twitter usage across U.S.: <a href="https://t.co/9nBh3h9z9v">https://t.co/9nBh3h9z9v</a></p>
<p></p>
<p>— Ben Zimmer (<span class="citation" data-cites="bgzimmer">@bgzimmer</span>) <a href="https://twitter.com/bgzimmer/status/693113133632720896">January 29, 2016</a></p>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>This didn’t lead to anything in my work, but it was pretty awesome to see what Jack Grieve had done. In case the link doesn’t load above, it shows an interactive program where you can type in a word and see its regional distribution across Twitter. It’s a lot of fun to play around with.</p>
</section>
<section id="datasets" class="level2">
<h2 class="anchored" data-anchor-id="datasets">Datasets</h2>
<p>Twitter has also been good for me to discover new datasets. This tweet for example let me know that the entire contents of Reddit had been extracted and were available for download.</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
</p><p>1 terabyte corpus of Reddit comments, up to may 2015, from <a href="https://twitter.com/internetarchive"><span class="citation" data-cites="internetarchive">@internetarchive</span></a>. What a glorious day <a href="http://t.co/cHtmhKZyHW">http://t.co/cHtmhKZyHW</a></p>
<p></p>
<p>— heather froehlich (<span class="citation" data-cites="heatherfro">@heatherfro</span>) <a href="https://twitter.com/heatherfro/status/619123195115868160">July 9, 2015</a></p>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>About a month or so later I was starting a course in Digital Humanities, so this corpus became the main tool for my term paper for that class. I ended up downloading all the Reddit comments from its inception (2007) until October 2015. It was a whopping 50 <em>billion</em> words of text sitting on a terabyte of storage. If this were printed on standard book-sized sheets of paper, it would be something like 2½ miles long! And growing at about 4 feet an hour. That’s a lot of data. I don’t have a terabyte of storage available for something like this, so I wrote a Perl script that cut it down to a hundredth of its original size (“only” 500 million words!).</p>
<p>I ended up having to download it all using lab computers in the student center off and on for a week. In fact, I had four computers going simultaneously, all downloading Reddit files, one month at a time, and running Perl scripts to make them smaller. I wasn’t surprised when IT came over and wondered what the heck I was doing. Turns out it was the fact that my login was used on four computers that triggered their systems, not the fact that I was running four computers at full speed for a couple hours. Once they saw what I was doing they shrugged their shoulders and said it was totally fine.</p>
<p>Handling this much data, even though it was a hundredth of the original size, was rough. I made a frequency list of all the words, which ended up being about half a million rows long. I wanted to track language across time so I had information about how often each word was used every month for about 100 months. That’s a lot of columns for all those rows. I pushed Excel (and my little laptop) to its limits.</p>
<p>Anyway, this project turned into a fun term paper that I never published. I wanted to look at the language of the most upvoted comments as compared to all other comments and see if there were any differences. I found a few, but with biggish data like this, statistical significance is everywhere so you have to be more careful about things.</p>
<p>Bottom line: Because of Twitter I got to work with an enormous corpus which was a lot of fun.</p>
</section>
<section id="new-methodology" class="level2">
<h2 class="anchored" data-anchor-id="new-methodology">New Methodology</h2>
<p>On Twitter people also post new things they see at conferences and other places. During NWAV44, I followed the live tweets and saw this gem:</p>
<blockquote class="twitter-tweet blockquote" data-lang="en">
<p lang="en" dir="ltr">
</p><p><span class="citation" data-cites="wgi_02445_temp">@wgi_02445_temp</span> has given us another gift. Bhattacharyya’s affinity to measure overlap: <a href="https://t.co/26byi2KpRk">https://t.co/26byi2KpRk</a> <a href="https://twitter.com/hashtag/NWAV44?src=hash">#NWAV44</a></p>
<p></p>
<p>— Paul De Decker (<span class="citation" data-cites="pmdedecker">@pmdedecker</span>) <a href="https://twitter.com/pmdedecker/status/658290609153843200">October 25, 2015</a></p>
</blockquote>
<script async="" src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Basically, Daniel Johnson talked about another way to measure vowel overlap—something I do a lot in my research. In the Shiny App linked above, Johnson compares Pillai scores and something called Bhattacharyya affinity. I ended up using this in a <a href="../../downloads/160714-LabPhon15-poster.pdf">poster</a> (abstract <a href="../../downloads/160714-LabPhon15-abstract.pdf">here</a>) I did with <a href="http://faculty.franklin.uga.edu/mrenwick/">Peggy Renwick</a> at <a href="http://labphon.org/labphon15/program">LabPhon</a>, and will continue to use this new measure of overlap, not exclusively, but in addition to the other measures out there.</p>
</section>
<section id="live-tweeting-conferences" class="level2">
<h2 class="anchored" data-anchor-id="live-tweeting-conferences">Live Tweeting Conferences</h2>
<p>I’m a lowly grad student and don’t have a ton of funding for conferences, so I can’t attend some of the big ones all the time. Luckily, a lot of people live tweet what’s going on at most major conferences, so I can follow along and feel like a part of the group.</p>
<p>I myself live tweeted for the first time at a linguistics conference here at UGA. I don’t have a ton of followers, and the conference isn’t super well-known. But I did try to find people’s Twitter handles whenever possible, as well as their department’s, and would include them in the tweets. Well as it turns out I got about half a dozen new followers from that conference. Not a huge deal, but it does spread my name just a little bit further, and maybe onto the right person’s computer screen.</p>
</section>
<section id="twitter-is-great" class="level2">
<h2 class="anchored" data-anchor-id="twitter-is-great">Twitter is great</h2>
<p>So in the end, having a Twitter account is a lot of fun. I’ve benefited personally and professionally, and it’s definitely a worthy investment of my time.</p>


</section>

 ]]></description>
  <category>How-to Guides</category>
  <category>Methods</category>
  <category>Research</category>
  <category>Twitter</category>
  <guid>https://new.joeystanley.com/blog/the-importance-of-twitter/index.html</guid>
  <pubDate>Mon, 31 Oct 2016 23:00:00 GMT</pubDate>
</item>
<item>
  <title>Making a website is fun!</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/making-a-website-is-fun/index.html</link>
  <description><![CDATA[ 




<p>In the past month or so I’ve been putting a lot of time and effort into increasing my professional web presence. In about a year I’ll be applying for academic positions, and it would sure be nice to be more visible to my potential employers. The sheer fact that you’re reading this means you’ve seen some of the fruits of my labor.</p>
<section id="why-now" class="level2">
<h2 class="anchored" data-anchor-id="why-now">Why now?</h2>
<p>It took me a while before I wanted to find out what area of linguistics I wanted to go into. I’ve been interested in a lot of things at one time or another: typology, documentation, indigenous languages of South America, language change, simulation, morphology, network analysis, forms of address, among other things. I’ve even gone to conferences presenting some of this research. But I knew at the time that whatever it was that I was presenting on wasn’t going to be what I wanted to be known for. So I didn’t bother networking with other people, and I hardly took people’s advice because I would brush this off and say it was just a glorified term paper.</p>
<p>But I’ve found my niche. I’m interested in sociolinguistics, dialectology, phonetics, phonology, and using computer and statistics to help me out. This is something I’d like to be known for. Right now I’m working on English in the Pacific Northwest, and I’m familiar with a lot of the work that’s been done in that area, so I know who to talk to at conferences because I’ve read a lot of their work.</p>
</section>
<section id="github" class="level2">
<h2 class="anchored" data-anchor-id="github">Github</h2>
<p>Over the past five years or so in my undergrad and graduate education, I’ve acquired some computer skills. I minored in linguistic computing, so I learned Perl and C# as a part of the required coursework. More importantly though, I learned that learning to use computers is pretty darn useful for my research. So I’ve learned a few other skills along the way to help me out with my larger linguistics questions.</p>
<p>Just this month I presented a paper on Quechua morphology. I mentioned in it that I wrote a computer script to help me out with generating the correct forms of the paradigm. One of the participants in the Q&amp;A session asked if the code was available on Github and I said it wasn’t. But why shouldn’t it be? That acted as a catalyst into getting a github profile and uploading some code. I also found out I could host a webpage (this webpage!) on there too. Well sweet.</p>
</section>
<section id="creating-the-webpage" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="creating-the-webpage">Creating the webpage</h2>
<p>Having never done web design before, I had a lot to learn. Turns out you’ve gotta host the webpage somewhere. By that I mean that all the files and formatting and content and stuff in a webpage has to be stored on some computer somewhere. It can’t be mine, because I’ve set it up as a server and stuff and that’s way beyond me expertise—plus I’m pretty sure I don’t want to have my laptop as a web server. So luckily, Github, will host mine for free. Okay good.</p>
<p>The next task was to figure out how. I had recently heard about a website called <a href="http://programminghistorian.org">The Programming Historian</a>, which has a lot of slick, easy-to-follow tutorials on how to do useful computer stuff for research. Well, one of their pages is called “<a href="http://programminghistorian.org/lessons/building-static-sites-with-jekyll-github-pages">Building a static website with Jekyll and GitHub Pages</a>”. Awesome. Now, to be clear, it wasn’t the easiest tutorial. You have to download all sorts of stuff to your computer using the command line and manage a bunch of files and stuff. But that’s fine. I got it. I was able to create a simple webpage.</p>
<div class="page-columns page-full"><p>Well, I’m never really satisfied with the default design of things, and I like having unlimited flexibility in how things look. So, I went over to <a href="http://lynda.com">Lynda.com</a>, which I have access to through UGA, and took a more detailed course on how to build a webpage using Jekyll. And it was great. I learned a lot and figured out what a lot of stuff means.</p><div class="no-row-height column-margin column-container"><span class="">Edit: Looks like the “Jekyll Web Design” course is no longer available. Makes sense; it was from 2016!</span></div></div>
<div class="page-columns page-full"><p>But, I’m still not satisfied with the way it looks. I learned how the website works in that course, but not a lot of formatting. So I’m currently taking another Lynda.com , which I think will help me a lot. As it turns out, the concepts are very similar to the job I did as an undergrad, where I essentially created eBooks for a program called <a href="http://wordcruncher.com">WordCruncher</a>.</p><div class="no-row-height column-margin column-container"><span class="">Looks like this one is missing too. It was called CSS Core Concepts. I wish I knew who the instructor was.</span></div></div>
<div class="page-columns page-full"><p>My goal in all this is to be able to make a beautiful webpage that is uniquely mine. I want all the flexibility I could ever want in how it works and looks. By so doing, I’m learning a lot of new skills like CSS, but that’s perfectly okay with me. So, today the webpage is still a hack off of the tutorial I went through, but hopefully over the course of the next few weeks and months it’ll slowly transform into my own.</p><div class="no-row-height column-margin column-container"><span class="">Now that I’ve switched to Quarto, I’ve lost much of that uniqueness and flexibility.</span></div></div>
<p>I guess the end goal of this is to wow potential employers still. But, let’s be honest, I’m sure enjoying the journey.</p>


</section>

 ]]></description>
  <category>CSS</category>
  <category>Github</category>
  <category>How-to Guides</category>
  <category>Meta</category>
  <guid>https://new.joeystanley.com/blog/making-a-website-is-fun/index.html</guid>
  <pubDate>Tue, 18 Oct 2016 17:34:00 GMT</pubDate>
</item>
<item>
  <title>Reviewer Feedback</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/reviewer-feedback/index.html</link>
  <description><![CDATA[ 




<p>Yesterday I got the reviewer feedback for the <a href="../../blog/ads-meeting">paper I’m going to be presenting</a> at the American Dialect Society in January.</p>
<p>This is not the first time I’ve gotten reviewer feedback: I’ve submitted several things to big enough conferences where reviewers give their feedback. But they’re usually something like, “Okay yeah that’s cool and all, but here are some obvious things you should consider. I’ll reluctantly give you a pass, but I expect major changes at the conference.” Either that, or they’re brutally honest and say it’s garbage.</p>
<p>I’m grateful for the feedback every time because it’s completely spot-on, and reading an uncomfortable email alone at my desk is merciful compared to what I might potentially hear at conferences. Or worse, what I might <em>not</em> hear but what people think.</p>
<p>But, I’m happy to report I had three glowing reviews this time! On top of that, I was offered advice on some studies to look up and some ways to strengthen my argument. Maybe this <em>is</em> an interesting topic after all!</p>



 ]]></description>
  <category>Conferences</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/reviewer-feedback/index.html</guid>
  <pubDate>Fri, 07 Oct 2016 17:34:00 GMT</pubDate>
</item>
<item>
  <title>JMP</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/jmp/index.html</link>
  <description><![CDATA[ 




<p>As a part of my assistantship this year, I get to work with the DigiLab in the Main Library at UGA. It’s a fun little gig where I get to do presentations, workshops, and seminars on digital humanities, in addition to helping researchers one-on-one on their own projects.</p>
<p>I’ve always been fairly tech savvy in my research. I minored in Linguistic Computing and had a job as an undergrad creating eBooks. I’ve always been fairly quantitative about things too, and I went over to the stats department last year and took classes on linear regression and multivariate analysis.</p>
<p>This week is my first presentation where I’ll show how to extract data from primary sources, introduce people to spreadsheets, and showcase <a href="https://www.jmp.com/en_us/home.html">JMP</a> If you’ve never heard of it, JMP (pronounced “jump”) is a pretty sophisticated piece of statistical software that can do all sorts of statistical analyses and visualizations. The great part is it’s drag-and-drop interface. No coding means it’s great for beginners.</p>
<p>I’ll be the first to admit that JMPs visualizations (at least as well as I can make them) are not as good as what I can do with ggplot2 in R. But I do like how easy it is to make quick and dirty visualizations in JMP. For this reason, it’s usually my go-to when exploring a new dataset. With just a few clicks, it makes it really easy to get to know your data visually as well as what’s under the hood.</p>
<p>As far as I know, JMP is not widely used in Linguistics or even in the Humanities, so showcasing it will be a lot of fun to people this week. I still think that everyone should learn R for their research, but since coding can be intimidating, JMP is a great tool for researchers wanting to get more quantitative about their projects.</p>
<p>Update (October 7): I just finished the presentation. I had about a dozen people in attendance, and I was the youngest person in the room. And besides the one other grad student there, I was probably the only one without a Ph.D.&nbsp;But, I feel like it went well. Not to mention, it was the first time I was introduced before a presentation, <em>and</em> there was food!</p>



 ]]></description>
  <category>Data Viz</category>
  <category>Presentations</category>
  <category>Skills</category>
  <category>Statistics</category>
  <guid>https://new.joeystanley.com/blog/jmp/index.html</guid>
  <pubDate>Tue, 04 Oct 2016 09:31:00 GMT</pubDate>
</item>
<item>
  <title>The Linguistic Atlas of the Pacific Northwest</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/linguistic-atlas-of-the-pacific-northwest/index.html</link>
  <description><![CDATA[ 




<p>As a part of my research assistantship this year, I work with the <a href="http://lap.uga.edu">Linguistic Atlas Project</a>, under the direction of Dr.&nbsp;William Kretzschmar. It’s an exciting project to be a part of.</p>
<p>There is a lot going on in the lab right now. We’ve got a team of over a dozen undergrad transcribers working dutifully on an NSF grant awarded to Kretzschmar and Dr.&nbsp;Peggy Renwick, not to mention the web developers for the Atlas Project and for Complex Systems.</p>
<p>One of the things I’m excited about is that I now have access to all the data for the Atlas Projects from over half a century ago. In a nutshell, what happened is that in the 30s and through the 50s and 60s, Hans Kurath and a team of researchers set out to document the language geography of the United States and Canada. Armed with whatever recording devices they could afford, several hours’ worth of interview questions, and expert phonetic transcribers, they set out to document all the accents and dialects of English in North America.</p>
<p>They were partially successful. Starting in New England and in the East, they talked to a couple thousand people, painstakingly analyzed the data, and published a couple multi-volume works specifically focused on certain areas of the United States. Thus, we have the Linguistic Atlases of New England (LANE), the Gulf States (LAGS), and the Upper Midwest (LAUM). However, funding was cut short. Realizing they may have bitten off more than they can chew, the data collected in other portions of the country was never published, other than some brief overviews by some of the researchers. Time passed, and for one reason or another, the majority of this unpublished data disappeared into obscurity.</p>
<p>By the late 1970s and into the 1980s, the original handwritten field notes and any extant recordings were scattered across multiple locations. The original researchers’ dream to publish this data for a general audience was never fulfilled, let alone the majority of potential publications for a more specialized audience. The data was always supposed to be accessible to anyone interested, and just a few decades later it was collecting dust in basements, accessible to probably the half a dozen people that knew about it.</p>
<p>In 1983 some of the data was under threat of being thrown out. Luckily, William Kretzschmar offered to take all the data from all projects and house it at the University of Georgia. Since then, he has been in the process of realizing the original researchers’ dream of making the data accessible. In the 21st century, that means digitizing it all and putting it online. And there has been success in that endeavor.</p>
<p>This is where I come in. As a lowly out-of-state grad student, I’m not particularly concerned with language around Georgia, as interesting as it is. I do however like research on the opposite side of the country: the Pacific Northwest. Only after reading about the <em>Linguistic Atlas of the Pacific Northwest</em> (LAPNW) did I realize that all that data was being housed by my own university. So as soon as I was offered the assistantship in the Linguistic Atlas office, I expressed interest in the LAPNW data. Well, just today, I made a visit to the repository where all the data is held.</p>
<p>After sitting alone for half an hour on the concrete floor literally in the furthest corner in that warehouse, I was quickly able to assess the situation. From what I’ve been able to tell, there are just four boxes of LAPNW data. Compared to the dozens of boxes in the large-scale projects (LANE, LAGS, etc.), it’s a meager project. One box contains the original handwritten notes for about half of the 51 participants, which is great, but I’m a little sad that some of the originals have been lost. But the other three boxes were all copies, including a complete set for all participants and another partial set. I don’t know who did the photocopies or when they were done, but I’m really glad we have them.</p>
<p>So, I brought them back to the office and I’ve started to look through them. It’s a bit exciting for me actually. Since being housed at UGA, I don’t know if these boxes have been opened by <em>anyone</em>. As far as I know, there are probably ten people in the world that would be interested in the LAPNW data, and certainly none of them have had the ability to peruse UGA’s repository. So this stuff literally hasn’t seen the light of day for decades. I don’t know what I’m going to do with this goldmine, but I’d sure like to revive it somehow and possibly do what I can to make it accessible. It’s an exciting time for me.</p>



 ]]></description>
  <category>Linguistic Atlas</category>
  <category>Pacific Northwest</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/linguistic-atlas-of-the-pacific-northwest/index.html</guid>
  <pubDate>Fri, 30 Sep 2016 20:23:00 GMT</pubDate>
</item>
</channel>
</rss>
