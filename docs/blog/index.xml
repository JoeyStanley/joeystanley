<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Joey Stanley</title>
<link>https://new.joeystanley.com/blog/index.html</link>
<atom:link href="https://new.joeystanley.com/blog/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<generator>quarto-1.3.433</generator>
<lastBuildDate>Mon, 25 Sep 2023 04:12:00 GMT</lastBuildDate>
<item>
  <title>Website Version 3</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/website-version-3/index.html</link>
  <description><![CDATA[ 




<p>After exactly seven years with my old website, I’ve decided to change it to what you are seeing now.</p>
<section id="what-was-wrong-with-the-old-one" class="level2">
<h2 class="anchored" data-anchor-id="what-was-wrong-with-the-old-one">What was wrong with the old one?</h2>
<p>I built my old website in September 2016. I had a research assistantship at the DigiLab at UGA, and Emily McGinn, the supervisor, suggested I find ways to increase my online presence. I learned some <a href="../../blog/making-a-website-is-fun">web design and CSS skills</a> skills and eventually made Version 1 of my website. That version was essentially the same as what I built in the tutorial I followed, so a few months later I rewrote everything from scratch and made Version 2. (Let’s be honest though, it’s still obviously heavily based on the tutorial.) Other than very minor tweaks to a few things, that’s how my website has been since then.</p>
<p>However, it got a bit unwieldy. The blog was organized just fine, but I also added pages here and there to go along with workshops and other presentations I gave. It got more confusing when I gave the same workshop a second time and had multiple similar pages floating around. Since I didn’t foresee some of these additions, its growth was reminiscent of unplanned suburban sprawl. For examples, sometimes images were just dumped into a folder, others were better organized. Non-blog pages were hidden and were sometimes a top-level page and other times within a dedicated subdirectory. Each individual addition wasn’t a big deal, but once I stepped back and looked at it all, it was a mess.</p>
<p>The format of my tutorials wasn’t consistent either. I have lots of handouts on my website, tucked away here and there. If they were associated with a workshop, they were separate R Markdown files that didn’t fit in with the rest of the site. Some of my earliest ones are PDFs of Word files! If they weren’t associated with a workshop, they’re regular blog posts. But because the site wasn’t connected to R, I had to do a <em>lot</em> of copying and pasting R Markdown code and careful insertion of images to get those tutorials to look right. In some cases, the extra work made it possible to do things like syntax highlighting in Praat and highlighting specific lines of code. But that was all done by manually inserting HTML tags and updating my CSS.</p>
<p>Also, as careful as I was about my CSS, it wasn’t perfect. I think there were some issues if like a list had only one element, and there were things with hyperlinks. Some one-off portions of blogs or tutorials sometimes didn’t look right. I had a disclaimer at the bottom of every page, saying something like, “This website is built from scratch. Pardon the flaws; I am not a web designer.” Which was a humble brag if anything. But as the site grew I didn’t want to change the CSS because it might change some blog post from years ago in unexpected ways.</p>
<p>Ultimately, I didn’t mind the mess because it’s what made my site unique. But, what made me finally decide to migrate to Quarto was the underlying architecture. It was built using Jekyll, which involves a programming language called Ruby in some way. After seven years I still have no idea what either of those are. I did this because it’s what the tutorial I followed used. When the site worked, it was great. But sometimes, the Ruby dependencies (called “gems”) would update or break or whatever and I had to google around trying to find a fix. I had no idea what I was doing and it led to a lot of frustrated late nights trying to get my website up and running again.</p>
<p>Then Quarto comes along, which makes it easy to make a blog entirely within R Studio. I have been very familiar with the R world for a while. In 2017, I was an early adopter of <a href="https://www.rstudio.com/products/shiny/">Shiny</a> (at least in linguistics, I think), so I was able to integrate all my html, CSS, and R skills into the <a href="http://lap3.libs.uga.edu/u/jstanley/vowelcharts/">Gazetteer of Southern Vowels</a>. In 2020, I also started dabbling with creating my own R Packages and using the amazing <a href="https://pkgdown.r-lib.org">pkgdown</a> to make dedicated websites for them (see <a href="https://joeystanley.github.io/joeyr/">joeyr</a>, <a href="https://github.com/JoeyStanley/futurevisions">futurevisions</a>, <a href="https://joeystanley.github.io/barktools/">barktools</a>, and <a href="https://joeystanley.github.io/joeysvowels/">joeysvowels</a>). Finally, I have a side project that involves collecting and analyzing data about what hymns are sung in LDS congregations, and in 2023 I decided to build the <a href="hymnstats.joeystanley.com">site</a> entirely in Quarto.</p>
<p>So, I’ve gradually built up to web development in R over the years and Quarto seems like the logical place to migrate to. Plus, it has some features that I’ve always wanted, like scrolling table of contents and a search feature. After some encouragement from folks on Twitter, I decided it’s time to bite the bullet and go for it.</p>
</section>
<section id="what-does-it-take-to-migrate" class="level2">
<h2 class="anchored" data-anchor-id="what-does-it-take-to-migrate">What does it take to migrate?</h2>
<p>I’m doing this page by page. Here’s the order I took:</p>
<ul>
<li>My homepage and any links on it. I didn’t clean up the linked pages, but at least there weren’t any dead links.</li>
<li>My blog posts
<ul>
<li>I started with some of my earliest ones because they were the simplest.</li>
<li>Then moved on to any conference or paper announcement. As part of that, I also transferred the associated slides, papers, and other files.</li>
<li>I then finished any non-tutorial posts.</li>
<li>I saved the tutorials for last because they would take the most time. Fortunately, it wasn’t too bad changing the static code blocks to ones that are run when the page is rendered. However, because dependencies like packages and dataset have been updated, some of the details and specific results have changed. Nothing major though.</li>
</ul></li>
<li>Other miscellaneous pages</li>
</ul>
<p>This took several months to make the full transfer. Little did I know that I had over 100 different webpages (mostly blog posts) all contained within my site. This was a surprise to me because I had not idea I had created so much content. I very slowly made progress by creating a reminder on my phone to migrate one webpage a day. Some were pretty straightforward. Others took more time, like tutorials and other code-based ones.</p>
<p>It was kinda fun to read through some of my old posts. In some cases, I added marginalia that basically pointed out how silly I was several years ago. I don’t think many people visit those early blog posts, so no one’s going to see them anyway.</p>
</section>
<section id="things-that-are-the-same" class="level2">
<h2 class="anchored" data-anchor-id="things-that-are-the-same">Things that are the same</h2>
<p>I’ve tried to keep as much of the original structure of the site the same as I could. However, as I migrated, I realized that I could make things overall a bit more contained by changing the structure of associated files.</p>
</section>
<section id="changes" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="changes">Changes</h2>
<p>Here’s a list of the changes I’ve made.</p>
<ul>
<li><p>Each blog is now in its own self-contained folder. The previous structure had all posts in a single folder and all images in another folder. This time, the images associated with a blog post are contained within that folder. So, instead of this:</p>
<pre><code>├──📁blog
|  ├──📄blog post 1.md
|  ├──📄blog post 2.md
├──📁images
|  ├──🌅image1.png
|  ├──🌅image2.png</code></pre>
<p>It’s now this:</p>
<pre><code>├──📁blog
|  ├──📁blog post 1
|  |  ├──  📄index.qmd
|  |  ├──  🌅image1.png
|  ├──📁blog post 2
|  |  ├──  📄index.qmd
|  |  ├──  🌅image2.png</code></pre>
<p>It shouldn’t affect any urls to existing blog posts because the url <code>blog/blog post 1</code> in the old format would go to the <code>blog post 1.md</code> file and in the new one it’ll go to the <code>blog post 1</code> directory, which’ll display <code>index.qmd</code> by default. I was concerned about changing the url because I know some people have cited my turorials in published work and I didn’t want those urls to break. I think this’ll work <em>and</em> it’ll keep the site better organized.</p></li>
<li><p>Within each post, I needed to update the header. I change from “tags” to “categories”, from “redirect_from” to “aliases.” I add a date-modified if needed. I remove excerpts because I only used them with my “big-link” style button. I’m replacing big-links with a standard callout box. I haven’t figured out if I can do redirects-to, which is a bummer for the GSV.</p></li>
</ul>
<div class="no-row-height column-margin column-container"><span class="">By the way, I’m stealing this way of visualizing file structure directly from <a href="https://github.com/tjmahr/quarto-blog/blob/main/posts/migrating-from-jekyll-to-quarto/index.qmd">TJ Mahr’s Migrating-to-Quarto page.</a>.</span></div><p>TODO * Rename blog post folders to something shorter and more consistent. Put aliases to old ones and make sure they work. Make sure internal links work.</p>
<ul>
<li>Change any me-specific HTML, like <span class="sidenote"> and tables. Within sidenotes themselves, I had to do HTML rather than markdown.</span></li>
</ul>


</section>

 ]]></description>
  <category>Meta</category>
  <guid>https://new.joeystanley.com/blog/website-version-3/index.html</guid>
  <pubDate>Mon, 25 Sep 2023 04:12:00 GMT</pubDate>
</item>
<item>
  <title>SoSy</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/sosy5/index.html</link>
  <description><![CDATA[ 




<p>Today, I’m in Champaign, Illinois at the 5th Sociolinguistics Symposium (SoSy) at the University of Illinois Urbana-Champaign. I’m with a student of mine, Katya Kravchenko, and we’re here presenting her research project, “Surzhyk: Attitudes and Usage among Ukrainian People.” You can view the slides <a href="../../downloads/230302-SoSy_Surzhyk.pdf">here</a>.</p>
<p>Throughout my sociolinguistics course last semester, Katya regularly kept us updated on fascinating things going on with language attitudes and ideologies among Ukrainians since the Russian invasion of Ukraine in February 2022. I think pretty much every Ukrainian speaks Russian, but not all speak Ukrainian. Even President Zelenskyy isn’t a native Ukrainian speaker and reportedly hired a tutor to help him achieve full command of the language.</p>
<p>Attitudes towards Russian have changed dramatically in the past year though. Before, TV shows would put Ukrainians subtitles if someone speaks Russian. Now, they remove the Russian audio entirely and dub it over with Ukrainian. (This what happened on the Ukrainian version of the show, “The Bachelor”.) Sometimes, there’s a disclaimer at the start of the show saying apologetically that it was filmed before February 2022 and that they apologize for the Russian. There’s a grassroots effort (I wish I had the website, but I can’t find it now) to replace Russian borrowings into Ukrainian with pure Ukrainian words. This is done either by coining neologisms, or by going back to and older form of Ukrainian and finding words that, for whatever reason, didn’t make their way into modern Ukrainian. Basically, many Ukrainians are vowing to never speak Russian again.</p>
<p>For native bilinguals, it’s not too much of a problem. However, for those who aren’t fluent in Ukrainian this can be a tricky thing!</p>
<p>In comes Surzhyk. Surzhyk is a mix of Ukrainian and Russian, akin to Spanglish. There’s not a lot of linguistic research on it, but it’s rather stigmatized. In the past year though, Katya is finding that people’s view of Surzhyk is becoming more positive. She interviewed 15 Ukrainians who were living in Ukraine in February 2022 and since fled to Utah. One part of the interview asked them about their usage patterns. Like any Fergesonian Low language, it’s seen as too casual for formal settings. But, when it comes to attitudes, it’s seen as a bridge to help Russian speakers learn Ukrainian. Speaking Surzhyk instead of Russian signals a <em>lot</em> about someone’s position in the war. A year and a month ago, speaking one language—whether it be Ukrainian or Russian—was better than mixing the two. Today, speaking Surzhyk is seen as better than full Russian.</p>
<p>This is 99% Katya’s research, but it has been fun to hop on board and work with her on this. It’s not about vowels, statistics, or American English, and I don’t speak a word of Russian, Ukrainian, or Surzhyk. But it has been a fun stretch for me.</p>



 ]]></description>
  <category>Conferences</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>Students</category>
  <guid>https://new.joeystanley.com/blog/sosy5/index.html</guid>
  <pubDate>Thu, 02 Mar 2023 14:00:00 GMT</pubDate>
</item>
<item>
  <title>New publication in Linguistics Vanguard</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/new-publication-in-linguistics-vanguard/index.html</link>
  <description><![CDATA[ 




<p>I’m happy to announce that <a href="https://doi.org/10.1515/lingvan-2022-0065">a paper of mine has been published</a> in <em>Linguistics Vanguard</em>. It’s called “Interpreting the order of operations in sociophonetic analysis” and it’s a direct follow-up to a <a href="https://repository.upenn.edu/pwpl/vol28/iss2/17/">paper</a> I wrote for the <em>Penn Working Papers in Linguistics</em> a couple months ago. While the <em>PWPL</em> paper showed that Order of Operations (OoO) matters, that we should be talking about it more, and that we should do our best to interpret others’ OoOs, it didn’t give any help as to <em>how</em> to interpret them. The main contribution for this follow-up paper then is to 1) arm researchers with knowledge of how to interpret order of operations and 2) justify the order I recommended in the <em>PWPL</em> paper.</p>
<section id="summary" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>To reiterate <a href="../../blog/new-publication-in-pwpl">what I said</a> when the <em>PWPL</em> paper came out, the idea for this paper got started when I was in the throes of data analysis and I noticed that reordering some of the processing steps resulted in different changes. I did a systematic study of OoO, presented it at <a href="../../blog/nwav49">NWAV49 in 2021</a>, and published those results in <em>PWPL</em>. But it occurred to me that even if we all become diligent and report the OoO we used in our papers, we don’t really have the knowledge of how we’re supposed to interpret those orders. As I put it in the paper,</p>
<blockquote class="blockquote">
<p>[I]t does little good if researchers are not familiar with how the order affects the overall results. A detailed methods section may explain that normalization happened before outliers were removed, but it is not currently clear what effect that order had on the results. How should a reader evaluate the results of one study that normalized the data before removing outliers against another study that transposed those two steps? This paper addresses this gap and explores in more detail the effect that some orderings are likely to have on the results of a study.</p>
</blockquote>
<p>Perhaps phrase another way, what specifically <em>is</em> the effect of normalizing before removing outliers compared to removing outliers before normalizing? Do formants go up, down, or something more complicated? As I mention in footnote 1, this knowledge can be used as “cheat codes” to manipulate your data the way you want. Hopefully reviewers can spot this kind of hacking!</p>
<p>Anyway, so when I analyzed the same data 5040 times but with different orders of operation, I ended up with 5040 hypothetical analyses of the same dataset. Obviously, it didn’t make sense to consider every single one. So instead, I concentrated my efforts on 1) finding orders that produced identical results and 2) seeing what happens when I swapped two steps in the recommended OoO I have in the <em>PWPL</em> paper.</p>
<p>Here’s that recommended order (Figure 1):</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/new-publication-in-linguistics-vanguard/recommended_OoO.png" class="img-fluid figure-img" style="width:25.0%"></p>
<figcaption class="figure-caption margin-caption">My recommended Order of Operations. Sorry the figure is so tall. And yes, I use PowerPoint for all my non-data visualizations :)</figcaption>
</figure>
</div>
<p>Many of the orders produced identical results. This was mostly the result of various subsetting functions removing different groups of unwanted data, such as unstressed vowels, presonorants, stopwords, and vowel trajectories. This makes sense because, as I say in the paper,</p>
<blockquote class="blockquote">
<p>The set of observations that are excluded in these steps is fixed: regardless of the normalization procedure, whether outliers have been removed, or how the vowels are classified, the exact same set of observations will be excluded each time.</p>
</blockquote>
<p>These functions are all similar in that they remove data that is not needed or wanted for the current analysis, but is otherwise good. This similarity is visualized by clumping them together within a single block. I argue that because this is good data, it should only be removed at the very end of the pipeline, even after normalization.</p>
<p>So then I go and explore each pair of steps in my recommended order. Allophones should be classified before removing outliers because it just makes sense to do so. Also, failing to do so will make Pillai scores go up because you artificially draw two vowel classes together. Outliers should be removed before normalization because you don’t want outliers to mess up the normalization.</p>
<p>The trickiest part of the paper to understand is section 6 and Figure 4. I use it to show the interaction between normalization and subsetting. I recommend normalizing first. If you subset first and then normalize, the data is altered in kind of a weird way, especially if you’re doing Lobanov normalization. In the end I conclude that it’s better to normalize first with this justification:</p>
<blockquote class="blockquote">
<p>One may argue that subsetting should happen before normalization so that comparisons across studies are more meaningful. It is true that a study that collects interview data will exclude many more tokens than another study that only elicits wordlist data. An argument can be made that by subsetting before normalization, what remains from the interview study more closely matches what is even collected in the wordlist study, and therefore the effect of normalization is more comparable between the two. However, a follow-up study of the interview data that happens to focus on something that was previously excluded, like vowel trajectories, will end up with a different input into the normalization step than the first study. There will be a difference between the normalized data in the first study and the normalized data in the second study. In other words, a single token of [æ] will have different normalized F1–F2 measurements between the two studies. This makes no sense since the token has not changed whatsoever.</p>
</blockquote>
<p>However, I acknowledge that if speakers have markedly different sample sizes, normalization will affect them in different ways. I think this is more indicative of an imperfect normalization procedure than anything else. We just haven’t yet found a method that perfectly models the human ear. There is room to explore normalization procedures that perform better or worse when speakers’ datasets are not particularly comparable.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Anyway, I encourage you to read the paper. I enjoyed writing it. And now that I’ve closed up that loose end, maybe I can now go back to doing actual sociolinguistic research!</p>


</section>

 ]]></description>
  <category>Methods</category>
  <category>Research</category>
  <category>Publications</category>
  <category>Vowel Overlap</category>
  <guid>https://new.joeystanley.com/blog/new-publication-in-linguistics-vanguard/index.html</guid>
  <pubDate>Wed, 14 Dec 2022 15:12:00 GMT</pubDate>
</item>
<item>
  <title>Prevelar raising paper published in American Speech</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/prevelar-raising-american-speech/index.html</link>
  <description><![CDATA[ 




<p>I’m thrilled to announce that a paper of mine has been <a href="https://read.dukeupress.edu/american-speech/article/97/3/374/174069/Regional-Patterns-in-Prevelar-Raising">published in <em>American Speech</em></a>! It’s called “Regional patterns in prevelar raising.” This one has been in the works for quite some time, so it’s very exciting to see it finally published.</p>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>Some people pronounce words like <em>bag</em>, <em>flag</em>, and <em>dragon</em> with a raised vowel, so that <em>bag</em> rhymes with <em>vague</em>. There are also some people who pronounce words like <em>beg</em>, <em>peg</em>, and <em>leggings</em> with that same raised vowel. People have studied this in a few places, most notably Wisconsin and the Pacific Northwest, but not really much anywhere else. I’m from St.&nbsp;Louis and I’ve got <sc>beg</sc>-raising pretty strong. So, where else do you get prevelar raising? Whenever I have a question like that, I just ask my 7000 closest friends what they do, as one does :)</p>
<p>I set up a survey that asks people to indicate how they pronounce something like 70 prevelar words. I distributed it on Reddit to get good geographic coverage. Using fancy GIS skills (thanks, Jack Grieve for helping me with that!), I was able to produce some pretty cool maps showing where you get raising. As it turns out, the regions where people reported <sc>bag</sc>-raising lines up with where <sc>bag</sc>-raising has been reported in the ANAE based on acoustic data, which is good because it means the data I have is at least somewhat reliable. For <sc>beg</sc>-raising though, I found that it’s much more widespread. Pretty much everywhere except the South and Michigan you’ll find people who have it, and you’re more likely to find it in places like Ohio, Indiana, the Upper Rockies, and Canadian Praries.</p>
<p>Anyway, I had a lot of fun with this one. There’s less work on prevelar raising at the moment compared to like five years ago when I first had the idea for the project. But that’s okay. It was fun to learn how to make cool maps.</p>
</section>
<section id="timeline" class="level2">
<h2 class="anchored" data-anchor-id="timeline">Timeline</h2>
<p>I take careful notes of when my projects hit major milestones. I figued I’d share those with you here:</p>
<ul>
<li>November 2017: I had the idea for the study. I was teaching a phonetics and phonology class and noticed that I have <sc>beg</sc>-raising in all but about six words, and that most of my exceptions have a sonorant following the /ɡ/: <em>integrity</em>, <em>interregnum</em>, etc. On November 10, I sent out a pilot study to my friends on Facebook. I got about 350 people to take it, which was pretty cool. In my notes I said I was hesitant to do a blog post about it because “these are legit results that I could publish.”</li>
<li>April 2018: I presented this preliminary data at an informal “TinyTalks” event to the linguistics grad students at UGA. I started making the full version of the survey and began filling out IRB forms. Approval was soon granted.</li>
<li>April–May 2018: I distributed the survey on Reddit and collected 7000 responses in two weeks. I made a plan to submit an abstract about phonological factors to NWAV and submit an abstract on regional factors to ADS.</li>
<li>Summer 2018. I submitted both abstracts as planned. I’m amazed at myself that the precise plans I made in the early days of the project all happened to a tee.</li>
<li>October 2018–January 2019: I presented at <a href="../../blog/nwav47">NWAV47</a> and <a href="../../blog/ads-and-lsa-2019">ADS2019</a> as planned. I wrote up preliminary findings and submitted a manuscript to our <a href="https://ling.franklin.uga.edu/wp2019-Stanley">UGA Working Papers in Linguistics</a>. I also wrote up the results in layperson’s terms in a <a href="../../blog/prevelar-raising-survey-results">blog post</a> to send to my participants.</li>
<li>September 13, 2019: Submitted the manuscript to <em>American Speech</em>. Not quite sure why it took me so long to finish the darn thing, but it might because it was my first Real Paper™. I was motivated to get this done so that I could include it in job applications.</li>
<li>December 4, 2019: Got an R&amp;R from <em>American Speech</em>.</li>
<li>2020: I put off working on this for a full year. I had my <a href="../../blog/dissertation">dissertation defense</a>, job interviews, a campus visit, dissertation revisions, an contract job with BYU during covid lockdown, graduation, moving to Utah, <a href="../../blog/I-got-a-job">starting a new job at BYU</a> in June, and teaching three new preps over the next six months. In November 2020 I set a goal to get this returned by the end of the year.</li>
<li>December 29, 2020: Resubmitted to <em>American Speech</em>.</li>
<li>April 8, 2021: Accept with revisions! Yay!</li>
<li>June 8, 2021: Returned the manuscript. I was told by <em>American Speech</em> that there’s a bit of a backlog, so it’d come out in 2022.</li>
<li>August 26, 2022: Got proofs from <em>American Speech</em>.</li>
<li>October 19, 2022: Got the physical copy in the mail!</li>
<li>November 2, 2022: I noticed it was published online!</li>
</ul>
<p>So from the start of the idea until publication was just about five years. I don’t really work on prevelar raising anymore, and this was a side project I wanted to get done quickly in grad school. It’s just interesting that a project I started so long ago and presented first as a grad student was used as a writing sample for job applications, and now it’ll go in my tenure portfolio! I’ve had a few papers that I started after this one come out already, but I guess I’m particularly excited about this because it was my first manuscript submitted to a peer-reviewed journal.</p>
</section>
<section id="misc-topics" class="level2">
<h2 class="anchored" data-anchor-id="misc-topics">Misc topics</h2>
<section id="unofficial-erratum" class="level3">
<h3 class="anchored" data-anchor-id="unofficial-erratum">Unofficial erratum</h3>
<p>Figure 9 was a very tricky one to do and I created probably dozens of versions of the plot trying to find the right one. Online, you’ll see the one I settled on, which does a pretty cool thing with color where I map two different variables to color.</p>
<p><img src="https://new.joeystanley.com/blog/prevelar-raising-american-speech/stanley2022_figure9_color.png" class="img-fluid"></p>
<p>This is basically impossible to print in black and white though, so I was asked to make a print-friendly one. The compromise that either I or the editors came up with was to do diagonal slashes in the regions.</p>
<p><img src="https://new.joeystanley.com/blog/prevelar-raising-american-speech/stanley2022_figure9_bw.png" class="img-fluid"></p>
<p>Unfortunately, it looks like the Figure 9 in my physical copy is just a black-and-white version of the online map, rather than the one specifically for print. This is especially confusing because the print version specifically mentions the slashes even though they’re not there. Oh well. More people will read the online version anyway.</p>
<p>[Update: Pretty soon after writing this, I got more physical copies in the mail. I suspected it was to correct this Figure 9 and sure enough it was. So, if you got an extra copy of that issue of <em>American Speech</em>, you can blame my darn complicated plot. I hope it didn’t cost the ADS too much money…]</p>
</section>
<section id="boustrophedonic-plots" class="level3">
<h3 class="anchored" data-anchor-id="boustrophedonic-plots">Boustrophedonic plots</h3>
<p>A while ago, I tweeted what would become one of my most viewed tweets:</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Okay, I'm trying something out. I have this histogram with one very tall bar and many shorter ones. So to save space, I made that tall bar follow the edge of the plotting area boustrophedonically—my favorite word!—but I'm not sure if I like it. Thoughts? <a href="https://twitter.com/hashtag/dataviz?src=hash&amp;ref_src=twsrc%5Etfw">#dataviz</a> <a href="https://t.co/9b9QYqQJLg">pic.twitter.com/9b9QYqQJLg</a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/1339467980820910080?ref_src=twsrc%5Etfw">December 17, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I even wrote <a href="../../blog/boustrophedonically">a blog post</a> about the suggestions people gave about alternative plots.</p>
<p>I’ll let you in on a little secret: I was working on this paper when I came up with the idea for that plot! The data shows the distribution of <sc>beg</sc>-raising across my entire sample. I wanted to show that there were lots of people without it, but also show that there is lots of variation among those who do have it.</p>
<p>Unfortunately, the plot didn’t make it into the manuscript. I just couldn’t do it. Figure 10 is my compromise:</p>
<p><img src="https://new.joeystanley.com/blog/prevelar-raising-american-speech/stanley2022_figure10.png" class="img-fluid"></p>
<p>So, not as fun, but prehaps more normal. Do I regret not including the boustrophedonic plot? Yeah, maybe a little.</p>


</section>
</section>

 ]]></description>
  <category>Publications</category>
  <category>Research</category>
  <guid>https://new.joeystanley.com/blog/prevelar-raising-american-speech/index.html</guid>
  <pubDate>Wed, 02 Nov 2022 14:45:00 GMT</pubDate>
</item>
<item>
  <title>NWAV50</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/nwav50/index.html</link>
  <description><![CDATA[ 




<p>Today I gave a talk that Betsy Sneller and I have been working on called “How Sample Size Impacts Pillai Scores – and What Sociophoneticians Should Do About It” at the 50th New Ways of Analyzing Variation conference in San Jose! This is an updateto what we presented at <a href="../../blog/asa2021">ASA2021</a>.</p>
<p>We have three things you can download.</p>
<ol type="1">
<li><p>First is <a href="../../downloads/221014-NWAV50_pillai.pptx">the actual powerpoint file</a>. In the notes of each slide though you can see the actual script I read, so you can read every word that was said during the talk.</p></li>
<li><p>Next, if that’s too much for you, you can download just <a href="../../downloads/221014-NWAV50_pillai.pdf">a PDF of the talk</a>. In case you want this ligherweight version of the slides.</p></li>
<li><p><del>Finally, here is the current manuscript that is under review with the <em>Journal of the Acoustical Society of America</em>. The final product will likely change somewhat, but most of the information is there.</del> [Edit (December 14, 2022): <a href="../../downloads/221202-Pillai-preprint.pdf">Here</a> is the accepted version.]</p></li>
</ol>
<p>If you need to calculate Pillai scores in R, I’ve got a two-part tutorial for you (<a href="../../blog/a-tutorial-in-calculating-vowel-overlap">here</a> and <a href="../../blog/vowel-overlap-in-r-advanced-topics">here</a>). I also did a blog post (<a href="../../blog/pillai-scores-dont-change-after-normalization">here</a>) about how Pillai scores don’t seem to change after normalization.</p>



 ]]></description>
  <category>Conferences</category>
  <category>Methods</category>
  <category>Phonetics</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>Simulations</category>
  <category>Statistics</category>
  <category>Vowel Overlap</category>
  <guid>https://new.joeystanley.com/blog/nwav50/index.html</guid>
  <pubDate>Fri, 14 Oct 2022 03:30:00 GMT</pubDate>
</item>
<item>
  <title>New publication in the Penn Working Papers in Linguistics</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/new-publication-in-pwpl/index.html</link>
  <description><![CDATA[ 




<p>I’ve just been informed that a manuscript I submitted to the <em>Penn Working Papers in Linguistics</em> has been published! It’s called “Order of Operations in Sociophonetic Analysis” and is available <a href="https://repository.upenn.edu/pwpl/vol28/iss2/17/">here</a>. In a nutshell, I discuss the various processing steps that are typical of a sociophonetic analysis an I show that changing the order that you run them can have a non-negligible impact on the overall results. I end the paper with a recommended order that we can use.</p>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>I originally started this paper because I noticed, by accident, that I was getting different results after moving some code around. I was in the middle of an analysis (of the very dataset I use in the paper) and had already gotten some results, but I had to change a few things in the processing and ended up moving a chunk of code up a little bit so that it happened before another chunks. Lo and behold, the results changed. Nothing about the underlying data changed, and nothing about the functions I ran changed—other than their order.</p>
<p>So this sent me down a bit of a rabbit hole. I identified seven processing steps that I did in my analysis pipeline. I then wrote some code that arranged those seven steps into all possible orderings, all 5,040 of them. I then took the exact same input dataset, and processed it 5,040 times, once for each permutation. With each resulting spreadsheet, I then calculated things like how shifted or overlapped people’s vowels were. Again, to be clear, the underlying data was identical, and the functions I ran were identical. The only thing that changed was the order that I ran them.</p>
<p>Well, as you can read in the paper, the results were a little concerning. First, I got many unique values for each person. Not 5,040 unique values, because some pipeline result in identical outputs. But sometimes hundreds of unique values. Some of these were admittedly very similar, but others were quite drastic. In one case, I point out that if I use some pipelines, a particular individual may be interpreted as being a linguistic innovator since she had advanced measures of some of the shifts. But in other pipelines, she would be seen as linguistically conservative since those same measures returned less-advanced measures. Taking the entire group of 53 speakers collectively, some pipelines showed that about half had shifted vowels while other pipelines showed that nearly all of them did. So, just by changing the order that I run my code can have an impact on how my dataset is interpreted!</p>
</section>
<section id="takeaways" class="level2">
<h2 class="anchored" data-anchor-id="takeaways">Takeaways</h2>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Please note that this is a different order than what I suggest in my NWAV49 talk! The version shown here is what I currently stand by.</p>
</div>
</div>
<p>So, in addition to pointing out the problem, I do offer a potential solution by prescribing an order of operations. Here’s what that is:</p>
<ol type="1">
<li><p>Reclassify your data into allophones</p>
<p>This is important because subsequent steps really need to run by <em>allophone</em> rather than by <em>phoneme</em>. I’d even say that we should separate the data into allophones even for vowels we’re not interested in (like allophones of /u/ even if we’re only interested in front vowels) because it has implications for what data gets excluded which could affect the centering when you normalize.</p></li>
<li><p>Remove “bad” data</p>
<p>This is when you remove outliers. Again, I argue that it should be done by allophone. I also recommend that stopwords and unstressed vowels be treated as their own separate category as well. But, I’m no married to that idea.</p></li>
<li><p>Normalize</p>
<p>Regardless of what normalization procedure you use, I think it is at this point in the pipeline that the procedure should happen. The normalization should include all good data (even if it’s not pertinent to the study) and not include any bad data.</p></li>
<li><p>Remove “good” but otherwise uninteresting data.</p>
<p>Finally, here is where you should subset your data to focus on just the stuff you’re interested. So, get rid of vowels or allophones you don’t want, stopwords, unstressed vowels, etc. Importantly though, it is only at this point in the pipeline that you should toss vowel trajectories! If you never extracted them in the first place, or just ignored those columns in FAVE’s output, then you’re excluding trajectory data as step 1 and that has an impact on your results!</p></li>
</ol>
<p>For now, these steps are based more on logic and theory (and I appreciate the input from Rich Ross and Thomas Kettig for helping me out with that)! I have a manuscript at the moment that dives more into these steps and provides some more quantitative justification for them. Stay tuned!</p>
</section>
<section id="my-soapbox" class="level2">
<h2 class="anchored" data-anchor-id="my-soapbox">My Soapbox</h2>
<p>Finally, towards the end, I do get a little preachy. First, I recommend that Order of Operations be explained in detail in methods sections so that we can evaluate them better. In fact, it was only after I submitted this paper that I found <a href="https://linkinghub.elsevier.com/retrieve/pii/S0095447021000711">Brand, Hay, Clark, Watson, &amp; Sóskuthy’s (2021) paper</a> that does exactly what I want to see! That’s exactly the kind of transparency that we need. Of course, at this point, it’s hard to interpret what effect one order has upon the data as opposed to another order, though, again, stay tuned for my manuscript which does exactly that!</p>
<p>I then say that quantitative linguists should be more mindful of how the data is being processed. I basically subtweet some methods that I’m not particularly fond of (Lobanov transformations, ANAE “benchmarks”) without calling them out specifically. I also subtweet a reviewer for a different paper who said to me that I shouldn’t use New Technique X and should instead use Old Technique Y for comparability with previous studies, even though recent research has shown that Old Technique Y is flawed and New Technique X is better. Anyway, so if those paragraphs sound cryptic, now you know some background.</p>
<p>Finally, I encourage quantitatively-minded linguists to continue writing methods papers. Whether it be developing a new technique or comparing existing techniques against each other, all that stuff is good for the field.</p>
<p>Anyway, I took the opportunity in this non-peer-reviewed methods paper to stand on my soapbox a little bit and talk about some of my views on the current state of quantitative linguistics. And I stand by what I wrote in the paper.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>So that’s it! This was a fun one to write because it literally has nothing to do with language or how language works: it’s purely methods. In fact, it’s not even about one specific method. It’s about how we should run our R code! Very niche. But I hope it does some small part in improving quantitative linguistics papers.</p>
<p>PS: In my notes I refer to “Order of Operations” as “OoO”. I’m 1000% okay with having <em>OoO</em> be a new abbreviation in people’s code and in methods sections now. Who wants to be the first? :)</p>


</section>

 ]]></description>
  <category>Methods</category>
  <category>Research</category>
  <category>Publications</category>
  <category>Vowel Overlap</category>
  <guid>https://new.joeystanley.com/blog/new-publication-in-pwpl/index.html</guid>
  <pubDate>Tue, 20 Sep 2022 04:11:00 GMT</pubDate>
</item>
<item>
  <title>ADS and LSA 2022</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/ads-and-lsa-2022/index.html</link>
  <description><![CDATA[ 




<p>I’m attending the Annual Meeting of the Linguistic Society of America and the American Dialect Society and I’ve got three presentations to tell you about! Please find links, summaries, and images from these presentations below!</p>
<section id="perspectives-on-georgia-vowels-from-legacy-to-synchrony" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="perspectives-on-georgia-vowels-from-legacy-to-synchrony">Perspectives on Georgia Vowels: From Legacy to Synchrony</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/220106-ADS-Georgia.pdf">here</a>!</p>
</div>
</div>
<div class="page-columns page-full"><p>On Thursday afternoon, Peggy Renwick, Jon Forrest, Lelia Glass, and I kicked off the ADS sessions with our presentation on English in Georgia. The four of us have been collaborating for about a year, pooling together datasets and sharing resources, on a project focusing on English in Georgia. This is our first talk showcasing some of our findings. Our results are largely descriptive at this point. Here are the main plots we used (in a fun dark mode!) split up by generation, gender, and ethnicity:</p><div class="no-row-height column-margin column-container"><span class="">For those of you that were there, this was the one that was horribly Zoombombed!</span></div></div>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-white_older.png" class="img-fluid"></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-white_younger.png" class="img-fluid"></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-black.png" class="img-fluid"></p>
<p>Turns out pretty vowel changes if you give it 100 years. We’re just excited to see acoustic data from such a large span of time analyzed together.</p>
<p><br></p>
</section>
<section id="homogeneity-and-heterogeneity-in-western-american-english" class="level2">
<h2 class="anchored" data-anchor-id="homogeneity-and-heterogeneity-in-western-american-english">Homogeneity and Heterogeneity in Western American English</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/220107-ADS-MTurk.pdf">here</a>!</p>
</div>
</div>
<p>At the ADS poster session on Friday, I presented a poster with two students, Jessica Shepherd and Auna Nygaard. As a bit of background, in <em>Speech in the Western States: Volume 2</em>, Fridland et al (2012:172) point out that pretty much every study of the front lax vowels in the Western US has been based on independent, isolated studies. Because each research collects and processes data their own way, it’s difficult to disentangle differences that may be due to region and differences that may be due to methodological choices. They say that “clearly, collecting the same type of data from all sites would be optimal in allowing us the most reliable cross-region assessment.”</p>
<p>This project is a direct response to that call. When I was a grad student I recruited people via Amazon Mechanical Turk to a bunch of recordings of people reading sentences and wordlists. In total, 212 people completed the task, scattered all across the Western US. This poster describes the first results from this project. As it turns out, our findings match the West’s description as exhibiting both “homogeneity and heterogeneity” (Fridland et al.&nbsp;2012:172). We find homogeneity in that most people have the LBMS to some degree and that education level and region weren’t statistically significant predictors. However, there’s a wide range of variation for the LBMS and <sc>ban</sc>-raising, with younger people and sometimes women appearing to lead both of these sound changes. Here are some sample plots from four representative speakers.</p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-mturk_samples.png" class="img-fluid"></p>
<p>And here’s an overall look at the vowel space in our dataset, with some additional allophones we don’t analyze here.</p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/ADS2022-mturk_overall.png" class="img-fluid"></p>
<p>We look forward to digging into this dataset a little bit more in the future!</p>
<p><br></p>
</section>
<section id="vowels-can-merge-because-of-changes-in-trajectory-prelaterals-in-rural-utah-english" class="level2">
<h2 class="anchored" data-anchor-id="vowels-can-merge-because-of-changes-in-trajectory-prelaterals-in-rural-utah-english">Vowels can merge because of changes in trajectory: Prelaterals in rural Utah English</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the slides <a href="../../downloads/220107-LSA-Prelaterals.pdf">here</a>!</p>
</div>
</div>
<p>Finally, on Friday afternoon, Lisa Johnson and I talked about vowel trajectories and what they can tell us about vowel merger. We look at prelaterals in rural Utah and find that, on the surface, they look like mergers by approximation. However, when we looked at the trajectories (with the help of some pretty cool animations!), it seems like the lateral gradually increases its influence on the vowel so that the merger happens “leftward,” from the coda to the onset. In this example, we have <sc>zeal</sc> and <sc>guilt</sc>, representing /il/ (<em>feel</em>, <em>deal</em>, <em>meal</em>) and /ɪl/ (<em>fill</em>, <em>dill</em>, <em>mill</em>), <a href="../../blog/extending-wells-lexical-sets-to-prelateral-vowels">respectively.</a></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_ZEAL-GUILT.gif" class="img-fluid"></p>
<p><br></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_FLAIL-SHELF.gif" class="img-fluid"></p>
<p><br></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_JOLT-MULCH.gif" class="img-fluid"></p>
<p><br></p>
<p><img src="https://new.joeystanley.com/blog/ads-and-lsa-2022/lsa2022_WOLF-MULCH.gif" class="img-fluid"></p>
<p>This was a pretty consistent pattern across all the pairs of prelateral vowels we looked at. We suspect that we might find this among other conditioned and vowel shifts, like prevelar raising, the <sc>mary-merry-marry</sc> merger, and post-coronal /u/-fronting. The point is, we think trajectories should be considered more when looking at vowel mergers because even among these supposed monophthongs, trajectories really illuminated how that merger happened.</p>
<p><br></p>


</section>

 ]]></description>
  <category>Animations</category>
  <category>Conferences</category>
  <category>Data Viz</category>
  <category>MTurk</category>
  <category>Phonetics</category>
  <category>Presentations</category>
  <category>R</category>
  <category>Research</category>
  <category>South</category>
  <category>Students</category>
  <category>Utah</category>
  <category>Vowel Overlap</category>
  <category>West</category>
  <guid>https://new.joeystanley.com/blog/ads-and-lsa-2022/index.html</guid>
  <pubDate>Sun, 02 Jan 2022 12:00:00 GMT</pubDate>
</item>
<item>
  <title>ASA181</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/asa181/index.html</link>
  <description><![CDATA[ 




<p>I’m in Seattle at the 181st Meeting of the Acoustical Society of America right now! This is my first in-person conference since October 2019, so it’s great to be here. I presented two posters today, which you can read about and download below.</p>
<p><br></p>
<section id="beyond-midpoints-vowel-dynamics-of-the-low-back-merger-shift" class="level2">
<h2 class="anchored" data-anchor-id="beyond-midpoints-vowel-dynamics-of-the-low-back-merger-shift">Beyond Midpoints: Vowel Dynamics of the Low-Back-Merger Shift</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211129-ASA2021-trajs.pdf">here</a>!</p>
</div>
</div>
<p>For some reason, I hadn’t yet presented any of my dissertation findings at a conference, not even while I was working on them or writing them up. Anyway, I’m happy to finally present some of my results at a conference. The purpose of this paper is to describe changes in vowel trajectory that accompany changes in midpoints. The Low-Back-Merger Shift is a now-widespread shift across much of North America. My data from Washington shows it pretty clearly across generations. But when I take a wide-angle lens at the vowel trajectories, I found that there was much more to the story than just a global lowering/centralizing of the front lax vowels.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/asa181/asa2021_trajs.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>There were perhaps three patterns I noticed when I modeled vowel trajectories. First is that the trajectory length was different between them. The low vowel /æ/ was much longer, then /ɛ/, and then /ɪ/. There’s also a general U-shaped pattern. Finally, the “angle” of this U-shaped was more towards the “left” for /æ/, more towards the right for /ɪ/, and in the middle for /ɛ/. These descriptions are consistent across generations and between the two geneders modeled, so it may say more about American English articulation than anything sociolinguistic.</p>
<p>Perhaps more interestingly though was <em>how</em> these trajectories changed—within the parameters just described—across generations. Older people’s vowels traversed through much more of the F2 space than younger generations did. The result is that the older people’s vowels look more like a shallow U-shape while the younger people’s is more of V-shape or even a “bounce” straight up and down in the F1-F2 vowel space. The fact that this was consistent across all three front lax vowels and between the genders suggests some interesting sociolinguistic change.</p>
<p>At this point, this is largely descriptive work. I don’t know how perceptible these differences are and I’m not even sure if everything I just described is statistically significant. It’ll take additional work to confirm both of these. Trajectories are often ignored because they’re chalked up articulatory causes; are we comfortable saying that trajectories are 100% phonetic and 0% sociolinguistic? (Meanwhile, if I may be a bit snarky, are the arbitrary single-point measurements that are typically analyzed magically sociolinguistically important?) I think people can exploit trajectories for sociolinguistic purposes. I just don’t know how or to what extent yet.</p>
<p><br></p>
</section>
<section id="sample-size-matters-when-calculating-pillai-scores" class="level2">
<h2 class="anchored" data-anchor-id="sample-size-matters-when-calculating-pillai-scores">Sample size matters when calculating Pillai scores</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211129-ASA2021_pillai.pdf">here</a>!</p>
</div>
</div>
<p>I’m very excited about this Pillai scores paper with a new colleague, <a href="https://betsysneller.github.io">Betsy Sneller</a>! The background for this papers is that a while ago I was analyzing some <em>cot-caught</em> merger data I had collected. I noticed that, without exception, I got higher pillai scores in wordlists than I did in conversational data. I thought I had stumbled upon some interesting style shifting! But it was <em>too</em> clean of a pattern, so I did some digging and found that it’s likely because of the sample size between the two subsets. I had less data from the wordlists than I did from the conversation. I hypothesized then that less data leads to higher Pillai scores.</p>
<section id="methods-and-experiements" class="level3">
<h3 class="anchored" data-anchor-id="methods-and-experiements">Methods and Experiements</h3>
<p>So in this paper, we test this hypothesis specifically by running a bunch of simulations. We started with a single bivariate normal distribution. We then randomly drew 5 numbers from that distribution and called it “group 1.” We then drew another 5 numbers from the <em>exact same distribution</em> and called it “group 2.” The fact that they’re drawn from the same underlying distribution represents a true underlying vowel merger. We then calculated the Pillai score of those two groups. We repeated with these group sizes 1000 times. Then we drew 6 tokens from each group 100 times and calcualted Pillai scores. Then 7. And all the way up to 100.</p>
<p>As seen in the main figure in the poster (slightly modified below), the results were clear: the larger the sample sizes, the lower the Pillai scores were. In theory, the Pillai scores should all be around zero since they’re from the same distribution. But with small samples sizes (&lt;10) observations per group, we very often got pretty high Pillai scores—scores that some researchers have considered to be distinct. It took around 30 observations per group to reliably (meaning 95% of the time) get the Pillai score under the somewhat conservative threshold of 0.1. It took 60 observations per group to get Pillai scores reliably below 0.05. This was concerning to us because few sociophonetic studies have sample sizes that large!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/asa181/asa2021_equal.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We were also concerned about unequal sample sizes betwen groups. So we reran the experiment, except the group sizes weren’t the same size. Each group could be anywhere from 5 to 100 observations, and we ran all 9000 or so combinations. The results were surprising to us—unequal group sizes doesn’t matter at all. The only thing that mattered was the total sample size. You can see this in the figure in the top right of the poster (or below): as you go from bottom-left to top-right, the average log Pillai score<span class="sidenote">We used log(pillai) because it worked better for this visual and for the math.</span> goes from high to low. But the fact that there is no pattern from the top-left to the bottom-right diagonal means that unequal sizes don’t matter.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://new.joeystanley.com/blog/asa181/asa2021_unequal.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>In other words, if Group A has 25 observations and Group B has 5, the Pillai score will average around 0.07. That’s the same as if you had two groups of 15. If Group A has 25 observations and Group B has 100, the Pillai score will average around 0.01. That’s the same as if you had two groups of 62.</p>
</section>
<section id="implications" class="level3">
<h3 class="anchored" data-anchor-id="implications">Implications</h3>
<p>We can think of a <em>lot</em> of implications for these findings. For one, mergers are probably underreported and splits/distinctions are probably overreported. This is because many sociophonetic studies run Pillai scores on somewhat smaller samples.</p>
<p>Because of sample size differences, comparison across studies is difficult. A study that collects lots of data per person will likely report lower Pillai scores than a study that is based on fewer observations per person.</p>
<p>Going back to the main impetus for this paper, comparison <em>within</em> studies is difficult. Since more careful speech styles typically elicit fewer observations, <strong>reading tasks will have higher Pillai scores than conversational data</strong>. To a naive researcher, this will be interpreted as style differences, when it is really just a reflection of the underlying math! This is such an important point and you can count on hearing more from me and Betsy about this in later venues.</p>
<p>Finally, one way to overcome the sample size difference is to look at the <em>p</em>-value that comes out the MANOVA test that the Pillai score came from. These <em>p</em>-values do seem to be reported in more phonetics-oriented papers, but for some reason they’re not in sociophonetics papers. So rather than us coming up with arbitrary and ad hoc thresholds for what a merged Pillai score should be, let’s us the <em>p</em>-value instead. Not reporting this <em>p</em>-value, to me at least, is kinda like reporting a <em>t</em>-statistic or <em>F</em>-ratio but without the accompanying <em>p</em>-value.</p>
<p>As a final note, and this is more of an after-thought for us, I wonder if it would be more helpful to report log(pillai) rather than raw pillai scores. Since Pillai ranges from 1 (completely distinct) to 0 (complete overlap), log Pillai would range from 0 (completely distinct) to negative infinity (complete overlap). In practical terms, it would mostly be betwen 0 and around –4 (the latter corresponding to a raw Pillai score of about 0.01). We’ll probably talk more about this in other venues so stay tuned for that.</p>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Dissertation</category>
  <category>Methods</category>
  <category>Pacific Northwest</category>
  <category>Phonetics</category>
  <category>Presentations</category>
  <category>R</category>
  <category>Research</category>
  <category>Simulations</category>
  <category>Statistics</category>
  <category>Vowel Overlap</category>
  <guid>https://new.joeystanley.com/blog/asa181/index.html</guid>
  <pubDate>Mon, 29 Nov 2021 06:00:00 GMT</pubDate>
</item>
<item>
  <title>NWAV49</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/nwav49/index.html</link>
  <description><![CDATA[ 




<p>I’m at New Ways of Analyzing Variation 49 online right now! Other than an quick online satellite session of LabPhon last summer, I haven’t attended a conference since November 2019 when we hosted LCUGA at UGA. Anyway, I’m excited to be conferencing again and while I miss seeing colleagues in-person, this online format isn’t bad. Anyway, on this page you’ll find links to the slides and YouTube videos of my two talks.</p>
<p><br></p>
<section id="order-of-operations-in-sociophonetic-analysis" class="level2">
<h2 class="anchored" data-anchor-id="order-of-operations-in-sociophonetic-analysis">Order of Operations in Sociophonetic Analysis</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211019-NWAV49_OoO.pdf">here</a>!</p>
</div>
</div>
<p>I’m very excited and nervous about this Order of Operations one. As it turns out, even if you start with the exact same spreadsheet and use the exact same functions, if you do those function in different orders, it’ll produce different results. Sometimes drastically different results. I did this by processing a spreadsheet 5,040 unique ways and got a whole range of results. To me at least, it’s making me rethink how I process my data and how I can interpret others’ results when the order isn’t explicitly reported in the methods section of a paper.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/8TEip-Fixyw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
</section>
<section id="years-of-georgia-english" class="level2">
<h2 class="anchored" data-anchor-id="years-of-georgia-english">100 Years of Georgia English</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Download the poster <a href="../../downloads/211019-NWAV49_Georgia.pdf">here</a>!</p>
</div>
</div>
<p>As a continuation of some work I did as a grad student, <a href="http://faculty.franklin.uga.edu/mrenwick/">Peggy Renwick</a> and I presented our research on Georgia English vowels and how they’ve changed over 100 years. Basically, all of them have. The Southern Vowel Shift seems to have undergone a rise and fall, perhaps peaking in those born around WWII. Meanwhile, back vowels are fronting. Younger people today have something like the Low-Back-Merger Shift, but flavored with some Southernisms still. You’ll hear more about this project in later conferences too.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/USF6fspxiGU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p><br></p>


</section>

 ]]></description>
  <category>Conferences</category>
  <category>Methods</category>
  <category>Presentations</category>
  <category>Research</category>
  <category>Simulations</category>
  <category>South</category>
  <guid>https://new.joeystanley.com/blog/nwav49/index.html</guid>
  <pubDate>Mon, 18 Oct 2021 12:00:00 GMT</pubDate>
</item>
<item>
  <title>#365 Papers (Update)</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/365-papers-update/index.html</link>
  <description><![CDATA[ 




<p>At the beginning of 2018, I set the ambitious goal of reading 365 papers during that year. I <a href="https://twitter.com/joey_stan/status/971972160322387968?s=20">tweeted</a> about it and <a href="../../blog/365-papers">blogged</a> about it, but ultimately didn’t achieve my goal. Turns out 365 is a lot. Well, after 1338 days, I can finally say I’ve ready 365 papers! So here’s just some visuals to see what kinds of things I’ve been reading.</p>
<p>What counts as a “paper” and what counts as “reading” it? I didn’t have any hard and fast rules, but these were the guidelines I laid out before starting.</p>
<ul>
<li><p><em>Chapters are okay</em>: I think that in addition to journal articles, chapters from either edited volumes, monographs, or dissertations count as one each.</p></li>
<li><p><em>Notes are required</em>: I like to take a lot of notes while I read things, so I’ll only count it if I dutifully summarize and take notes as I go along. This means that skimming an article doesn’t count. If I’ve already read an article but for whatever reason didn’t take notes, I’ll only count it if I go through it again and take notes.</p></li>
<li><p><em>Conferences don’t count</em>: At least for me, attending a conference and taking notes there doesn’t count, and neither does going through the slides/poster if available. Not that there’s anything wrong with conferences, but this is #365<em>papers</em> after all.</p></li>
</ul>
<p>In a few cases, I counted full books as a single entry, like if they had short chapters. I think a 3-page chapter of a book shouldn’t count the same as an article in <em>Language</em>, for example. Similarly, a lot of the Masters Theses I read were shorter and about the same as an article reading so those counted as one.</p>
<p>I will say that <em>re-reading</em> something counts a second time if I do it just as thoroughly. Things like textbook chapters from classes I’m teaching are the main culprit, but it’s nice to revisit things after a few years.</p>
<p>And to be clear, this doesn’t represent <em>all</em> the papers I’ve ever read. In fact, I’d say the bulk of reading for my dissertation happened before I started keeping track. I’ve kept decent notes about what I’ve read since about 2010, but I’ll just focus on the most recent 365 for now.</p>
<section id="pace" class="level2">
<h2 class="anchored" data-anchor-id="pace">Pace</h2>
<p>If I wanted to read 365 papers in a year, that’s obviously one paper a day. What was my actual pace and did it change? The following plot answers this. From left to right are the months of the year. The colored lines go up as I finished a paper that year. In dashed gray lines, I have benchmarks for where the colored lines would be if I had maintained a constant rate.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/pace.jpg" class="img-fluid"></p>
<p>Looks like in 2018 and 2019 (when I was in the throes of dissertation-writing), my pace was usually somewhere around one paper every 4 to 8 days. So about one a week or occasionally two a week, on average. Starting in 2020 and continuing into this year, my pace is quicker and I’m reading a paper at least every three days on average.</p>
<p>My pace ebbed and flowed within a single year quite a bit and it’s interesting to see the patterns. In August of 2018 for example, I started really hunkering down and writing my dissertation, so there’s a sudden increase in pace (in the blue line). In early 2019 you can see I read in short bursts (I binge-read several 3rd Wave sociolinguistics papers). In June 2019 I took GIS and Stats courses so that uptick was from those classes. In September I was in a data visualization phase. And it looks like the time between when I submitted my dissertation and when I defended it (in December 2019), I didn’t do much reading at all.</p>
<p>My pace went up quite a bit in 2020 as I was transitioning from dissertation work to teaching. I read some material related to my job talk and was working on submitting my chapter in <em>Speech in the Western States: Volume III</em>. The biggest jump was in March 2020. Yes, that’s when COVID hit, but I was also fortunate to be hired as an “instructional designer” for BYU so I was prepping a course and doing a <em>lot</em> of reading. Things waned as I moved to Utah but when Fall semester hit, I kept that pretty quick pace up as I was prepping two new courses. This continued into 2021 as I prepped another two new courses. And you can see my recent uptick as I start getting ready to teach again.</p>
</section>
<section id="content" class="level2">
<h2 class="anchored" data-anchor-id="content">Content</h2>
<p>So now that we’ve got the pace covered, let’s look at the content itself.</p>
<section id="years" class="level3">
<h3 class="anchored" data-anchor-id="years">Years</h3>
<p>First, I’ll show the publication years of the things I read. Note that I do have two colums for “no date” and forthcoming: those are mostly reviews I did or other sneak-peaks at unpublished work.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/years.jpg" class="img-fluid"></p>
<p>I’m happy to see that a large proportion of what I read was recent, having come out since I started this little project. Looks like half of the papers I read came out in 2008 or later (or rather, within the last 10–14 years); a third was 2017 or later (the last 1–4 years). I honestly wish I had read even more recent stuff though because I feel a little behind the times. A quarter of what I read was before 1993. It’s good to read the classics, but I think I need to be staying more up to date though. Something that certainly accounts for this older skew is that I read while walking and the things I read are typically older (Trudgill 1978, Petyt 1980, Preston 1989, etc). I’m happy I read some older things, but I wish this plot had been more skewed towards the right.</p>
</section>
<section id="topics" class="level3">
<h3 class="anchored" data-anchor-id="topics">Topics</h3>
<p>Next, here’s a plot of the broad topic the papers fell in. I only gave each paper a single tag, and sometimes the decision to call something sociolinguistics vs dialectology, for example, was somewhat arbitrary. But this should give you a rough idea of what things I read.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/tags.jpg" class="img-fluid"></p>
<p>It should come to no surprise that most of what I read was sociolinguistic in nature, followed closely by dialectology. The socio stuff is relevant to research and teaching and the dialectology stuff is mostly for research. Phonetics and statistics coming next are also exactly what I’d expect. I wish I had a bit wider range of topics though so that I can be more well-rounded of a linguist.</p>
</section>
<section id="publication-type" class="level3">
<h3 class="anchored" data-anchor-id="publication-type">Publication Type</h3>
<p>Next, here’s a basic plot on the publication type. I’ve divided everything into three broad categories: journal articles (which include conference proceedings), monographs, and edited volumes.</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/pub_type.jpg" class="img-fluid"></p>
<p>This is where I think I fall short. I’m happy to see that journal articles were the most common, but I think I should be reading a higher proportion of newer articles than I am. In fact, monographs and edited volumes combined make up 54% of what I read. This may also be because I read as I walk to and from my car and around my building, so I do get more regular book-reading time than sit-and-read-an-article time.</p>
</section>
<section id="publication-venue" class="level3">
<h3 class="anchored" data-anchor-id="publication-venue">Publication Venue</h3>
<p>Finally, the publication venue. Just focusing on the journal articles, here’s a list of the venues I read from the most. (I’ve filtered out venues that I only read from once or twice, for space issues).</p>
<p><img src="https://new.joeystanley.com/blog/365-papers-update/venue.jpg" class="img-fluid"></p>
<p>Based on my research, it should come as no surprise that <em>American Speech</em> and <em>LVC</em> are the top two. I have a print subscription to <em>American Speech</em>, and I had a habit of reading through all the articles while on the bus. My guess is that the <em>PWPL</em> ones are mostly proceedings from NWAV too. <em>JASA</em>, <em>JEngL</em>, and <em>J. Soc.</em> are also not much of a surprise.</p>
<p>However, this plot again highlights what I think are my shortcomings. I feel like I need to be reading more <em>Language in Society</em> and <em>Journal of Sociolinguistics</em>. I also think I need to be reading about languages other than English too. I feel like I’ve latched on to my venues to my detriment and I’m missing a lot of interesting work by not expanding my horizons.</p>
</section>
</section>
<section id="outlook" class="level2">
<h2 class="anchored" data-anchor-id="outlook">Outlook</h2>
<p>I’m glad I did this exercise ad I’ll certainly continue with it. And looking back at the past 3⅔ years has been enlightening to say the least. My goals for the next 365 papers are the following:</p>
<ul>
<li><p>Read a larger proportion of journal articles. Specifically, I want to go from 45% journal articles to 65%.</p></li>
<li><p>Read a larger proportion of newer articles. Specifically, I want over half of what I read to be since 2015 (6–9 years old).</p></li>
<li><p>Finish 365 papers sooner. It took 44 months to do this first batch. Since I’ve been keeping a pretty good pace of a paper every three days, I’ll aim for 36 months and finish by August 31, 2024.</p></li>
</ul>
<p>I also want to get through my to-read list. I have about 50 papers on it. It is always growing, and as I read more I find more things to read. But my current list has been nagging me so I want to knock out a bunch of those.</p>


</section>

 ]]></description>
  <category>Personal</category>
  <guid>https://new.joeystanley.com/blog/365-papers-update/index.html</guid>
  <pubDate>Tue, 31 Aug 2021 15:03:00 GMT</pubDate>
</item>
<item>
  <title>Kohler Tapes (Update)</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/kohler-tapes-update/index.html</link>
  <description><![CDATA[ 




<p>In <a href="../../blog/kohler-tapes">February</a>, I acquired a goldmine of data that I can use for linguistic analysis. Here’s an update on that project, now that I have some more solid numbers.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/kohler_tapes2.jpg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">(560 of 751 tapes!)</figcaption>
</figure>
</div>
<section id="cataloguing" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="cataloguing">Cataloguing</h2>
<p>Soon after getting the tapes, I had to organize them in some way. Since I don’t really know what I’m doing, I reached out to a few people I know who have worked with collections comparable in size to ask for their advice. (I also had to ask some Gen Xers how to handle and store cassette tapes because, well, I’ve never done that before 🤷🏻‍♂️).</p>
<div class="page-columns page-full"><p>So, over the course of a couple months, I took the tapes home in batches of fifty or so and cataloged them. By this, I mean that I labeled each with a sequential identifier and took photos of all sides of the tape, its case (if it had one), and any other slips of paper it came with.</p><div class="no-row-height column-margin column-container"><span class="">Thanks, Charlie, for that tip!</span></div></div>
<p>While I was there, I wrote down whatever information was written on the outside of the tape. Things like the student’s name, the interviewee’s name, the date of the interview, their age, and the relationship between the two people (grandparent, great-grandparent, etc.). It looks like most of the tapes were done between 1986 and 1999. The ones from the 80s weren’t documented as consistently and I think Mr.&nbsp;Kohler caught on to that and asked his students to do a better job because the ones in the 90s were much more well-documented.</p>
<p>There are a couple really fun gems for me as I went through the names. First, I went to Heber in 2018 to collect some audio data myself. I talked to several older people then. As it turns out, some of these tapes contain recorded interviews with some of the people I talked to! Again, it’s a small town, so not a complete surprise, but it’s still pretty cool. Also, my sister-in-law has family from Heber, and sure enough, the collection contains interviews with about 10 of her distant relatives (great-grand-uncle, etc.). I’m sure I’ll discover some other gems as I dig deeper into this collection.</p>
</section>
<section id="digitizing" class="level2">
<h2 class="anchored" data-anchor-id="digitizing">Digitizing</h2>
<p>Thanks to a great tip from my colleague Chris Rogers, I found out that the <a href="https://hlr.byu.edu">Humanities Learning Resource Center</a> in my building can digitize tapes. So I dropped everything and talked to them. Not only can they do it, but they said they do it for free! Wow!</p>
<p>So, I dropped off a box of tapes for them and two weeks later the files magically appeared in my Box drive! So I went and collected them, dropped off another several dozen and repeat the process over and over. It was a good morning when I woke up to the notification from Box saying that another 100 files were ready to download.</p>
<p>I want to just pause and do a huge shout-out to the student employees who processed all this audio! They had to hear the whir of the digitizing machine going for 8–9 hours days for 86 straight work days. Not to mention get up and flip the tape over or insert a new tape every 30–60 minutes, trim the audio, and upload the file. As someone who can’t stand unnecessary white noise or interruptions, that sounds like awful work to me. I’m sure if I had had to do it myself, it’d take me three or four times as long to get it all done and I wouldn’t be a happy camper.</p>
</section>
<section id="file-structure" class="level2">
<h2 class="anchored" data-anchor-id="file-structure">File Structure</h2>
<p>Something that I haven’t yet figured out though is the best way to store all this. When I worked with the Linguistic Atlas Project, it was simple: one speaker per file. Most interviews were longer and were recorded on multiple reels, so a single speaker may be on as many as ten or so files, but it was otherwise pretty well-organized.</p>
<p>This collection though is a hot mess. Here’s a list of the kinds of things I’m working with:</p>
<ul>
<li><p>Many students did the cleanest route and interviewed one person and turned in one tape. Great.</p></li>
<li><p>However, some students went overboard and turned in multiple (as many as five!) tapes for a single interview. I welcome more data, so that’s not too bad.</p></li>
<li><p>To complicate things, sometimes the same person was interviewed by different students on different years. One person was interviewed six different times!</p></li>
<li><p>Sometimes, if the first interview wasn’t long enough, a student would conduct another interview with a different person. So there are two interviews and two different people on a single tape.</p></li>
<li><p>The messier route was if a student interviewed two grandparents at the same time. So the husband and wife would alternate back and forth. So one interview, but two people. This will be the trickiest to process.</p></li>
<li><p>And, of course, there are a few cases where multiple joint interviews are tagged on to each other, and this collection of interviews was spread across multiple tapes. Ugh.</p></li>
</ul>
<p>Currently, my file structure is one-folder-per-tape, but as I get my hands dirty, I’m realizing I need to switch to a one-folder-per-person structure.</p>
<p>And of course, all this necessarily will need to come with multiple spreadsheets and some minor databasing to keep track of it all. Currently, I’ve got a spreadsheet for tapes, a spreadsheet for sides of tapes, and a spreadsheet for individuals. It’s not as clean as a single spreadsheet but it works.</p>
</section>
<section id="some-numbers" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="some-numbers">Some numbers</h2>
<p>So now that they’ve all been cataloged and digitized, I can give some more concrete numbers than I did in my previous blog post.</p>
<section id="number-of-tapes-751" class="level3">
<h3 class="anchored" data-anchor-id="number-of-tapes-751">Number of tapes: 751</h3>
<p>My estimate before was 600–700, so it’s a little more than I expected (which is great!)</p>
</section>
<section id="hours-of-audio-631" class="level3">
<h3 class="anchored" data-anchor-id="hours-of-audio-631">Hours of audio: 631</h3>
<p>I know that some of that is music (some students taped over mix tapes) so the number may go down as I listen to it all. I anticipated “only” 467 hours of audio at first, so this is 33% more than what I originally thought.</p>
<p>▼ I tried to estimate how much I’d end up with before they were all done, and it looks like by around 200 tapes or so I had a pretty good idea. The blue line is the predicted number and the black lines are some error. The pink line shows the true total.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/estimated_audio.jpg" class="img-fluid"></p>
</section>
<section id="minutes-per-tape-51.7-on-average." class="level3">
<h3 class="anchored" data-anchor-id="minutes-per-tape-51.7-on-average.">Minutes per tape: 51.7 (on average).</h3>
<p>My estimate in February was 40 minutes, so not only did I end up with more tapes than I expected, but they were 30% longer than I expected. I think the assignment was to have 30 minutes, but I didn’t expect so many students to go that much longer.</p>
<p>▼ Here’s the distribution of how many minutes of audio were on each tape (both sides). I’m pretty sure the peaks at 30, 65, and 95 or so reflect how much audio a cassette tape can hold.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/audio_per_tape.jpg" class="img-fluid"></p>
</section>
<section id="digitizing-pace-8.46-tapes-a-day-on-average" class="level3">
<h3 class="anchored" data-anchor-id="digitizing-pace-8.46-tapes-a-day-on-average">Digitizing pace: 8.46 tapes a day (on average)</h3>
<p>Since digitization happens in real-time, that means these students had this going for like nine hours a day. It took them 86 work days to do it all.</p>
<p>▼ Based on the creation date of the files, here’s how much work they did per day. They worked Monday through Saturday every week. You can see that after the semester ended in April it was slightly less consistent. Sometimes I wasn’t on campus the day they finished a box so they had to wait a day or two to get the next batch.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/digitization.jpg" class="img-fluid"></p>
</section>
<section id="number-of-people-806" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="number-of-people-806">Number of people: 806</h3>
<p>That’s just interviewees. If you add the 667 students, that’s 1473 total people. My guess is that that number will go down a small amount as I clean up the metadata. I’ve already had to change “Mr.&nbsp;Norman” and “Mrs.&nbsp;Norman” to their full names once I listened to them. Correcting any typos may change the number too if people were interviewed multiple times. I mentioned this in <a href="../../blogs/kohler-tapes">my last blog post</a>, but Heber only had a few thousand people living in it at the time, so this is decent proportion of the total population of Heber. And if you just focus on the age group that this collection represents, that proportion goes up quite a bit!</p>
<p>There are a fair number of common family names like Jones, Smith, Johnson, McDonald, Thompson, Anderson, Davis of course. But there are also a lot of names like Giles, Bethers, Jensen, Web, Allred, Broadhead, Casper, Duke, Probst, and Young, which I presume are local families.</p>
<div class="page-columns page-full"><p>I will say right now that some of the students’ speech has some pretty distinctive linguistic features. These would be people born between about 1972 and 1987, or Gen Xers and early Millennials,  who grew up in Heber. Unfortunately, I won’t have enough data from them to do much of an analysis.</p><div class="no-row-height column-margin column-container"><span class="">Geriatric Millennials?</span></div></div>
</section>
<section id="interview-years-19862001" class="level3">
<h3 class="anchored" data-anchor-id="interview-years-19862001">Interview years: 1986–2001</h3>
<p>That’s at least based on the 418 tapes where the interview date was written on the outside. Almost all were in April or May of each year. I suppose if I really wanted to I could track down some old yearbooks and find when the students were in 8th grade and get an exact year. I may find this information in the audio, but I haven’t listened to all of them yet. I may also be able to deduce it from people’s ages and birth years if they mention them.</p>
<p>▼ Notice there are many more in the 90s. I think it’s a sampling bias though. My guess is that later on in the project, the students received more explicit instructions to write that information than the students in the 1980s did.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/interview_years.jpg" class="img-fluid"></p>
</section>
<section id="birth-years-19051953" class="level3">
<h3 class="anchored" data-anchor-id="birth-years-19051953">Birth Years: 1905–1953</h3>
<p>Again, that’s at least based on the 28 tapes I’ve listened to. This information was not written on the outside of the tape, so I can only get it in the audio itself. If they don’t say it explicitly, I can usually get enough information about the person to look up census records and get a confirmed date.</p>
<p>▼ Here’s the spread of confirmed birth years. They’re color-coded by generation cohort in case that’s meaningful to you. I estimated everyone would be born between 1900 and 1940, so that was pretty close being right.</p>
<p><img src="https://new.joeystanley.com/blog/kohler-tapes-update/birth_years.jpg" class="img-fluid"></p>
</section>
<section id="places-of-birth-mostly-wasatch-county" class="level3">
<h3 class="anchored" data-anchor-id="places-of-birth-mostly-wasatch-county">Places of birth: mostly Wasatch County</h3>
<p>Once again, that’s based on the 28 tapes so far. Wasatch County includes Heber, Charleston, Daniel, and Walsburg. Keep in mind these interviews took place in Heber, the county seat of Wasatch County.</p>
<p>▼ Several other places in Utah are represented so far too. 14 unique cities in just 28 tapes. Only one person so far was born outside of Utah. <img src="https://new.joeystanley.com/blog/kohler-tapes-update/birth_places.jpg" class="img-fluid" style="width:85.0%"></p>
</section>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>I won’t rehash what I wrote in my earlier blog post, but now that I have some more solid numbers, I can have better estimate for what I need to get this project done.</p>
<p>With 631 hours of audio and a rough estimate of 10 hours of work for every hour of audio, that’s 6,310 hours of manual labor needed to transcribe this all. Again, that’s about 35% more than I anticipated in February. At $15 per hour of work, that’s $94,650 in student wages.</p>
<p>If I can get some more stellar RAs like I had this semester, who worked 10 hours a week, that’s 631 student-weeks. At 15 weeks a semester, that’s 42 student-semesters of work. If I want this done in two years, that’ll take an average of 14 RAs each semester, including summers. Anyone who has worked with transcribers knows that retention is not great, so I’ll most certainly need more than 14 student helpers and they’ll most certainly not last two years.</p>
<p>This doesn’t even include my pipe dream of getting some grad student workers to form a core group of researchers. They’d help with supervising and training the transcribers, quality control, other aspects of the data processing (force-aligning, formant-extraction, file management), and analysis.</p>
<p>Am I already looking at external grants? Yes, yes I am. And am I already looking at different types of transcription software, methods, speech-to-text programs, and other things to speed this up and/or make it less costly? Yes, yes I am.</p>
</section>
<section id="immediate-plans" class="level2">
<h2 class="anchored" data-anchor-id="immediate-plans">Immediate Plans</h2>
<p>My first task though is to get as many of the gaps in my metadata spreadsheet filled as quickly as possible. I only know the birth years and places for 28 of the 806 people. I’d like to get a much more complete picture of what this collection is like before I start prioritizing which tapes to transcribe first. Sometimes this information is near the start of the interview but sometimes it’s not. Not quite sure how to get that information without just listening to all of them.</p>
<p>Fortunately, I got a grant from the <a href="https://reddcenter.byu.edu">Redd Center for Western Studies</a> to go towards this project. It’s about the right amount needed to process enough data for a preliminary linguistic analysis. So I hope to get the ball rolling on some transcriptions and metadata extraction. Stay tuned for the first results at a conference near you!</p>


</section>

 ]]></description>
  <category>Research</category>
  <category>Utah</category>
  <guid>https://new.joeystanley.com/blog/kohler-tapes-update/index.html</guid>
  <pubDate>Wed, 16 Jun 2021 17:24:00 GMT</pubDate>
</item>
<item>
  <title>Kohler Tapes</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/kohler-tapes/index.html</link>
  <description><![CDATA[ 




<p>So, I just acquired a goldmine of data that I can use for linguistic analysis. Sitting in my office are 452 cassette tapes, each containing at least 30 minutes of recorded interviews with an older folks from Heber City, Utah. And that’s about half of the collection: the other half is with a historian in Midway, Utah. So, I’m looking at roughly 400–500 hours of audio. Not sure how I’m going to process it all, but I wanted to kick off the beginning of this long-term project with a blog post describing the history of the tapes, why I’m interested in them, and speculations about the future.</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/kohler-tapes/kohler_tapes.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption margin-caption">452 tapes sitting on my shelf!</figcaption>
</figure>
</div>
<section id="background" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="background">Background</h2>
<p>I first heard about the tapes a little over three years ago. In January 2018, the LSA annual meeting was in Salt Lake City. Wanting to take advantage of the trip out there, I applied for and received a grant from the University of Georgia to collect audio in Heber City, aiming for multiple generations within a family to track language change over time. I decided on Heber partly because it was a region of Utah that had never been the subject of acoustic (let alone linguistic) analysis, as far as I know. My parents were living there at the time too, so they could hook me up with some potential contacts.</p>
<div class="page-columns page-full"><p>So on the morning of the first day of my fieldwork, the first thing I did was go to the Heber Valley Visitor’s Center as a way to potentially find some contacts. Literally the first person I talked to told me about a man who had a huge collection of tapes. One person led me to another, and I was talking to an elderly man named Norm Kohler in his nursing home.</p><div class="no-row-height column-margin column-container"><span class="">Side note, it’s amazing that I heard about this goldmine <em>literally</em> through the first person I talked to while doing fieldwork? Who knew that there’d be such an amazing collection of audio sitting in someone’s basement nearby? In fact, there could be lots of collections like these, just collecting dust in people’s basements. All it takes is to find the right person!</span></div></div>
<p>Norm was a beloved middle school teacher in Heber City in the 1980s and 1990s. As a history project, he had each of his students get a cassette tape and interview a grandparent. I don’t know what the interview questions were, but I think they mostly concerned life in Heber Valley. He kept all the tapes his students turned in and, over the course of two decades, he ended up with over 1200 interviews! Norm intended to compile them and put together an oral history of the town, but unfortunately was unable to do so. So, just weeks before I met him, he decided it was best to return the tapes to the family members’ of his students and the people they interviewed. So he put an ad in the paper and hundreds of people claimed their tapes and were able to hear their ancestors’ voices, perhaps for the first time.</p>
<p>However, not all the tapes were claimed. I was told a few hundred remained. So, after Norm passed away a few months later, his family held on to them for a while before finally donating them to the Midway Historical Society. (Midway is the town next door to Heber.) Several complications made it difficult for me to get access to the tapes, including outdated contact information on Midway’s website, the society going on an extended hiatus, me living in Georgia, and then covid. But I did my best to reach out to anyone who might know about where the tapes were being stored.</p>
<p>Finally, on Thursday this week, I was contacted by the historian in custody of the tapes. She asked if I was still interested in them, and I most definitely am! So we had a nice chat about what my goals were for them and what the goals were for the Historical Society, and we think there’s mutual interest in getting them digitized and transcribed. So, the next day, yesterday, she happened to be in Provo so she dropped off about half of the tapes—452 of them!—at my office!</p>
<p>So after three years of following tenuous leads, I finally have the tapes!</p>
</section>
<section id="why-am-i-so-interested" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="why-am-i-so-interested">Why am I so interested?</h2>
<p>I am a linguist, so why should I care about these tapes? Well, the obvious reason is that it’s a <em>lot</em> of audio. For my dissertation I analyzed about 40 hours of interviews and that was already a lot of data. This is at least 10 times the amount of audio. In fact, it’s about the size of the <em>Digital Archive of Southern Speech</em>, a subset of the <em>Linguistic Atlas of the Gulf States</em>, that I spent four years in grad school analyzing. So having access to this much audio is absolutely incredible.</p>
<p>But it’s not just the amount of audio. There are dozens of oral history projects even in Utah. This particular set is attractive for several reasons:</p>
<ol type="1">
<li><p>The nature of the homework assignment ensured good metadata. A few tapes have already been digitized and they all start off introducing the interviewer (the middle-schooler) and the interviewee, with information like the date of interview, their age, and where they grew up.</p></li>
<li><p>Because these were all students in the same smallish town in Utah the sample will be relatively homogeneous geographically. While it doesn’t ensure that the interviewees (the grandparents) were from Heber or Heber Valley generally, my guess is that a significant number of them are.</p></li>
<li><p>Typically, interviews happen with a historian or someone that the interviewer is unfamiliar with. In sociolinguistics, it’s generally accepted that the degree of familiarity with the interviewer can have an influence on a person’s speech. In all cases with these tapes, the interviewer is a teenager and a grandchild of the interviewee. So that lowers the formality of the situation and will likely mean that the interviewees’ speech will be more casual.</p></li>
<li><p>Heber Valley has been the focus of very little acoustic research. There may be occasional interviews as parts of the Linguistic Atlas Project or the <em>Dictionary of Regional American English</em>, but no study, as far as I know, has focused on Heber. Instead, most research looks at people from Utah Valley and Salt Lake Valley. This collection of interviews will offer a new spot on the map of Utah dialectology and a nice point of comparison between more urban and more rural areas of the state.</p></li>
<li><p>I have virtually no metadata about the interviewees right now, but if their grandchildren were about 14 years old in the 1980s and 1990s, then the speakers in these tapes were born perhaps sometime between 1900 and 1940. There has been some research on the development of Utah English, mostly by David Bowie, but he acknowledges that it was based on public sermons given by upper-class white men. This collection offers a unique look into how other Utahns born around that time talked. And since I have some comparable data from contemporary Heber City residents, I can begin to look at language change in real time.</p></li>
</ol>
<div class="no-row-height column-margin column-container"><span class="">There were about 4500 people living in Heber in the 1980s and 1990s, which means this sample is a significant chunk of the community!</span></div><p>So there are lots of reasons for why I’m really interested in this collection of tapes. And that’s on top of the oral history the Midway Historical Society wants to create based on them.</p>
</section>
<section id="looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="looking-ahead">Looking Ahead</h2>
<p>Luckily, I’ve had some experience working on a project of this size. For four years at the University of Georgia, I was a part of the team that processed the <a href="http://www.lap.uga.edu/Site/DASS.html"><em>Digital Archive of Southern Speech</em></a>, which is a 367-hour subset of the <em>Linguistic Atlas of the Gulf States</em>. So I’ve sat in on transcriber training sessions, seen what kinds of obstacles get in the way of processing, managed thousands of files, and analyzed spreadsheets with a couple million acoustic measurements in them. However, that was only as a graduate student. I’m sure there’s a lot that goes on behind the scenes as a PI that I didn’t see.</p>
<p><em>Transcribers</em>—Some back-of-the-envelope calculations suggest that I’ll need a sizable grant to get this all processed. Again, I don’t have definite numbers for anything, I know my 452 tapes are a little over half of them, so let’s say there are 700 tapes total. They’re all at least 30 minutes long and I know many went longer, so if I average say 40 minutes per tape, that’s 28,000 minutes or roughly 467 hours. I think the the transcribers for <em>DASS</em> averaged about 13 hours per 50 minutes of audio or so, but this audio is newer and I presume Utah transcribers will be more familiar with Utah speakers I think, so I’ll estimate 10 hours of work per tape. That’s 4670 hours of transcription. At $15 per hour, I’m looking at about $70,000 in student wages. Obviously, I can’t get that much coin internally so it sounds like this is only going to happen with an external grant.</p>
<p><em>Grad student workers</em>—That’s of course assuming that the only wages I’ll need to pay for are transcribers. This might be getting into “If you give a mouse a cookie” territory, but it would be nice to have some grad students helping out with the project. At UGA, we had at least four and as many as six grad students involved in the project at a time. There was a lot of overlap between our duties, but very roughly speaking, one managed the transcribers, one managed the spot-checks, one managed the acoustic analysis, and one did miscellaneous duties. We were all involved in analysis, and a few others popped in for a semester or two to do additional analysis or perform other duties. To lighten my load, it would be handy to have perhaps three grad students manage the transcribers, check their work, and do the acoustic analysis. I’m fuzzy on what costs are associated with RA-ships at BYU, but I do know it’ll add significantly to the total cost of the project.</p>
<p><em>Time</em>—How long will transcriptions take? I’ve done transcriptions and they’re soul-sucking work. Even when I was highly motivated to process my own dissertation data, that I collected myself, and under a bit of a time crunch, I could barely put in more than about two hours a day. I surely don’t expect undergraduate transcribers to do more than 10 hours a week. When motivated by money, I’ve seen some at UGA do more, but those students were exceptional. I’ll estimate five hours of work per transcriber per week. So under the assumption of 4670 hours of work total, that’s 934 transcriber-weeks. If a semester is fifteen weeks, that’s 62 transcriber-semesters. If I set a goal of getting all the work done in two years (six semesters if you include summers), it would take ten or eleven transcribers to do it in two years. Of course, these are all very rough estimates, but managing several tens of thousands of dollars and almost a dozen workers for two years is not something I expected to do right away!</p>
<p><em>Digitizing</em>—Regardless of the cost, number of workers, and time involved, the first step of the process will be digitization. Fortunately, it sounds like the Office of Digital Humanities can take care of that for me! Wow! So my short term goal is to get a batch—maybe 30 or 50 tapes—done first. While they work on digitizing the next batch, I can get started on listening to the first few minutes of the completed tapes and extracting whatever metadata I can from them. Eventually, all the tapes will be digitized and I can have a more concrete idea of how much audio (and consequently, people, time, hours, and money) I’m looking at.</p>
<p><em>Metadata</em>—After digitizing all of them, my next step will be to finish collecting the metadata. It’ll be nice to have a clear picture of birth years, genders, and birthplaces for all 700 or so people. The most likely scenario is that I <em>won’t</em> get an external grant because they’re extremely competitive, so I’ll have to prioritize which ones to transcribe first. The Historical Society would like to start with some of the prominent members of the community and descendants of the town’s founders. I’d like to find a balance of genders and birth years too, so we’ll probably settle on a subset that satisfies both of our needs. How big? I’m thinking between 35 and 70 (5% to 10% of the tapes). That’s a more reasonably-sized project that I could possibly get funded internally. It could provide me at least a beginning look at the speech community which would help seed an external grant.</p>
<p><em>Follow-up project?</em>—In case I just need more data to analyze (ha!) wouldn’t it be cool to track down some of the tapes that were given away? Presumably, if an ad in the paper is what it took for the families to get them, then an ad might be a good place to start to find them. We’d digitize the tapes right there for people, give them a copy and return the tape to them of course, but then also add that to the collection for the oral history. I think it would be especially cool to interview those people themselves! That way we can get some contemporary data to compare the tapes to, as well as track change within the family. That’ll have to wait until I get NSF grant number two!</p>
<p><em>Publications</em>—What’s the end goal? Well, I’ll obviously start cranking out some papers as soon as a reasonable amount of data has been processed. There is a <em>lot</em> going on in Utah English. Many of the stereotyped features are dying out, so these people may provide good acoustic data for what would otherwise be hard to study phonetically today. But there are also lots of other features that I believe are recent innovations, so if they’re infrequent or missing from these speakers, it’ll help establish the timing of when they did develop. Even before I had the tapes, I’ve been thinking a full analysis of this collection deserves a book-length treatment. It likely won’t get done before I’m up for tenure, but maybe it’ll go towards my application for full professor.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>The history of the Kohler Tapes is pretty cool, and I’m lucky to be a part of the creation of an oral history of Heber City. It’s so satisfying teaming up with a historical society and finding ways to help the community I’m studying too. Linguistically, they’re interesting to me for lots of reasons, but I think everyone benefits from seeing these tapes get processed. As far as how I’m going to go about processing all of them, I really have no idea what I’m doing so there will be a lot of learning involved. But I’m excited to be involved and to have a clear research trajectory for the next decade or so!</p>


</section>

 ]]></description>
  <guid>https://new.joeystanley.com/blog/kohler-tapes/index.html</guid>
  <pubDate>Sat, 13 Feb 2021 21:16:00 GMT</pubDate>
</item>
<item>
  <title>Pillai scores don’t change after normalization</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/pillai-scores-dont-change-after-normalization/index.html</link>
  <description><![CDATA[ 




<p>I was playing around with some data the other day and I discovered that if you calculate the pillai score on raw data you get the same result as if you calculated it on normalized data. This might be common knowledge among sociophoneticians who work with this kind of data, and now that I think about how normalization works, it makes sense. But it’s new to me so I thought I’d write about it and illustrate it.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Update (October 19, 2021)</strong> Please see my <a href="nwav49">NWAV49</a> presentation on order of operations in sociophonetic analysis. While this blog post shows that normalization doesn’t affect the overall outcome, the order that you apply other sociophonetic data processing steps can have a substantial effect on your results!</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Update (November 23, 2021)</strong> Betsy Sneller and I have done some recent research on Pillai scores. Please see the summary our <a href="asa2021">ASA2021</a> poster (and the poster itself) for more information.</p>
</div>
</div>
<p>Incidentally, this post is also somewhat of a tutorial on how to do a few different vowel normalization procedures and how to calculate pillai scores. I hope to do a separate tutorial on normalization, but I do have a detailed tutorial on calculating vowel overlap already, which you can view <a href="a-tutorial-in-calculating-vowel-overlap">here</a>.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb1-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(joeyr)</span>
<span id="cb1-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(joeysvowels)</span></code></pre></div>
<section id="calculating-pillai-scores" class="level2">
<h2 class="anchored" data-anchor-id="calculating-pillai-scores">Calculating Pillai scores</h2>
<p>I’ll start by loading a sample dataset. This is a simplified dataset of 10 English speakers from the state of Idaho, which comes from my <a href="https://joeystanley.github.io/joeysvowels/"><code>joeysvowels</code> package</a>. It contains F1–F4 measurements from a random sample of 10 tokens from 11 monophthongs.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1">idahoans <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> joeysvowels<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span>idahoans <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb2-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # A tibble: 1,100 x 7</span></span>
<span id="cb2-5"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    speaker sex    vowel    F1    F2    F3    F4</span></span>
<span id="cb2-6"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    &lt;fct&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb2-7"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  1 01      female AA     699. 1655. 2019. 3801.</span></span>
<span id="cb2-8"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  2 01      female AA     685. 1360. 1914. 4257.</span></span>
<span id="cb2-9"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  3 01      female AA     713. 1507. 2460. 3617.</span></span>
<span id="cb2-10"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  4 01      female AA     801. 1143. 1868. 2908.</span></span>
<span id="cb2-11"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  5 01      female AA     757. 1258. 1772. 2778.</span></span>
<span id="cb2-12"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  6 01      female AA     804. 1403. 2339. 4299.</span></span>
<span id="cb2-13"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  7 01      female AA     664. 1279. 1714. 2103.</span></span>
<span id="cb2-14"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  8 01      female AA     757. 1325. 1929. 2660.</span></span>
<span id="cb2-15"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  9 01      female AA     730. 1578. 2297. 2963.</span></span>
<span id="cb2-16"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## 10 01      female AA     700. 1546. 2109. 3432.</span></span>
<span id="cb2-17"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # … with 1,090 more rows</span></span></code></pre></div>
<p>I’ll start off by normalizing the data in three different ways.</p>
<ol type="1">
<li><p>First, I’ll do the Lobanov transformation which is pretty common although <a href="http://santiagobarreda.com">Santiago Barreda’s</a> forthcoming paper in LVC suggests that we really shouldn’t be using it. I can accomplish the normalization with one line of code using by applying the base R <code>scale</code> function to both the <code>F1</code> and <code>F2</code> columns <code>dplyr::across</code>. I’ll create new columns called <code>F1_lob</code> and <code>F2_lob</code>.</p></li>
<li><p>Then, I’ll normalize using the method described in the <em>Atlas of North American English</em>. I won’t go into detail about how this normalization procedure works, but I’ve written it up as a function and made it available in my sandbox <a href="https://joeystanley.github.io/joeyr/"><code>joeyr</code> package</a>. To get this to work, I’ll first specify which columns contain the formant measurements to normalize (<code>F1</code> and <code>F2</code>). I also need to specify which column contains unique values for each vowel token; in this case, since it’s one row per token (<em>i.e.</em> this isn’t trajectory data), I can just supply the row names. I’ll then specify which column contains unique values per speaker.</p></li>
<li><p>Finally, I’ll normalize the data using the ΔF technique described in Johnson (2020). Again, I won’t go into detail, but I wanted to try it out anyway because it’s less common and because it takes into account F3 and F4 as well. I’ve also wrapped that one up into a function in my <code>joeyr</code> package, <code>norm_deltaF</code>, and I just need to specify the formant columns to be used.</p></li>
</ol>
<p>So I can easily incorporate all three of these normalization procedures in just three lines of a tidyverse pipeline. Pretty cool!</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1">idahoans_norm <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> idahoans <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(speaker) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">across</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(F1, F2), scale, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">.names =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"{col}_lob"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">norm_anae</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">hz_cols =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(F1, F2), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">vowel_id =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">row.names</span>(.), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">speaker_id =</span> speaker) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">norm_deltaF</span>(F1, F2, F3, F4) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb3-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span>
<span id="cb3-7"></span>
<span id="cb3-8"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # A tibble: 1,100 x 15</span></span>
<span id="cb3-9"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # Groups:   speaker [10]</span></span>
<span id="cb3-10"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    speaker sex   vowel    F1    F2 F1_anae F2_anae    F3    F4 F1_deltaF</span></span>
<span id="cb3-11"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    &lt;fct&gt;   &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb3-12"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  1 01      fema… AA     699. 1655.    714.   1690. 2019. 3801.     0.637</span></span>
<span id="cb3-13"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  2 01      fema… AA     685. 1360.    700.   1388. 1914. 4257.     0.624</span></span>
<span id="cb3-14"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  3 01      fema… AA     713. 1507.    728.   1539. 2460. 3617.     0.650</span></span>
<span id="cb3-15"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  4 01      fema… AA     801. 1143.    818.   1167. 1868. 2908.     0.730</span></span>
<span id="cb3-16"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  5 01      fema… AA     757. 1258.    772.   1284. 1772. 2778.     0.689</span></span>
<span id="cb3-17"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  6 01      fema… AA     804. 1403.    821.   1432. 2339. 4299.     0.733</span></span>
<span id="cb3-18"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  7 01      fema… AA     664. 1279.    678.   1306. 1714. 2103.     0.605</span></span>
<span id="cb3-19"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  8 01      fema… AA     757. 1325.    773.   1353. 1929. 2660.     0.690</span></span>
<span id="cb3-20"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  9 01      fema… AA     730. 1578.    746.   1611. 2297. 2963.     0.665</span></span>
<span id="cb3-21"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## 10 01      fema… AA     700. 1546.    715.   1578. 2109. 3432.     0.638</span></span>
<span id="cb3-22"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # … with 1,090 more rows, and 5 more variables: F2_deltaF &lt;dbl&gt;,</span></span>
<span id="cb3-23"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## #   F3_deltaF &lt;dbl&gt;, F4_deltaF &lt;dbl&gt;, F1_lob[,1] &lt;dbl&gt;, F2_lob[,1] &lt;dbl&gt;</span></span></code></pre></div>
<p>I’ll focus on the <em>cot-caught</em> merger here. To calculate the pillai scores then, I can use another function in <a href="https://joeystanley.github.io/joeyr/"><code>joeyr</code></a> called <code>pillai</code>. To use it, I’ll first need to only include the vowels I want run the pillai score on. I then put in the formula that I’d normally use in <code>manova()</code>. I’ll do that four times, once for the raw data and then once for each of the normalizations.</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1">idahoans_pillai <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> idahoans_norm <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb4-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(vowel <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%in%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AA"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AO"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb4-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pillai_raw    =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pillai</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(F1,        F2)        <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> vowel),</span>
<span id="cb4-4">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pillai_lob    =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pillai</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(F1_lob,    F2_lob)    <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> vowel),</span>
<span id="cb4-5">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pillai_anae   =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pillai</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(F1_anae,   F2_anae)   <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> vowel),</span>
<span id="cb4-6">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">pillai_deltaF =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pillai</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">cbind</span>(F1_deltaF, F2_deltaF) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span> vowel)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb4-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span>
<span id="cb4-8"></span>
<span id="cb4-9"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # A tibble: 10 x 5</span></span>
<span id="cb4-10"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    speaker pillai_raw pillai_lob pillai_anae pillai_deltaF</span></span>
<span id="cb4-11"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    &lt;fct&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;</span></span>
<span id="cb4-12"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  1 01           0.592      0.592       0.592         0.592</span></span>
<span id="cb4-13"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  2 02           0.500      0.500       0.500         0.500</span></span>
<span id="cb4-14"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  3 03           0.763      0.763       0.763         0.763</span></span>
<span id="cb4-15"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  4 04           0.663      0.663       0.663         0.663</span></span>
<span id="cb4-16"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  5 05           0.557      0.557       0.557         0.557</span></span>
<span id="cb4-17"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  6 06           0.136      0.136       0.136         0.136</span></span>
<span id="cb4-18"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  7 07           0.412      0.412       0.412         0.412</span></span>
<span id="cb4-19"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  8 08           0.310      0.310       0.310         0.310</span></span>
<span id="cb4-20"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  9 09           0.173      0.173       0.173         0.173</span></span>
<span id="cb4-21"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## 10 10           0.267      0.267       0.267         0.267</span></span></code></pre></div>
<p>At a glance, you can see that the scores are pretty much the same for all 10 speakers across all the versions of the data. We can test this for sure using the <code>near</code> function. Technically, due to rounding errors, the numbers could be <em>very</em> slightly off from each other, so <code>near</code> checks for whether two number are—for all intents and purposes—identical.</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">idahoans_pillai <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sameAB =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">near</span>(pillai_raw, pillai_lob),</span>
<span id="cb5-4">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sameAC =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">near</span>(pillai_raw, pillai_anae),</span>
<span id="cb5-5">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">sameAD =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">near</span>(pillai_raw, pillai_deltaF)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span>
<span id="cb5-7"></span>
<span id="cb5-8"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # A tibble: 10 x 8</span></span>
<span id="cb5-9"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    speaker pillai_raw pillai_lob pillai_anae pillai_deltaF sameAB sameAC sameAD</span></span>
<span id="cb5-10"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    &lt;fct&gt;        &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt; </span></span>
<span id="cb5-11"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  1 01           0.592      0.592       0.592         0.592 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-12"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  2 02           0.500      0.500       0.500         0.500 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-13"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  3 03           0.763      0.763       0.763         0.763 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-14"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  4 04           0.663      0.663       0.663         0.663 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-15"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  5 05           0.557      0.557       0.557         0.557 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-16"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  6 06           0.136      0.136       0.136         0.136 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-17"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  7 07           0.412      0.412       0.412         0.412 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-18"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  8 08           0.310      0.310       0.310         0.310 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-19"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  9 09           0.173      0.173       0.173         0.173 TRUE   TRUE   TRUE  </span></span>
<span id="cb5-20"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## 10 10           0.267      0.267       0.267         0.267 TRUE   TRUE   TRUE</span></span></code></pre></div>
<p>Yeah, so it looks like they’re equal. Regardless of whether you run the pillai score on raw data, data that’s been normalized where F1 and F2 are adjusted independently (Lobanov), data that’s been normalized where F1 and F2 are treated the same (ANAE normalization), or whether F3 and F4 are also included (ΔF), the results are going to be the same.</p>
</section>
<section id="why-does-this-work" class="level2">
<h2 class="anchored" data-anchor-id="why-does-this-work">Why does this work?</h2>
<p>Okay, so we’ve established that they’re the same then. But why?</p>
<p>Well, you may know that normalization doesn’t change the relative positions of the F1 or F2 measurements to each other. It just sort of stretches them out and recenters them. You can think of normalization as taking image of vowel plots (one for each speaker), pasting them in PowerPoint or something,<span class="sidenote">In the case of Lobanov, you actually can only adjust one side and then the other, rather than pulling on the corner, which results in some distortion.</span> and then pulling the corner of them so that they’re all the same size. You can also drag them around so that they’re on top of each other. In the case of log-scale normalization procedures (like ANAE and ΔF) that apply to F1 and F2 at the same time, you can only move them along a diagonal line going from the bottom left to the top right. For Lobanov, you’re free to reposition them any way you’d like. The point is, normalization just stretches/contracts and recenters vowel spaces rather changing individual points’ relative positions.</p>
<p>I can kinda illustrate this by visualizing the same speaker’s data four different ways: once for the raw data and once for each normalization type. First, I’ll have to reshape it a little bit so that all the F1 values are in the same column. I can do that with <code>pivot_longer</code>. Before I do that, I’ll change the raw <code>F1</code> column to <code>F1_raw</code> so that the names all have the same template of <code>{formant}_{procedure}</code>.</p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1">idahoans_reshaped <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> idahoans_norm <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb6-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rename_with</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">paste0</span>(., <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"_raw"</span>), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(F1, F2, F3, F4)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb6-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rename_with</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">str_replace</span>(., <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"norm"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"delta_F"</span>), <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ends_with</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"norm"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb6-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cols =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">starts_with</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F"</span>),</span>
<span id="cb6-5">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">".value"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"method"</span>),</span>
<span id="cb6-6">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_pattern =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(F</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\\</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">d)_(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\\</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">w+)"</span>),</span>
<span id="cb6-7">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"value"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb6-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span>
<span id="cb6-9"></span>
<span id="cb6-10"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # A tibble: 4,400 x 8</span></span>
<span id="cb6-11"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # Groups:   speaker [10]</span></span>
<span id="cb6-12"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    speaker sex    vowel method  F1[,1]   F2[,1]      F3      F4</span></span>
<span id="cb6-13"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    &lt;fct&gt;   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb6-14"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  1 01      female AA    raw    699.    1655.    2019.   3801.  </span></span>
<span id="cb6-15"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  2 01      female AA    anae   714.    1690.      NA      NA   </span></span>
<span id="cb6-16"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  3 01      female AA    deltaF   0.637    1.51     1.84    3.46</span></span>
<span id="cb6-17"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  4 01      female AA    lob      1.15    -0.341   NA      NA   </span></span>
<span id="cb6-18"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  5 01      female AA    raw    685.    1360.    1914.   4257.  </span></span>
<span id="cb6-19"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  6 01      female AA    anae   700.    1388.      NA      NA   </span></span>
<span id="cb6-20"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  7 01      female AA    deltaF   0.624    1.24     1.74    3.88</span></span>
<span id="cb6-21"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  8 01      female AA    lob      1.04    -0.906   NA      NA   </span></span>
<span id="cb6-22"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  9 01      female AA    raw    713.    1507.    2460.   3617.  </span></span>
<span id="cb6-23"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## 10 01      female AA    anae   728.    1539.      NA      NA   </span></span>
<span id="cb6-24"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # … with 4,390 more rows</span></span></code></pre></div>
<p>I’ll then pick a speaker, we’ll say speaker <code>02</code>, and just get their two low back vowels. (There will be NAs in the F3 and F4 columns because they were not involved in the Lobanov or ANAE normalizations.)</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1">s02_reshaped <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> idahoans_reshaped <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb7-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(speaker <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"02"</span>, </span>
<span id="cb7-3">         vowel <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%in%</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AA"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AO"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb7-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span>
<span id="cb7-5"></span>
<span id="cb7-6"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # A tibble: 80 x 8</span></span>
<span id="cb7-7"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # Groups:   speaker [1]</span></span>
<span id="cb7-8"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    speaker sex   vowel method  F1[,1]   F2[,1]      F3      F4</span></span>
<span id="cb7-9"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##    &lt;fct&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;</span></span>
<span id="cb7-10"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  1 02      male  AA    raw    449.    1081.    2593.   3047.  </span></span>
<span id="cb7-11"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  2 02      male  AA    anae   592.    1423.      NA      NA   </span></span>
<span id="cb7-12"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  3 02      male  AA    deltaF   0.478    1.15     2.76    3.24</span></span>
<span id="cb7-13"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  4 02      male  AA    lob      0.196   -0.833   NA      NA   </span></span>
<span id="cb7-14"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  5 02      male  AA    raw    582.    1105.    2593.   3757.  </span></span>
<span id="cb7-15"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  6 02      male  AA    anae   766.    1456.      NA      NA   </span></span>
<span id="cb7-16"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  7 02      male  AA    deltaF   0.619    1.18     2.76    4.00</span></span>
<span id="cb7-17"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  8 02      male  AA    lob      1.68    -0.765   NA      NA   </span></span>
<span id="cb7-18"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">##  9 02      male  AA    raw    512.    1152.    2238.   3655.  </span></span>
<span id="cb7-19"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## 10 02      male  AA    anae   675.    1517.      NA      NA   </span></span>
<span id="cb7-20"><span class="do" style="color: #5E5E5E;
background-color: null;
font-style: italic;">## # … with 70 more rows</span></span></code></pre></div>
<p>I can then plot those four together.</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(s02_reshaped, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> vowel)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">stat_ellipse</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">level =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.67</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-6">  ggthemes<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_color_ptol</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">facet_wrap</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>method, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">scales =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"free"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Four versions of speaker 02's low back vowels"</span>,</span>
<span id="cb8-10">       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"To quote Pam Beesly, </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\"</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">They're the same picture.</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\"</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span></code></pre></div>
<p><img width="85%" src="https://new.joeystanley.com/images/plots/pillai_normalization.png"></p>
<p>So, as you can see, the plots are virtually identical, other than the scales of the <em>x</em>- and <em>y</em>-axes. This might not be the best illustration of what’s going on because <code>ggplot2</code> will automatically stretch and center the data, but maybe it works for you?</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>So there you have it. It doesn’t matter if you calculate pillai scores before or after normalization—at least with the three procedures used here—the results are going to be the same regardless.</p>


</section>

 ]]></description>
  <category>How-to Guides</category>
  <category>Methods</category>
  <category>Phonetics</category>
  <category>R</category>
  <category>Skills</category>
  <category>Vowel Overlap</category>
  <guid>https://new.joeystanley.com/blog/pillai-scores-dont-change-after-normalization/index.html</guid>
  <pubDate>Sat, 06 Feb 2021 21:30:00 GMT</pubDate>
</item>
<item>
  <title>10 Years of Linguistics</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/ten-years-of-linguistics/index.html</link>
  <description><![CDATA[ 




<p>On this day, ten years ago, I decided to major in linguistics. Today, I’m an assistant professor. To celebrate this decade of linguistics, I thought I’d write a little bit about where I came from and how I came to the decision to go into linguistics.</p>
<section id="music" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="music">Music</h2>
<!--### Middle school and high school band

Growing up, I was a total band geek. I had already been playing piano for a a couple years and was pretty good for my age and I did well at the recorder in 4th and 5th grade music classes. When 6th grade came and it was time to choose my fine arts class, band was the obvious choice over orchestra, choir, or general music. I honestly don't remember my reasoning but I chose to learn the saxophone. 

I excelled in band in middle school. I was playing 8th grade material halfway through 6th grade. In 7th grade I was transferred to a brand new middle school and we were now combined with all the other band instruments (flutes, clarinets, saxophones, trumpets, and a few trombones). We had lots of new shiny instruments and way too many saxophonists, so when the director asked if anyone was willing to learn a new instrument, I jumped at the opportunity and signed up for… well, all of them. 

I started off on tuba at my band director's recommendation to fill out the bottom end of the band's sound. I even made regionals on Tuba. I also learned french horn and oboe. I also learned the bass guitar since we had a middle school jazz band but no one to play the bass guitar. It helped too that some of my older siblings were in band but dropped out so I got their old instruments (trombone and flute) and my dad owned a thrift store so I could get a couple others (trumpet, accordion). It got to the point where I could just come into band holding whatever instrument I wanted and my band director wouldn't care. In fact, I had been practicing trumpet for a few days and decided to bring mine to school---the day they did seating tests. How did I do? I got first chair. (This is 7th grade band---it's not like I was amazing or anything.)

My band director this whole time was extremely supportive and saw that I stood out. He took me under his wing and even offered private lessons in his home after school once a week. We'd hang out and eat cereal with his wife and then he'd teach me jazz and stuff. I still like jazz. Thanks, Mr. Marx.

In 8th grade, I got a new band director who didn't approve of me jumping around so much, so I settled on trombone since we didn't have any others. I got first chair in the district band that year too! But when I saw that a piece we were playing had a bassoon part, I asked if I could take one home---less than a week before the concert. So, yes, I played bassoon in a concert after playing it for six days. When it came time to audition for high school band, I really had to settle down, so I auditioned on trombone for marching band and bassoon for concert band. They said that was the strangest combination they had seen. 

High school band was great. Marching band was a lot of fun and I made a lot of friends. I made the district band on trombone and bassoon (I chose bassoon I think) my sophomore year. When the bass trombonist graduated though, I jumped on the opportunity to learn that. So from junior year on, I was a dedicated bass trombone player. Of course when it came time for district band auditions, I had to see how many instruments I could audition on. I don't remember junior year, but my senior year I made it on both trombone and bass trombone (for both jazz and concert bands). I was also an alternate for tuba. (I auditioned for euphonium but didn't get in.)

One new skill that I sort of picked up was arranging music for whatever small ensemble I wanted. Friday mornings they liked having someone from the school sing or play the national anthem, so I arranged a trombone quartet for me and my friends to play. I started doing a couple other brass ensemble pieces too. So by the time I graduated high school I had a small collection of little pieces I had done.


### Music major 

Anyway, so music was my thing. So going into college, I knew that I would be a music major. I got accepted to Brigham Young University, but I was very disappointed that I didn't get accepted into the music school. I auditioned for a performance major, focusing on bass trombone. (In retrospect, I don't think I completed all the application materials.) So I was officially as "pre-music major" which is code for "I still want to do music but I haven't realized I'm not cut out for it." 

My freshman year was great. I met great friends that I'm still in contact with today. I also knocked out all my general education courses in a year, which was nice. I took as many music classes as I could, but it wasn't a lot because most of them are for declared, accepted music majors only. 

At this point, I had had a lot of experience arranging music. I met a lot of other music and pre-music majors my freshman year (they sort of tried to house us all together), so I met a lot of other really good piano players. So, instead of arranging music for brass ensembles, I tried arranging for piano ensembles. Like two people sitting at one piano or four people sitting at two pianos. I typically did movie music, like Star Wars or other John Williams pieces, since BYU's library had a really nice collection of them. My favorites were a 2-piano, 6-player arrangement of a piece from Star Wars ("The Forest Battle") and a 3-piano, 6-player piece from Spiderman (by Danny Elfman). (In fact, now that I'm back at BYU and have access to their library, I've started arranging movie music again---I'm working on Jurassic Park right now.) 

When it came time to audition for the music school again, I auditioned this time to be a "Media Music Major." This was recommended to me by Jeff Shumway, a piano professor in the music faculty who played in an piano quartet. I had always liked movie music anyway and I knew I wasn't cut out for performance. 

Side story. Part of the audition material was an aural skills test. They said the average score for accepted music majors was about 30 questions right out of 64. I was nervous going into it, but was confident I could do well. My score? A 60. I don't know how many people applied to the music school that year (well over a hundred for sure), and I got the second highest score. So even though I knew I wasn't going to make it as a performer, Media Music sounded right. I wanted to be the next John Williams.

Long story short, I got accepted into the music school. Hooray! The problem was I was about to leave on a two-year mission to Brazil. So, I put my acceptance on hold and moved to Brazil to be a full-time missionary. 

-->
<div class="page-columns page-full"><p>Growing up, I was a total band geek. I’ll spare you the details, but I took piano lessons when I was eight, started saxophone in 6th grade band, hopped around to pretty much all the instruments I could for a few years, and finally settled on bass trombone junior year of high school. I wasn’t bad either: I made the district band most years (on trombone plus a couple other instruments) and even the Missouri All-State band my senior year.</p><div class="no-row-height column-margin column-container"><span class="">If you peek into the code of this webpage on Github, there’s a 1200-word summary of my band geekiness and musical background.</span></div></div>
<p>When I started my freshman year at BYU, I auditioned to get into the Brass Performance major, but I didn’t get accepted. So I was officially a “pre-music major”, or rather, the “I-haven’t-realized-I’m-not-cut-out-for-this-yet major.” That gave me a year to knock out most of my general education courses though, which was nice.</p>
<p>I had a fun music hobby though. I’d find movie scores or other songs from the library and I’d arrange them for piano ensembles (like a six-person, two-piano arrangement of a piece from Star Wars). I had been doing that since high school, and BYU seems to have a disproportionate number of people who can play piano, so it was a cinch to find a handful of good sight-readers to play with me. So at the recommendation of a music faculty member I met with one time, I auditioned a second time for the music school, but this time it was to be a Media Music Studies major. And I was accepted!</p>
<p>But, I was 19 years old, and the important thing to do was to go on a full-time, two-year mission. So I took time off from school, knowing my spot in the music school would be waiting for me. I’m so grateful for this break though because without it I would have just barreled through my music major. But the time off gave me the chance to stop and figure out what I was doing with my life.</p>
</section>
<section id="early-signs-that-i-wanted-to-be-a-linguist" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="early-signs-that-i-wanted-to-be-a-linguist">Early signs that I wanted to be a linguist</h2>
<p>Until May 2008, linguistics was not on my radar at all. Like, I didn’t even know what it <em>was</em>. I didn’t even take any foreign language courses in high school.</p>
<p>There were a few signs though. The one I remember most was from when I was in a play my freshman year of high school. I didn’t have a big role, so I had to kill a lot of time in the drama room while the others rehearsed. I was flipping through one of the textbooks and I saw this chart with what’s called the International Phonetic Alphabet. My brother, who had taken a couple theater classes, had mentioned the IPA to me a few years prior. He described it as basically if you can transcribe it well and read it well, you can use it to, in theory, speak in any accent. I remember thinking it was so cool so I copied down all the symbols from that book. [Edit: I found the paper! Here it is!]</p>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://new.joeystanley.com/blog/ten-years-of-linguistics/highschool_IPA.png" class="img-fluid figure-img" style="width:85.0%"></p>
<figcaption class="figure-caption margin-caption">I copied this IPA guide from a theater book in 2003!</figcaption>
</figure>
</div>
<p>Anyway, it was in May of 2008 that I got the call that I’d be a missionary in Brazil. Meaning I’d have to learn Portuguese. Even though I would be spending the first two months of my mission in an intensive language school, I went ahead and tried learning as much as I could beforehand. And it was then that I realized that learning languages was pretty cool! I finally saw the IPA in action, and was able to use it to learn the sounds. But I remember it blew my mind that, for hundreds of millions of people, “house blue” sounds totally normal and “blue house” sounds totally wrong. Blew. My. Mind.</p>
<p>So even before I had left for my mission, I had already been thinking about linguistics. I had even added to my Facebook profile was that I was considering a minor in linguistics. So, getting called to a foreign mission is what put linguistics on my radar for sure.</p>
</section>
<section id="my-time-in-brazil" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="my-time-in-brazil">My time in Brazil</h2>
<p>So I went to Brazil and served my mission. While I was down there, I <em>really</em> enjoyed learning Portuguese. I practiced vocabulary like crazy and studied as much grammar as I could. Some of the other missionaries joked that if anyone needed to talk to a lawyer about the gospel that they should call Elder Stanley because he’s the only one that could understand him. After a year and a half or so, I could convince people that I was Brazilian (my darker complexion helped there)—not a local Brazilian, mind you, but I’d tell them I was from another part of the country. I would get phone calls from other missionaries—native Portuguese-speaking Brazilians!—asking about some nuanced aspect of grammar. It was fun.</p>
<p>You may know that Mormon missionaries have pretty strict rules about what they can and can’t do. At the time, the internet was completely off-limits except to email our parents once a week. Well, I would occasionally sneak on to Wikipedia and look up linguistics pages and print them out and stuff. Of all the ways to rebel, I think looking up IPA symbols was a pretty tame way to do so.</p>
<div class="page-columns page-full"><p>At one point, I was in a city relatively close to Paraguay and would occasionally run into Guaraní speakers. I wrote to my parents about the language, and my dad sent me a Guaraní translation of the <em>Book of Mormon</em> and encouraged me to learn as much of the language as I could. I also met someone who had what was basically a “Teach Yourself Guaraní” textbook (written in Spanish, so I had to quickly learn to read some basic Spanish) so I used that to learn some of the morphology. So in the little free time I had, I spent it trying to learn Guaraní.</p><div class="no-row-height column-margin column-container"><span class="">In retrospect, I’m not sure if they spoke Paraguayan Guaraní because they were Brazilians, but I wonder if they spoke some other Tupí language in that part of the country.</span></div></div>
<div class="page-columns page-full"><p>Towards the end of my mission, I served in a college town and my companion and I went to the university’s bookstore. I bought a Portuguese Phonetics and Phonology textbook and <em>really</em> had fun reading that. I learned about minimal pairs and basic phonological distributions, and I especially enjoyed reading the dialectal variation that it mentioned. During my last month or so, I bought a comprehensive grammar book, one that was written entirely in Portuguese and was meant for Brazilian university students. In fact, my mission president saw me reading it one time and he’s like, “Elder Stanley, aren’t you going home in like three weeks? Why are you reading that?” Why not? It was fascinating!</p><div class="no-row-height column-margin column-container"><span class="">It was Thaïs Cristóforo Silva’s 2007 textbook, <a href="https://www.editoracontexto.com.br/produto/fonetica-e-fonologia-do-portugues-roteiro-de-estudos-e-guia-de-exercicios-nova/1496828"><em>Fonetica e Fonologia do Portugues</em></a>.</span></div></div>
</section>
<section id="realizing-music-wasnt-for-me" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="realizing-music-wasnt-for-me">Realizing music wasn’t for me</h2>
<section id="octoberdecember-2010" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="octoberdecember-2010">October–December 2010</h3>
<p>I got home from my mission in October so I had a few months before the next semester of school started. My plans hadn’t changed yet: I wanted to be the next John Williams so my mind was set on Media Music Studies. But I knew I also wanted to at least minor in linguistics, if not double-major.</p>
<p>Because I was starting in January, I couldn’t start all the the theory and other core classes with the other first-year students because those were only offered in the fall. So I had to sort of fill my semester with fluff. I was able to sign up for the Songwriting class though, which was kinda like the intro to the Media Music Studies major. And since I had a time slot available, I went ahead and signed up for Intro to Linguistics. I also signed up for Acoustics for Music and Speech, band, a non-audition choir, and private bass trombone lessons. So about as much music as I could do without those core classes.</p>
<div class="page-columns page-full"><p>My family visited Utah soon after I got back so I took the opportunity to meet with a linguistics advisor, just to see what classes they’d recommend. It was Alan Melby that I met with, and he recommended I minor in Linguistics Computing. I thought that was a pretty good idea, so I went ahead and signed up for an Intro to Linguistic Computing class as well.</p><div class="no-row-height column-margin column-container"><span class="">Now that I’m on the faculty side of the department, I can see why he pushed the minor: enrollment was low and they were struggling to keep the minor!</span></div></div>
<p>In the meantime, I worked for my dad and spent my free time getting the right equipment and software for my music studies. But I also spent a lot of time studying linguistics. Mostly looking at Wikipedia and other resources online, including lectures that I could listen to while driving. So even though I didn’t know linguistics would eventually be my major (and career), I was already investing a lot of time into learning it and had a decent grasp of a lot of basic topics.</p>
</section>
<section id="wednesday-january-5th-2011" class="level3">
<h3 class="anchored" data-anchor-id="wednesday-january-5th-2011">Wednesday, January 5th, 2011</h3>
<p>First week of classes comes and I walk into my songwriting class full of confidence. This was going to be the first day of the rest of my life[Although, as my brothers point out, this is technically true every day :)]{.aside} That class turned out to be a pivotal moment like I had anticipated, it just wasn’t <em>quite</em> pivotal moment I was expecting.</p>
<p>After going over the syllabus, we learn that the final project was going to be to write and record a pop song. Uh-oh. I don’t listen to pop music. We got a homework assignment that day too: submit the names of three pop artists you think most closely resemble your own style of music. Ummm…&nbsp;what? I was there to learn to write movie music, not learn about pop singers. I had just barely gotten back to the country, so I literally couldn’t even <em>name</em> three artists on the radio[I’d struggle with that today, to be fair.]{.aside} Pop music wasn’t my thing. But the assignment had to be pop music.</p>
<p>Funnily enough, my Intro to Linguistics class was right after that. And I freaking loved it. I wrote in my journal that night that I was already considering changing majors. I think I had known for a long time—<em>really</em> deep down—that I wasn’t cut out for music. This experience in my Songwriting class was just what I needed to come to that realization.</p>
</section>
<section id="thursday-january-6th-2011" class="level3">
<h3 class="anchored" data-anchor-id="thursday-january-6th-2011">Thursday, January 6th, 2011</h3>
<p>The next day, I wrote to my songwriting professor expressing my concern. He said something along the lines of this: “Too bad. I accepted you into this major as a favor to a friend. The odds of you making it as a film score composer are basically zero. Either you expand your horizons or you’re not getting anywhere in the music world. Pop music is where the jobs are so if you can’t keep up, you’re in the wrong major.”</p>
<p>Ouch.</p>
<p>Since middle school, I’d thought of nothing but music and for two years in Brazil, I eagerly anticipated the day when I’d finally start my music classes. And literally in the first hour of the first one, I get a slap in the face, a reality check, and a rude awakening to the fact that I was not going to have a career in music. What was my life for then? Was all that music a waste?</p>
</section>
</section>
<section id="switching-to-linguistics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="switching-to-linguistics">Switching to linguistics</h2>
<section id="friday-january-7th-2011" class="level3">
<h3 class="anchored" data-anchor-id="friday-january-7th-2011">Friday, January 7th, 2011</h3>
<p>I spent several hours that evening looking through classes and figuring out what I was going to do. I considered switching to just a general Music major, but now that the rose-colored glasses were off, it occurred to me that the classes that looked the most fun (like orchestration and score analysis) were only possible after three or four long years of coursework that was <em>not</em> very fun-sounding. I’d have to slog through years of alone time in the practice room and classes I didn’t want to take just to finally get to those fun ones at the very end.</p>
<p>Meanwhile, after taking a closer look at the courses in the linguistics major, I realized that they all sounded really fun! Phonetics? Phonology? Morphology? Sociolinguistics? Language documentation? Sign me up!</p>
</section>
<section id="saturday-january-8th-2011" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="saturday-january-8th-2011">Saturday, January 8th, 2011</h3>
<div class="page-columns page-full"><p>At this point, I was learning towards a double major in (general) music and linguistics, but I was weighing my options. To help me out, I made some charts to see how my semesters would be spent, credit-hour wise. According to my journal, 65% of my time would be spent in music classes. I had already decided my career wouldn’t be in music at that point, so that’d be a lot of time spent doing something that wasn’t going to lead me anywhere.</p><div class="no-row-height column-margin column-container"><span class="">…and this offers a peek into how my mind works and was a early sign I’d do a lot of quantitative work</span></div></div>
<p>So at that point, the decision was clear. If all these music classes sounded lame and all the linguistics classes sounded fun, what was stopping me from switching to linguistics?</p>
</section>
<section id="sunday-january-9th-2011" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sunday-january-9th-2011">Sunday, January 9th, 2011</h3>
<p>My parents have always been extremely supportive of everything I do. They were in the loop on all the developments up to that point, but that afternoon, I Skyped with them to hash a few things out. As expected, they were just as shocked as I was that I was considering switching, but still extremely supportive.</p>
<p>I don’t recall exactly how it all went down, but I know that by the end of that conversation with my parents, my mind was made up: I was going to major in linguistics and minor in linguistics computing.</p>
<div class="page-columns page-full"><p>It’s pretty interesting what my future plans were at that time. I had these grand plans of learning lots of languages (Mandarin, Arabic, and potentially Hebrew), minoring in TESOL, and teaching abroad somewhere. I was already considering a Master’s program (probably based on conversations with my Intro to Linguistics professor). None of that really panned out, but at that point, a PhD and academia were not in the picture.</p><div class="no-row-height column-margin column-container"><span class="">I did end up taking two semesters of Mandarin the next school year.</span></div></div>
<p>I thought it was interesting that I wrote in my journal how much I was looking forward to the Varieties of English class. When I did finally take it a couple semesters later, I was stoked (and it did not disappoint)! Little did I know I’d grow up to be a dialectologist and that I’d be teaching that very course in 10 years’ time. In fact, I taught it in the very same classroom where my Intro to Linguistics class was!</p>
<p>So, at 11:00 on Wednesday the 5th, I was still confident that I’d be a music major. By the evening of Sunday the 9th, I had made up my mind to major in linguistics and was emotionally ready to abandon music studies. It was a tough five days, but that’s all it took. I don’t regret doing music or being in band or learning trombone at all. I still get opportunities to play piano (I’m playing church this Sunday) and I’m still doing arrangements of movie music (I’m working on Jurassic Park right now). But I am <em>soooo</em> glad I didn’t major in it.</p>
</section>
</section>
<section id="starting-linguistics" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="starting-linguistics">Starting linguistics</h2>
<p>I met with a humanities advisor a few days later and showed her my pie charts and she basically said she had nothing to say because it’s clear my mind was made up already. I don’t know when I officially made the switch according to the university systems, but it must not have been much later because soon after that I was calling myself a linguistics major in my journal.</p>
<p>The advisor also recommended I do a study abroad. So the next day, I was looking through potential study abroad programs and found one that went to Ecuador to study Pastaza Kichwa with Dr.&nbsp;Janis Nuckolls. I’ve told Janis this sense then, but that study abroad was what set me into motion to get a PhD and ultimately go into academia. Being there in the field doing rigorous linguistic documentation was a total <em>blast</em>.</p>
<p>Later, she invited me to join her research team, which ultimately led me to a presentation at SSILA and attending my first LSA conference in Boston in 2013. I attended as many sessions as I could, including many in the American Dialect Society meetings. And that’s when I caught the bug. I knew then that I had to do my own research go to more conferences. I had already applied to grad schools at that point, but it was that conference that gave me the determination to present at conferences my first year of grad school (and many times since then).</p>
<div class="page-columns page-full"><p>I’m a little fuzzy on the details about deciding to do a PhD and figuring out what my research focus would be. I know I mentioned to my mission president during my closing interview with him that I was considering a PhD, but it didn’t seem like it was on my radar when I switched to linguistics. I did apply to PhD programs though so it must have been that study abroad that sent me that direction. As far as my research focus, I started off wanted to do language documentation, but at some point I decided on sociolinguistics and, more specifically, dialectology. I’ll have to continue reading my journal and seeing if I can pinpoint exact dates for those too.</p><div class="no-row-height column-margin column-container"><span class="">I do have specifics about when I decided on my dissertation topic. Maybe I’ll do a blog post about that.</span></div></div>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>So that’s it. Ten years ago today is when I decided to major in linguistics. After one difficult homework assignment (that I never finished by the way) and a strongly worded reality check from a professor, it took just five days to abandon the previous decade’s worth of plans to major in music. I look forward to another decade of linguistics and to see where this career will take me!</p>


</section>

 ]]></description>
  <category>Personal</category>
  <guid>https://new.joeystanley.com/blog/ten-years-of-linguistics/index.html</guid>
  <pubDate>Sat, 09 Jan 2021 07:25:00 GMT</pubDate>
</item>
<item>
  <title>“Boustrophedonically”</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/boustrophedonically/index.html</link>
  <description><![CDATA[ 




<p>Earlier this week, I tweeted about a data visualization that I made. I said:</p>
<blockquote class="blockquote">
<p>Okay, I’m trying something out. I have this histogram with one very tall bar and many shorter ones. So to save space, I made that tall bar follow the edge of the plotting area boustrophedonically—my favorite word!—but I’m not sure if I like it. Thoughts?</p>
</blockquote>
<p>I then showed a plot that looked something like this:</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/boustrophedon.png" class="img-fluid"></p>
<p>The data, which comes from a paper I’m working on, is difficult to visualize because the vast majority of the responses is clustered around zero while the rest is spread out a bit. I continued:</p>
<blockquote class="blockquote">
<p>I’m trying to show that the one bar is huge compared to the others, but at the same time I want to show the detail in the smaller bars. Data transformations haven’t seemed to work. No matter what I try I can’t seem to find an effective visualization.</p>
</blockquote>
<p>I got lots and lots of comments from people and people’s thoughts were all over the board. Some said it’s great; others said they didn’t like it. And there were a handful that had very strongly mixed feelings of loving it and hating it. It’s a new kind of plot, so interpretation isn’t super straightforward, but it’s funny, silly, surprising, interesting, and memorable, which is why <em>I</em> think it’s a good one.</p>
<section id="boustrophewhat" class="level2">
<h2 class="anchored" data-anchor-id="boustrophewhat">Boustrophewhat??</h2>
<p>The way the tallest plot sort of goes back along the top can be perfectly described in one fantastic word: <em>boustrophedonically</em>. It’s my favorite word ever. The word has its roots in describing how an ox plows a field and can also describe how Ancient Greek was written. Nowadays, older Millennials just think of playing Snake on a brick phone. You might think it’s so obscure, so long, and so specific that no one could ever find a use for it, but I did manage to find a way to use it <em>twice</em> in a previous blog <a href="../../blog/simulating_chutes_and_ladders">post about Chutes and Ladders</a>.</p>
<p>I first saw plots like these when reading one of Edward Tufte’s books. I don’t have them on me, but I believe it was in <a href="https://www.edwardtufte.com/tufte/books_vdqi"><em>The Visual Display of Quantitative Information</em></a>. <a href="https://twitter.com/gmarmstrong/status/1339706465926455296?s=20">Guthrie McAfee Armstrong</a> points out that that W. E. B. Du Bois used this technique in his visualizations from well over 100 years ago. I believe Tufte showed some of these plots. You can see some of those original visuals in <a href="https://t.co/A2pjBlippi?amp=1">this Medium article</a> that <a href="https://twitter.com/mjskay/status/1339574623512440833?s=20">Matthew Kay</a> pointed me to.</p>
<p>I got lots of great suggestions from people on Twitter, so I thought I’d try out their suggestions so you can judge for yourself which one is the best. I’ll try to credit everyone who made the suggestions: this was truly a group effort here!</p>
</section>
<section id="the-full-height" class="level2">
<h2 class="anchored" data-anchor-id="the-full-height">The full height</h2>
<p><a href="https://twitter.com/JWGrieve/status/1339613750094155776?s=20">Jack Grieve</a> and <a href="https://twitter.com/jtth/status/1339711677311426561?s=20">jordan t. thevenow-harrison</a> suggested I just plot all the data on a mega <em>y</em>-axis. Well, because the first bar is so stinking huge, I’d have to make the plot <em>suuuuuper</em> tall.</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/super_tall.png" class="img-fluid"></p>
<p>This way of visualizing data is not always bad: on March 27, 2020, the New York Times made <a href="https://www.nytimes.com/issue/todayspaper/2020/03/27/todays-new-york-times">an epic plot</a> showing unemployment numbers for that week. But for my data, I don’t know if it’s quite right. Though, see <a href="https://xkcd.com/1162/">this relevant xkcd</a> that <a href="https://twitter.com/BleddwganMiaren/status/1339613093933047808?s=20">Rodolpho Piskorski</a> delightfully reminded me of!</p>
</section>
<section id="log-transformed" class="level2">
<h2 class="anchored" data-anchor-id="log-transformed">Log-transformed</h2>
<p>When you’ve got wildly different heights like this, the first step is to do a transformation of some sort. <a href="https://twitter.com/ctdicanio/status/1339568623397040130?s=20">Christian DiCanio</a> recommended a log transformation like this:</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/log_transformed.png" class="img-fluid"></p>
<p>While it does show all the bars at once, I just can’t fully appreciate the magnitude of the biggest one.</p>
</section>
<section id="split-the-y-axis" class="level2">
<h2 class="anchored" data-anchor-id="split-the-y-axis">Split the <em>y</em>-axis</h2>
<p>A common technique for something like this would be to split the <em>y</em>axis so that there’s a discontinuity and several people recommended this route.</p>
<p>As Hadley Wickham mentions <a href="https://groups.google.com/g/ggplot2/c/jSrL_FnS8kc/m/MvzM_2_jiSIJ">here</a>, there’s no native way in ggplot2 to do a discontinuous <em>y</em>-axis, so I had to sort of fudge it with <a href="https://patchwork.data-imaginist.com/index.html"><code>patchwork</code></a>. Here’s what that plot might look like:</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/chopped_y.png" class="img-fluid"></p>
<p>This method is generally frowned upon though since the amount of real estate devoted to the big plot is disproportionate to the amount of data it actually represents so it hides the magnitude of that big bar.</p>
</section>
<section id="pointing-arrow" class="level2">
<h2 class="anchored" data-anchor-id="pointing-arrow">Pointing arrow</h2>
<p>One workaround is to zoom in to the smaller bars, and just give an indicator of how tall the big one is. I just text with an arrow pointing up.</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/pointing_label.png" class="img-fluid"></p>
<p>This was one that I’ve been considering for a while now, but again, the problem is the real estate issue and it’s difficult to fully appreciate the actual height of that plot.</p>
</section>
<section id="chunky-first-bar" class="level2">
<h2 class="anchored" data-anchor-id="chunky-first-bar">Chunky first bar</h2>
<p><a href="https://twitter.com/tjmahr/status/1339571715467337728?s=20">TJ Mahr’s</a> funny recommendation was to, instead of retaining the bar’s original length, make it wider.</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/chunky.png" class="img-fluid"></p>
<p>Like the boustrophedon, it breaks the <em>xy</em>-coordinate system a histogram relies on, but the main strike against it is that humans aren’t good at judging areas as well as we think we are, so it only sort of does a good job at showing the size.</p>
</section>
<section id="plot-within-a-plot" class="level2">
<h2 class="anchored" data-anchor-id="plot-within-a-plot">Plot within a plot</h2>
<p>Honestly, I think the best workaround would be to take <a href="https://twitter.com/jvcasill/status/1339560493741174788?s=20">Joseph Casillas</a>, <a href="https://twitter.com/msoskuthy/status/1340083524670394369?s=20">Márton Sóskuthy</a>, <a href="https://twitter.com/TimoRoettger/status/1339593352451244041?s=20">Timo Roetger’s</a>, and <a href="https://twitter.com/mayhplumb/status/1339606411920195587?s=20">May Helena Plumb’s</a> recommendations and split the plot into two, one showing the big bar relative to the rest and the other showing the detail of the smaller ones. One way to do this is with a plot within a plot, which I did with the <code>patchwork</code> package again.</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/plot_within_plot.png" class="img-fluid"></p>
<p>Again, probably the best recommendation if I can get that smaller plot to look decent.</p>
</section>
<section id="zoomed-in-plot" class="level2">
<h2 class="anchored" data-anchor-id="zoomed-in-plot">Zoomed in plot</h2>
<p>An alternative to doing the plot-within-a-plot is to make it clearer that there’s a zoom happening, so the relevant portion of the full-size plot is highlighted and linked to the zoomed in one. This is accomplished with <a href="https://ggforce.data-imaginist.com/reference/facet_zoom.html"><code>ggforce::facet_zoom</code></a>, as recommended by <a href="https://twitter.com/justinjhlo/status/1339473347537743873?s=20">Justin Lo</a> and <a href="https://twitter.com/sj2915/status/1339473888485498880?s=20">Sandra Jansen</a>:</p>
<p><img src="https://new.joeystanley.com/blog/boustrophedonically/facet_zoom.png" class="img-fluid"></p>
<p>In this case, I’m not a huge fan of the greyed portion in the upper plot, because it sort of gets in the ways of the bars in the <em>y</em>-axis.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>So, there are lots of ways to do this. Honestly, I freaking love the boustrophedon one and I’m seriously considering including it in the paper. I ran a poll and the slight majority agreed with me:</p>
<blockquote class="twitter-tweet blockquote" data-conversation="none">
<p lang="en" dir="ltr">
Overall impressions?
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/1339599682922680324?ref_src=twsrc%5Etfw">December 17, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>I think because it’s so controversial and because people have such mixed feelings, it made for a really good discussion about the purpose behind the plot, faithfulness to the data, and overall aesthetics. Who knows I’d have so much fun rallying people together over some silly visual?</p>


</section>

 ]]></description>
  <category>Data Viz</category>
  <guid>https://new.joeystanley.com/blog/boustrophedonically/index.html</guid>
  <pubDate>Sat, 19 Dec 2020 04:51:00 GMT</pubDate>
</item>
<item>
  <title>New publication in the latest PADS volume</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/new-publication-in-the-latest-pads-volume/index.html</link>
  <description><![CDATA[ 




<p>This week I finally got to lay my hands on a physical copy of my latest publication! It’s called <a href="https://read.dukeupress.edu/pads/article/105/1/95/167300/6-The-Absence-of-a-Religiolect-Among-Latter-Day">“The Absence of a Religiolect among Latter-day Saints in Southwest Washington”</a> and it’s in the latest Publication of the American Dialect Society, <a href="https://read.dukeupress.edu/pads/issue/105/1"><em>Speech in the Western States Volume III: Understudied Dialects</em></a> by Valerie Fridland, Alicia Wassink, Lauren Hall-Lew, &amp; Tyler Kendall. The physical copy was delivered to my office about two weeks ago, but my wife and daughter had just tested positive for covid-19 (they’re fine—very mild symptoms) so I was only just now able to see it now that my two-week quarantine is over.</p>
<p><img src="https://new.joeystanley.com/blog/new-publication-in-the-latest-pads-volume/pads_chapter.JPG" class="img-fluid"></p>
<section id="a-brief-bit-of-background" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="a-brief-bit-of-background">A brief bit of background</h2>
<p>I’m so excited to make it into this PADS volume! Just to give a brief timeline, I decided that I wanted to study English in the West around January 2015, after attending the American Dialect Society annual meeting in Portland and seeing the great talks on language in the West there. I did as much background and reading as I could over the next year or so and put together a grant proposal to go do fieldwork in southwest Washington. So when the first volume came out in January 2016, I was thrilled to see the latest research and to know that my research idea was a hot topic in American dialectology. That <a href="https://read.dukeupress.edu/pads/issue/101/1">first volume</a>, which covered California, Oregon, and Washington was extremely important in helping me shape my own research.</p>
<div class="page-columns page-full"><p>In 2016, my research in the West began in earnest. I got my grant to go do fieldwork and spend June and July in Cowlitz County. I had processed enough of the wordlist data in time to submit a paper to the American Dialect Society annual meeting. I was excited because it was my first big conference and was my introduction to the field as a dialectologist. Around that time <a href="https://read.dukeupress.edu/pads/issue/102/1"><em>Speech in the Western States Volume II</em></a> came out, which focused on the Mountain West and included chapters on Arizona, New Mexico, Nevada, Utah, Colorado, and Montana. I was bummed I wasn’t able to make it into that volume, but I really didn’t have anything relevant to that area at the time and my research was in the beginning stages still.</p><div class="no-row-height column-margin column-container"><span class="">Being excited about this meeting was the <a href="../../blog/ads-meeting">first thing I blogged about</a>!</span></div></div>
<p>So at that point, I figured I had missed the train. I hopped on the West bandwagon just a year or so too late—soon enough to really benefit from the current research, but not soon enough to be a part of that first conversation. Nevertheless, my research continued.</p>
<p>I had finished processing my Washington data and was working on my dissertation when I heard about a third volume of <em>Speech in the Western States</em>, this time focusing not on any geographic area within the West but rather on understudied communities. While I didn’t have any data from ethnic minorities from Washington, it did occur to me that I had a nice balance of members of the Church of Jesus Christ of Latter-day Saints to non-members. So I put together an abstract that compares the two groups, sent it to the editors, and the rest is history.</p>
<p>So I am just thrilled to be a part of this last volume on <em>Speech in the Western States</em>. The first two volumes were so important as my research was developing and so it just made it that much sweeter to be a part of the last volume.</p>
</section>
<section id="a-brief-summary-of-the-chapter" class="level2">
<h2 class="anchored" data-anchor-id="a-brief-summary-of-the-chapter">A brief summary of the chapter</h2>
<p>The question I had was this: do Latter-day Saints in southwest Washington sound different than non–Latter-day Saints? In other words, do they have a religiolect? I thought they might since they do in Utah and in Southern Alberta. Specifically, they tend to have more (or more exaggerated) Utah English features and tend to lag behind regional language changes. I thought I’d test for that same thing in Washington since I had a nice, balanced sample of Latter-day Saints to non–Latter-day Saints.</p>
<p>So, using fancy statistics and looking at vowels known to be variable in Utah and Washington, I conclude that there was very little difference between the two groups. So, a null result. The question then is this, why not? Why don’t Washingtonian Latter-day Saints have a religiolect while Albertan and Utahn Latter-day Saints do? I got into a lot of detail on Latter-day Saint culture and history and eventually conclude that they’re just too small of a minority, aren’t locally salient enough, and aren’t as entrenched in Latter-day Saint culture for a religiolect to have developed.</p>
</section>
<section id="lots-of-qualitative-analysis" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="lots-of-qualitative-analysis">Lots of qualitative analysis</h2>
<p>Overall the paper is dense. The whole chapter is 28 PDF pages, and a quarter of that is just references! I tend to be a little citation-heavy in all my writing to be honest, but over 100 references in this otherwise relatively short paper might have been a little much… But I had a lot of things to bring in: Utah English, Washington English, Latter-day Saints, religiolect, and GAMMs.</p>
<p>You may notice that the paper is and is a bit very top-heavy as well. If you just take the 6,962 words of actual body text, 2,967 of them (43%) is background and lit review. I go into a lot of detail on Utah English and Washington English, not to mention detail on Latter-day Saint culture and history. I then have 2,098 words (30%) of methods, which was also necessary since GAMMs can take a while to explain. I even had to leave out a lot of detail and refer readers to my dissertation! So you don’t even get to the linguistic analysis until three-quarters of the way into the paper!</p>
<div class="page-columns page-full"><p>The actual results are only 982 words (14%), but I think I made some good visualizations that explain things better than words do. Besides, it’s a null-result paper, so there’s not a lot to say other than, “nope and this isn’t significant either.” Finally, I finish with another 915 words (13%) of discussion and conclusion, which again go into detail about Latter-day Saint culture.</p><div class="no-row-height column-margin column-container"><span class="">In fact, a stylized version of one of my plots made its way to the cover of the book!</span></div></div>
<p>And, on top of all this this is three pages of notes, some of which are pretty long, an appendix with more visuals, and online supplementary material. So, a lot of background for what turns out to be relatively little actual phonetic analysis, but I think all that background was important to really appreciate the overall message of the paper. I think it strikes a nice balance of qualitative and quantitative work.</p>
</section>
<section id="my-favorite-parts" class="level2">
<h2 class="anchored" data-anchor-id="my-favorite-parts">My favorite parts</h2>
<p>One thing I’m particularly pleased with in that paper is the map on page 96. This one map shows a lot of information all at once, pulled together from a few different sources. First, it shows state and county boundaries, which come from publicly available sources. Those counties are then colored by number of Latter-day Saints per 1000 residents, which was data I had to pull from the US Religion Census. Finally, there are the outlines of the “Mormon Culture Region,” which was defined in Meinig (1965). For that, I had to scan in the original map and basically trace the original boundaries onto the digital map. I’m quite pleased with how it turned out, and the publishing editors did a fantastic job at sprucing it up so that it matches the look and feel of <em>American Speech</em> articles.</p>
<p><img src="https://new.joeystanley.com/blog/new-publication-in-the-latest-pads-volume/figure6-1.png" class="img-fluid"></p>
<p>Another thing that this paper introduces is a method of outlier detection that I’ve been working on for a few years. I’ll give more detail on a future blog post, and perhaps a publication all on its own, but for now, you can read the details in page 102.</p>
<p>Finally, I quite like deep dives that I took in some of the footnotes. In particular, Note 2 gives a brief history of the Church of Jesus Christ of Latter-day Saints in Cowlitz County. This was data that was also pulled from several sources. I had to ask my mother-in-law if she knew any old-timers who might be able to fill in some of the gaps, which was very helpful. But my friend Jonathan Hepworth, a history PhD student at the University of Georgia, was the most help. He was able to track down some primary sources that helped fill in some of the details (like the date of creation of the Longview Stake)—and he did so in like an hour! I’m amazed at the resources that historians have access to.</p>
<p>Anyway, so that’s it for this paper.</p>


</section>

 ]]></description>
  <category>Pacific Northwest</category>
  <category>Publications</category>
  <category>Research</category>
  <category>West</category>
  <guid>https://new.joeystanley.com/blog/new-publication-in-the-latest-pads-volume/index.html</guid>
  <pubDate>Sat, 05 Dec 2020 04:11:00 GMT</pubDate>
</item>
<item>
  <title>generations: Convert birth years to generation names</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/generations/index.html</link>
  <description><![CDATA[ 




<p>I’m happy to announce the release of another R package, <code>generations</code>! I’ve apparently caught the creating-R-packages bug because this is my fourth one this year (<a href="../../blog/futurevisions-my-first-r-package"><code>futurevisions</code></a>, <a href="../../blog/barktools"><code>barktools</code></a>, <a href="../../blog/joeysvowels"><code>joeysvowels</code></a>, and now <code>generations</code>). This one provides some functions to easily convert years to generational cohorts (Boomer, Gen X, Millennial, Gen Z, etc.).</p>
<p>I recently read Howe &amp; Strauss’ book, <em><a href="https://www.amazon.com/Generations-History-Americas-Future-1584/dp/0688119123">Generations: The History of America’s Future, 1584 to 2069</a></em>. While the generational theory they propose isn’t water-tight, it is intriguing. Relatedly, I’ve seen lots of linguistics studies that model age in generational cohorts. (Ideally, we’d model age as a continuous variable, of course, but sometimes there’s just not enough data to do so.) I used a categorical age variable in the models in my dissertation and in other recent studies and, while it’s not perfect, it seems to work well enough.</p>
<p>Well, so now that I’m converting age into generational cohorts in lots of different projects, my code is starting to get a little repetitive. And in the R world, they say if you end up writing the same code a lot, might as well wrap it up into a package. This idea came to me about a week ago and this weekend I found some time to put this together.</p>
<p>The result is <code>generations</code>. And, I’ve made it so that it doesn’t depend on any other packages, so it was fun for me to figure out how to do some things in base R that I only knew how to do in tidyverse, which was fun for me! The rest of this post is the readme page for the package. You can find more about the package at <a href="https://joeystanley.github.io/generations/">joeystanley.github.io/generations</a>.</p>
<section id="installation" class="level2">
<h2 class="anchored" data-anchor-id="installation">Installation</h2>
<p>The package currently lives on GitHub, so you can install it like you would with any other package on GitHub:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">remotes<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install_github</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"joeystanley/generations"</span>)</span></code></pre></div>
</div>
<p>You can then load it like you can with any library.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(generations)</span></code></pre></div>
</div>
<p>For the purposes of this tutorial, I’ll load <code>ggplot</code> and <code>dplyr</code> as well.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span></code></pre></div>
</div>
</section>
<section id="converting-years-to-generations" class="level2">
<h2 class="anchored" data-anchor-id="converting-years-to-generations">Converting years to generations</h2>
<p>The main function in this package is <code>generations()</code>. Given a vector of integers, it’ll return a factor of generation names. First, I’ll generate some random years of birth.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1">yobs <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">floor</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">runif</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1900</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2020</span>))</span>
<span id="cb4-2">yobs</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] 1972 1932 1987 2018 1974 1979 1952 1937 1994 1980</code></pre>
</div>
</div>
<p>I can now easy convert that into generations.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generations</span>(yobs)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] Gen X      Silent     Millennial Gen Z      Gen X      Gen X     
 [7] Boomer     Silent     Millennial Gen X     
Levels: Silent Boomer Gen X Millennial Gen Z</code></pre>
</div>
</div>
<p>This function works on any year between 1435 and 2030. Numbers outside that range return <code>NA</code>.</p>
<p>Note that by default, the function will return the vector as <em>factor</em>, with the levels ordered so that the oldest generation in the vector is first. To get a character vector instead, add the argument <code>as_factor = FALSE</code>.</p>
<section id="customizing-output" class="level3">
<h3 class="anchored" data-anchor-id="customizing-output">Customizing output</h3>
<p>There are some tweaks you can do to adjust the output of <code>generations</code>. First, you can return longer forms of the generational names by specifying <code>full_names = TRUE</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generations</span>(yobs, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">full_names =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] Generation X          Silent Generation     Millennial Generation
 [4] Generation Z          Generation X          Generation X         
 [7] Boomer Generation     Silent Generation     Millennial Generation
[10] Generation X         
5 Levels: Silent Generation Boomer Generation ... Generation Z</code></pre>
</div>
</div>
<p>What this does is simply add <code>"Generation"</code> to the end of each one, unless it’s <code>"Gen X"</code> (or Y, or Z), in which case it’ll expand it out to simply <code>"Generation X"</code>.</p>
<p>You can also show the years included in each generation by adding the <code>years = TRUE</code> argument. This will add a space and, inside a pair of parentheses, the start and end years of that generation, separated by an en dash.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generations</span>(yobs, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">years =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] Gen X (1964–1983)      Silent (1929–1945)     Millennial (1984–2007)
 [4] Gen Z (2008–2030)      Gen X (1964–1983)      Gen X (1964–1983)     
 [7] Boomer (1946–1963)     Silent (1929–1945)     Millennial (1984–2007)
[10] Gen X (1964–1983)     
5 Levels: Silent (1929–1945) Boomer (1946–1963) ... Gen Z (2008–2030)</code></pre>
</div>
</div>
<p>The primary purpose of this is for visualizations, since not everyone is familiar with (or agrees with) the year ranges. For example, if you’ve got a bunch of people and want to visualize the distribution of when they were born, you could have very informative legends.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1">many_yobs <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">tibble</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">yob =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">floor</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rnorm</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1975</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">15</span>))) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb12-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">gen =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generations</span>(yob, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">full_names =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">years =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>))</span>
<span id="cb12-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(many_yobs, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(yob, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> gen)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb12-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_histogram</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">binwidth =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb12-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_fill_brewer</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">palette =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Set1"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/generations/index_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>How this additional portion is formatted can be adjusted. If rendering an en dash is troublesome for you, you can change it to something else with <code>years_range_sep</code>. You may also want to change the space between the generation name and the opening parenthesis into a newline character with <code>years_sep</code>, again for visualization purposes.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1">many_yobs <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> many_yobs <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb13-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">gen =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generations</span>(yob, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">full_names =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">years =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">TRUE</span>,</span>
<span id="cb13-3">                           <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">years_sep =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">years_range_sep =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">" to "</span>))</span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(many_yobs, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(yob, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> gen)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_histogram</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">binwidth =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_fill_brewer</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">palette =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Set1"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb13-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">legend.key.height =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unit</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"cm"</span>))</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/generations/index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>If you want to get really fancy, you can make the legend keys approximate the width they take up on the <em>x</em>-axis and put better tics marks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1">widths <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> many_yobs <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(gen) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(yob) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">min</span>(yob)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ungroup</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb14-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">width =</span> width <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(width) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.4</span>) <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># you may have to fudge this a little more</span></span>
<span id="cb14-6"></span>
<span id="cb14-7"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(many_yobs, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(yob, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> gen)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_histogram</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">binwidth =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_fill_brewer</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">name =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">palette =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Set1"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_continuous</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1929</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1946</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1964</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1984</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2008</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2030</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">x =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">NULL</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-12">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">legend.position =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bottom"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb14-13">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">guides</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">fill =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">guide_legend</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">nrow =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">label.position =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bottom"</span>, </span>
<span id="cb14-14">                             <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">keywidth =</span> widths<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">$</span>width, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">default.unit =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"inches"</span>))</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/generations/index_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="querying-generation-data" class="level2">
<h2 class="anchored" data-anchor-id="querying-generation-data">Querying generation data</h2>
<p>To see a list of the generational data, you can use <code>show_generations()</code>, which will return a data frame containing the names, start years, and end years.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">show_generations</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             name start  end
1           Gen Z  2008 2030
2      Millennial  1984 2007
3           Gen X  1964 1983
4          Boomer  1946 1963
5          Silent  1929 1945
6            G.I.  1908 1928
7            Lost  1886 1907
8      Missionary  1865 1885
9     Progressive  1844 1864
10         Gilded  1822 1843
11 Transcendental  1794 1821
12     Compromise  1773 1793
13     Republican  1746 1772
14        Liberty  1727 1745
15      Awakening  1704 1726
16  Enlightenment  1675 1703
17       Glorious  1649 1674
18       Cavalier  1621 1648
19        Puritan  1594 1620
20  Parliamentary  1569 1593
21    Elizabethan  1542 1568
22       Reprisal  1517 1541
23    Reformation  1497 1516
24       Humanist  1459 1496
25     Aurthurian  1435 1458</code></pre>
</div>
</div>
<p>You can also get simple information. For example, if you want to know when the start or end year of a particular generation is, you can use <code>get_start()</code> or <code>get_end()</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get_start</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Silent"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1929</code></pre>
</div>
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get_end</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Millennial"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2007</code></pre>
</div>
</div>
<p>You can also find the names of neighboring generations with <code>get_prev_gen()</code> and <code>get_next_gen()</code>, though these were mostly created for internal purposes only rather than for you to use.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get_next_gen</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Millennial"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Gen Z"</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">get_prev_gen</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Missionary"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] "Progressive"</code></pre>
</div>
</div>
<p>Note that if ask for something newer than Gen Z or older than Aurthurian it will return <code>NA</code>.</p>
</section>
<section id="customizing-generation-data" class="level2">
<h2 class="anchored" data-anchor-id="customizing-generation-data">Customizing generation data</h2>
<p>The data that this package uses is loaded as a hidden object when you load the package. You may modify it with the functions described in this section. These changes will affect the dataset so long as the <code>generations</code> package is loaded. You’ll have to reset the data each time to reload it.</p>
<p>The labels and years for each generation are mostly borrowed from Howe &amp; Strauss’ Generational Theory books. However, not everyone agrees on the names and year ranges for the various generations. For this reason, the <code>generations</code> package makes it easy to modify the generations data to your liking.</p>
<p>To rename a generation, use <code>rename_generation()</code>, with the old name first and the new name second. For example, if you want to use <em>Zoomer</em> instead of <em>Gen Z</em>, you can do so.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rename_generation</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Gen Z"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Zoomer"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Gen Z has been renamed Zoomer</code></pre>
</div>
</div>
<p>You’ll get a message informing you that the change has been made. If you now run <code>show_generations()</code> you’ll see that the change has been made and if you rerun <code>generations()</code>, you’ll get updated results.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">show_generations</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             name start  end
1          Zoomer  2008 2030
2      Millennial  1984 2007
3           Gen X  1964 1983
4          Boomer  1946 1963
5          Silent  1929 1945
6            G.I.  1908 1928
7            Lost  1886 1907
8      Missionary  1865 1885
9     Progressive  1844 1864
10         Gilded  1822 1843
11 Transcendental  1794 1821
12     Compromise  1773 1793
13     Republican  1746 1772
14        Liberty  1727 1745
15      Awakening  1704 1726
16  Enlightenment  1675 1703
17       Glorious  1649 1674
18       Cavalier  1621 1648
19        Puritan  1594 1620
20  Parliamentary  1569 1593
21    Elizabethan  1542 1568
22       Reprisal  1517 1541
23    Reformation  1497 1516
24       Humanist  1459 1496
25     Aurthurian  1435 1458</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb29" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">generations</span>(yobs)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code> [1] Gen X      Silent     Millennial Zoomer     Gen X      Gen X     
 [7] Boomer     Silent     Millennial Gen X     
Levels: Silent Boomer Gen X Millennial Zoomer</code></pre>
</div>
</div>
<p>Because people may want to use the term <em>Zoomer</em> instead of <em>Gen Z</em>, a shortcut function, <code>use_zoomer()</code>, which is just a wrapper around <code>rename_generation("Gen Z", "Zoomer")</code>, is included in the package. The other shortcut functions are <code>use_gen_y()</code>, <code>use_13th()</code>, <code>use_baby_boom()</code> as well as their reciprocals <code>use_gen_z()</code>, <code>use_millennial()</code>, <code>use_gen_x()</code> and <code>use_boomer()</code>.</p>
<p>You may also want to change the years. For example, many people consider 1997 as the end of the Millennial Generation. You can make this change with <code>redefine_generation()</code>. With this function, you must specify the new start and the new end year.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb31" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">redefine_generation</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Millennial"</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1983</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1997</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Gen X is now from 1964 to 1982</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Millennial is now from 1983 to 1997</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Zoomer is now from 1998 to 2030</code></pre>
</div>
</div>
<p>Since changing one generation impacts adjacent generations, you’ll get a message showing you what the new ranges are for this, the previous, and the next generations.</p>
<p>You can reset the data back to its original form with <code>reset_generations()</code>.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>That’s the package so far! I plan on adding more things in the future, primarily to handle stability issues and to include some error catching. Hopefully, if you use generational cohorts in your data, this package is useful for you.</p>


</section>

 ]]></description>
  <category>Github</category>
  <category>R</category>
  <category>R Packages</category>
  <guid>https://new.joeystanley.com/blog/generations/index.html</guid>
  <pubDate>Mon, 19 Oct 2020 04:11:00 GMT</pubDate>
</item>
<item>
  <title>joeysvowels: An R package of vowel data</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/joeysvowels/index.html</link>
  <description><![CDATA[ 




<p>I’ve just released my third R package, <a href="https://joeystanley.github.io/joeysvowels/"><code>joeysvowels</code></a>. It provides a handful of datasets, some subsets of others, that contain formant measurements and other information about the vowels in my own speech. The purpose of the package is to make vowel data easily accessible for demonstrating code snippets when demonstrating how to work with sociophonetic data. There are no functions contained in <code>joeysvowels</code>; it’s a data-only package.</p>
<p>This is my third package. My first one, <a href="https://github.com/JoeyStanley/futurevisions"><code>futurevisions</code></a>, contains a collection of color palettes. The second is <a href="https://joeystanley.github.io/barktools/"><code>barktools</code></a>, which helps you work with Barks in your sociophonetic data (and even has its own hex!). Technically, I have another package called <a href="https://joeystanley.github.io/joeyr/"><code>joeyr</code></a> that is sort of my sandbox package that I use it all the time and has useful functions for sociophonetic work but it’s not quite ready for distribution yet.</p>
<p>Why create a data-only package? A lot of it had to with my <code>barktools</code> and <code>joeyr</code> packages. As I was developing websites for them using <code>pkgdown</code>, I wanted to create some better help files and examples. To do that, I needed real vowel data to work with. So for a while I had a couple datasets built into each of those packages. Sometimes the same dataset was included with both packages, which is fine by themselves, but since I often had both loaded in the same script, it created a small clash. I figured I should just offload the data from the two packages onto a third one, which would then be a dependency of both. Thus <code>joeysvowels</code> was born!</p>
<section id="installation" class="level2">
<h2 class="anchored" data-anchor-id="installation">Installation</h2>
<p>You can install <code>joeysvowels</code> through GitHub:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1">remotes<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install_github</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"joeystanley/joeysvowels"</span>)</span></code></pre></div>
</div>
<p>You can then load the package like normally:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(joeysvowels)</span></code></pre></div>
</div>
<p>I’ll load a few other packages for the purposes of this post.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(ggplot2)</span>
<span id="cb3-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyr)</span>
<span id="cb3-3"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(dplyr)</span></code></pre></div>
</div>
</section>
<section id="contents" class="level2">
<h2 class="anchored" data-anchor-id="contents">Contents</h2>
<p>Currently, there are six datasets contained in <code>joeysvowels</code>. You can access them using <code>data()</code>. I’ll briefly visualize the datasets.</p>
<section id="a-messy-dataset-darla" class="level3">
<h3 class="anchored" data-anchor-id="a-messy-dataset-darla">A messy dataset: <code>darla</code></h3>
<p><code>darla</code> is one that was prepared using pretty standard methods, using the DARLA web interface to automatically transcribe, force-align, and extract formants from the audio. The audio was me reading 300 prepared sentences. It’s a bit of a noisy dataset, so it’s a good example of working with real data and testing out various outlier detection functions. It is also very close to the format that FAVE exports its data, so any tutorials that use FAVE-produced spreadsheets can be followed along using <code>darla</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(darla)</span>
<span id="cb4-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(darla, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> vowel)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_reverse</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/joeysvowels/index_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="cleaner-datasets-coronals-and-its-subsets" class="level3">
<h3 class="anchored" data-anchor-id="cleaner-datasets-coronals-and-its-subsets">Cleaner datasets: <code>coronals</code> and its subsets</h3>
<p><code>coronals</code> is a much cleaner, more controlled dataset. You can read about the methods by viewing the documentation (<code>?coronals</code>). Essentially, I read a bunch of (C)CVC(C) nonce words where the consonants were (almost) all coronal. All my vowel phonemes are represented. I aligned and extracted formants from the data myself. Four formants were extracted every 5% of the vowels’ durations, so great for demonstrating functions and visuals involving vowel trajectories.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(coronals)</span>
<span id="cb5-2">avg_trajs <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> coronals <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">group_by</span>(vowel, percent) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">summarize</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">across</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(F1, F2), mean)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">print</span>()</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 273 × 4
# Groups:   vowel [13]
   vowel percent    F1    F2
   &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
 1 LOT         0  454. 1616.
 2 LOT         5  592. 1346.
 3 LOT        10  648. 1283.
 4 LOT        15  651. 1238.
 5 LOT        20  661. 1178.
 6 LOT        25  651. 1176.
 7 LOT        30  636. 1152.
 8 LOT        35  630. 1148.
 9 LOT        40  633. 1153.
10 LOT        45  625. 1158.
# ℹ 263 more rows</code></pre>
</div>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(avg_trajs, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> vowel)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb7-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">group =</span> vowel), </span>
<span id="cb7-3">            <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">arrow =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">arrow</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">angle =</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">length =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unit</span>(<span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.15</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"in"</span>), <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">type =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"closed"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb7-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb7-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_reverse</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/joeysvowels/index_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>If you don’t care about trajectories but would like something clearer than <code>darla</code>, then <code>midpoints</code> what you’ll want. It’s a subset of <code>coronals</code> and contains only the midpoints from F1 and F2.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(midpoints)</span>
<span id="cb8-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(midpoints, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> vowel)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_reverse</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/joeysvowels/index_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>If you just need to demonstrate one vowel’s trajectory, check out <code>mouth</code> since it’s only the <sc>mouth</sc> (/aw/) vowel.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(mouth)</span>
<span id="cb9-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(mouth, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(percent, hz, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> formant)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">group =</span> traj_id))</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/joeysvowels/index_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><code>mouth_lite</code> is a subset of <code>mouth</code> and trims away most of the columns and only contains 10 tokens.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(mouth_lite)</span>
<span id="cb10-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(mouth_lite, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(percent, hz, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> formant)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb10-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_path</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">group =</span> traj_id))</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/joeysvowels/index_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="multiple-speakers-idahoans" class="level3">
<h3 class="anchored" data-anchor-id="multiple-speakers-idahoans">Multiple speakers: <code>idahoans</code></h3>
<p><code>idahoans</code> contains formant measurements from 11 individuals from the state of Idaho in the US.<span class="sidenote">These participants did consent to their data being used for teaching purposes and to be distributed to interested researchers.</span> I needed something to test out some functions that do vowel normalization and relying on my own voice wasn’t going to cut it. It’s not a full dataset: for each of the 10 speakers, there are ten tokens per canonical monophthong, randomly selected from a larger dataset. But it should be enough for illustrative purposes. Plus, when was the last time you saw acoustic data from Idaho??</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">data</span>(idahoans)</span>
<span id="cb11-2"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(idahoans, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> vowel)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb11-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb11-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb11-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb11-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">facet_wrap</span>(<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">~</span>speaker)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/joeysvowels/index_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>That’s it so far! Feel free to use the datasets for teaching and demos. That’s what they’re there for.</p>


</section>

 ]]></description>
  <category>Github</category>
  <category>Methods</category>
  <category>Phonetics</category>
  <category>R</category>
  <category>R Packages</category>
  <category>Side Projects</category>
  <category>Teaching</category>
  <category>West</category>
  <guid>https://new.joeystanley.com/blog/joeysvowels/index.html</guid>
  <pubDate>Wed, 30 Sep 2020 08:28:00 GMT</pubDate>
</item>
<item>
  <title>A big list of Mary-merry-marry words</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/mary-merry-marry/index.html</link>
  <description><![CDATA[ 




<p>Most Americans, including me, have this thing called the <em>Mary-merry-marry</em> merger. We pronounce all three words—and the vowels in similarly patterning words—the same. However, some Americans retain at least a two-way distinction and most, if not all, varieties of English outside of North America distinguish between all three.</p>
<p>As is typical for people with a merger, it’s not easy for me to separate words into their historic distributions. But sometimes I need to for teaching or preparing wordlists. So, as I prepared to cover the merger (or rather, the lack thereof) in my Varieties of English course this semester, I wanted to show the students a list of words that group with <em>Mary</em>, <em>merry</em>, and <em>marry</em>. But I couldn’t find a decent list anywhere. So I asked Twitter and I was pleasantly surprised to get lots of help from my non-merging followers!</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Is there a wordlist somewhere (perhaps an appendix to a paper) with a decent list of MARY, MERRY, and MARRY words? <br><br>(I know the list wouldn't be universal for all non-mergers, but as a MMM-merger myself, I have zero intuition about this stuff.)
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/1306359729933832193?ref_src=twsrc%5Etfw">September 16, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Thank you to all those who sent me lists of words that belong to each class! And to those who pointed me to searchable dictionaries that distinguish between the three! I won’t mention names here, but I hope they are okay with me turning their collective input into a blog post.</p>
<p>So, the purpose of this post is to provide the most comprehensive list I could come up with of <sc>Mary</sc>, <sc>merry</sc>, and <sc>marry</sc> words—the list I was hoping to find a few days ago—just in case any other American needs it.</p>
<p>Note: I’m told that outside the US, there is little variation in which class each word belongs to. However, in areas of North America that do make some distinction, there can be some variability. So I guess take this list with a grain of salt.</p>
<section id="merry" class="level2">
<h2 class="anchored" data-anchor-id="merry"><sc>merry</sc></h2>
<p>The first set, <sc>merry</sc>, is actually the <sc>dress</sc> lexical set. John Wells <a href="http://phonetic-blog.blogspot.com/2009/08/my-colleague-patricia-ashby-consulted.html">points out</a> that <sc>merry</sc> is typically spelled with &lt;e&gt;. It also seems like a lot of French words have this vowel.</p>
<p>Here are some words that were verified by some folks who do not have the merger.</p>
<p style="margin-left:35px; background-color: #BFD5ED; padding:5px; border-radius:7px">
<i>berry</i>, <i>beryl</i>, <i>burial</i>, <i>bur{y|ied}</i>, <i>cherry</i>, <i>derring-do</i>, <i>Derry</i>, <i>error</i>, <i>derriere</i>, <i>ferret</i>, <i>ferrous</i>, <i>ferry</i>, <i>Gerry</i>, <i>inherit(ed)</i>, <i>Jerry</i>, <i>Kerry</i>, <i>merit(s)</i>, <i>Merovingian</i>, <i>Merriam</i>, <i>Merrion</i>, <i>Merrow</i>, <i>merry</i>, <i>Perrier</i>, <i>Perry</i>, <i>perry</i>, <i>seropositive</i>, <i>sherry</i>, <i>skerry</i>, <i>steril{e|ize}</i>, <i>terrier</i>, <i>terribl{e|y}</i>, <i>terror</i>, <i>terrif{y|ied}</i>, <i>Terry</i>, <i>verisimilitude</i>, <i>very</i>, <i>wherry</i> <!--xeriscape, query, care-->
</p>
<p>Here’s a more complete list from the Britphone dictionary, based on the search pattern “ˈɛ ɹ” with a few additions from <em>The Routledge Dictionary of Pronunciation for Current English</em>, based on the search pattern “ɛr|”.</p>
<p style="margin-left:35px; background-color: #BFD5ED; padding:5px; border-radius:7px">
<i>America{s|n|ns}</i>, <i>atmospheric</i>, <i>beret</i>, <i>burial</i>, <i>cerebral</i>, <i>ceremony</i>, <i>chemotherapy</i>, <i>cherish</i>, <i>Cheryl</i>, <i>clerical</i>, <i>Derek</i>, <i>deterren{t|ce}</i>, <i>equerry</i>, <i>Eri{c|k}</i>, <i>Ericsson</i>, <i>experiment(s)</i>, <i>generic</i>, <i>Gerald</i>, <i>Herald</i>, <i>Hereford</i>, <i>Herefordshire</i>, <i>heritage</i>, <i>heroin</i>, <i>heron</i>, <i>inherent</i>, <i>inheritance</i>, <i>Jeremy</i>, <i>knobkerrie</i>, <i>merrily</i>, <i>necessarily</i>, <i>numeric(al)</i>, <i>peril</i>, <i>perish</i>, <i>primarily</i>, <i>prosperity</i>, <i>referral(s)</i>, <i>serif</i>, <i>severity</i>, <i>sheriff</i>, <i>stereo</i>, <i>stereotype</i>, <i>terrace</i>, <i>territor{y|ies}</i>, <i>terrorism</i>, <i>terrorist(s)</i>, <i>therapist</i>, <i>therapy</i>, <i>verif{y|ied}</i>
</p>
</section>
<section id="marry" class="level2">
<h2 class="anchored" data-anchor-id="marry"><sc>marry</sc></h2>
<p>The second of the three, <sc>marry</sc>, is actually the <sc>trap</sc> lexical set. John Wells <a href="http://phonetic-blog.blogspot.com/2010/12/merry-mary-and-hairy-harry.html">points out</a> that the when an <em>a</em> is followed by two <em>r</em>’s, it’s a decent indicator of <sc>marry</sc>.</p>
<p>Here are some words that were verified by some folks who do not have the merger.</p>
<p style="margin-left:35px; background-color: #C1EBD1; padding:5px; border-radius:7px">
<i>arable</i>, <i>arid</i>, <i>apparent</i>, <i>Aragon</i>, <i>Areopagus</i>, <i>arid</i>, <i>arrant</i>, <i>arrow</i>, <i>baritone</i>, <i>baron</i>, <i>barren</i>, <i>barricade</i>, <i>barrow</i>, <i>Barry</i>, <i>Caradon</i>, <i>caravan(s)</i>, <i>caret</i>, <i>carob</i>, <i>carol</i>, <i>Carol{e|ine|yn}</i>, <i>carr{y|s|ied|ing|ier}</i>, <i>charabanc</i>, <i>chariot</i>, <i>charity</i>, <i>charitable</i>, <i>Clarence</i>, <i>clarify</i>, <i>clarion</i>, <i>clarity</i>, <i>comparison(s)</i>, <i>circularity</i>, <i>Darrell</i>, <i>Darren</i>, <i>Darrow</i>, <i>Faraday</i>, <i>Farrell</i>, <i>farrier</i>, <i>farrow</i>, <i>Garamond</i>, <i>Gareth</i>, <i>Gary</i>, <i>guarantee</i>, <i>harakiri</i>, <i>harried</i>, <i>harrow</i>, <i>Harry</i>, <i>Iscariot</i>, <i>Jared</i>, <i>larrikin</i>, <i>Karen</i>, <i>Larry</i>, <i>larynx</i>, <i>marabou</i>, <i>Marazion</i>, <i>Marian</i>, <i>Marilyn</i>, <i>Marion</i>, <i>marital</i>, <i>maritime</i>, <i>marronage</i>, <i>marrow</i>, <i>marr{y|ied|s|ing}</i>, <i>narrative</i>, <i>narrow(ly)</i>, <i>para<em>(-</em>bolic<em>, -</em>chute<em>, -</em>graph<em>, -</em>llel<em>, -</em>noid<em>, -</em>normal<em>, -</em>lyze* etc), *parr{y|ied}</i>, <i>parody</i>, <i>parrot</i>, <i>Raritan</i>, <i>saraband</i>, <i>Saracen</i>, <i>scarify</i>, <i>Sharon</i>, <i>taradiddle</i>, <i>tarry</i>, <i>varicose</i>, <i>yarrow</i>, <i>Zara</i>
</p>
<p>And here’s a longer list from the Britphone dictionary, based on the search pattern “ˈæ ɹ” with a few additions from <em>The Routledge Dictionary of Pronunciation for Current English</em>, based on the search pattern “ar|”.</p>
<p style="margin-left:35px; background-color: #C1EBD1; padding:5px; border-radius:7px">
<i>apparel</i>, <i>Arab</i>, <i>Arabic</i>, <i>barracks</i>, <i>barrel</i>, <i>barrier(s)</i>, <i>caribou</i>, <i>carriage</i>, <i>Carrie</i>, <i>carrier(s)</i>, <i>Carroll</i>, <i>carrot(s)</i>, <i>character{s|ize}</i>, <i>charit{y|ies|able}</i>, <i>comparative(ly)</i>, <i>Daryl</i>, <i>disparage</i>, <i>embarrass{ed|ing|ment}</i>, <i>garage(s)</i>, <i>gharry</i>, <i>glengarry</i>, <i>harass(ment)</i>, <i>Haringey</i>, <i>Harold</i>, <i>Harriet</i>, <i>Harris</i>, <i>Harrison</i>, <i>Harrogate</i>, <i>karri</i>, <i>Larry</i>, <i>marathon</i>, <i>marriage(s)</i>, <i>Marriott</i>, <i>Maryland</i>, <i>Marylebone</i>, <i>miscarriage(s)<em>, </em>paradigm</i>, <i>paradise</i>, <i>paradox</i>, <i>Paraguay</i>, <i>Paris</i>, <i>parish</i>, <i>popularity</i>, <i>similarit{y|ies}</i>, <i>solidarity</i>, <i>tariff</i>, <i>tarot</i>, <i>transparen{t|cy}</i>
</p>
</section>
<section id="mary" class="level2">
<h2 class="anchored" data-anchor-id="mary"><sc>Mary</sc></h2>
<p>Finally, there’s <sc>mary</sc>, which is actually the <sc>square</sc> lexical set. John Wells <a href="http://phonetic-blog.blogspot.com/2010/12/merry-mary-and-hairy-harry.html">points out</a> that the when an <em>a</em> is followed by just one <em>r</em>, it’s a decent indicator of <sc>mary</sc> (though not always).</p>
<p>Here are some words that were verified by some folks who do not have the merger.</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>Aaron</i>, <i>aerate</i>, <i>aerial</i>, <i>airing</i>, <i>area</i>, <i>baring</i>, <i>bear{ing|er}</i>, <i>Bering</i>, <i>carer(s)</i>, <i>Carey</i>, <i>caring</i>, <i>chairing</i>, <i>Charing</i>, <i>Clary</i>, <i>dare{e|ing}</i>, <i>dairy</i>, <i>fairy</i>, <i>far{e|ing}</i>, <i>flare-up</i>, <i>flaring</i>, <i>glaring</i>, <i>(nom de) guerre</i>, <i>hairy</i>, <i>hare</i>, <i>haring</i>, <i>lair</i>, <i>lairy</i>, <i>mare</i>, <i>Mary</i>, <i>mayoral</i>, <i>Nair</i>, <i>nary</i>, <i>pair(ing)</i>, <i>Pharaoh</i>, <i>precarious</i>, <i>rare</i>, <i>raring</i>, <i>Sara(h)</i>, <i>scar{y|ing}</i>, <i>shar{er|ing}</i>, <i>sparing</i>, <i>squaring</i>, <i>staring</i>, <i>swearing</i>, <i>tear(ing)</i>, <i>Vair</i>, <i>variable(s)</i>, <i>varian{t|ce}</i>, <i>var{y|ying|ied|ies}</i>, <i>wary</i>
</p>
<p>And here are some other ones based on the <a href="https://github.com/JoseLlarena/Britfone">Britphone dictionary</a>, based on the search pattern “ˈɛə ɹ”.</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>aerosol</i>, <i>aerospace</i>, <i>air{y|ing}</i>, <i>apparent(ly)</i>, <i>aquarium</i>, <i>Averham</i>, <i>Barham</i>, <i>Bulgaria(n)</i>, <i>canary</i>, <i>comparing</i>, <i>contrary</i>, <i>eire</i>, <i>Faeroes</i>, <i>hilarious</i>, <i>humanitarian</i>, <i>Hungarian</i>, <i>invariably</i>, <i>librarian</i>, <i>malaria</i>, <i>Ontario</i>, <i>parent{s|ing}</i>, <i>pharaoh(s)</i>, <i>prairie</i>, <i>preparing</i>, <i>secretariat</i>, <i>sierra</i>, <i>variegated</i>, <i>various</i>, <i>vegetarian</i>, <i>wearing</i>, <i>whereabouts</i>
</p>
<section id="word-final-and-pre-consonantal-tokens" class="level3">
<h3 class="anchored" data-anchor-id="word-final-and-pre-consonantal-tokens">Word-final and pre-consonantal tokens</h3>
<p>It occured to me that the search patterns that I used only included words that, in UK English, are pronounced with /ɹ/ (i.e.&nbsp;the /ɹ/ is intervocalic). So you’ll notice that <em>caring</em> is on the list of <sc>Mary</sc> words but <em>care</em> is not. So I searched for tokens in Britphone with “ˈɛə” that are <em>not</em> followed by an /ɹ/ (so, preconsonantal and word-final) to produce the following list.</p>
<p>This list includes words that I thought were from different lexical sets. For example, <em>care</em> and <em>hair</em> are on this list, which are presumably part of <sc>Mary</sc> since <em>caring</em> and <em>hairy</em> are too, but then the word <em>square</em> is also in this list, which is, by definition, part of <sc>merry</sc>, since <sc>merry</sc> is just <sc>square</sc>. But, when I asked for clarification on Twitter, I was told that these are all <sc>square</sc>—and therefore <sc>Mary</sc>.</p>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Okay, so what about "pair", "pear", and "pare"? Is that a minimal triplet for the non-MMM-mergers out there? <br><br>Britphone doesn't differentiate the classes word-finally, so "care" and "square" are both ˈɛə even though I'm pretty sure they're respectively DRESS and SQAURE. <a href="https://t.co/3esqw2l4FO">https://t.co/3esqw2l4FO</a>
</p>
— Joey Stanley (<span class="citation" data-cites="joey_stan">@joey_stan</span>) <a href="https://twitter.com/joey_stan/status/1308442632306057217?ref_src=twsrc%5Etfw">September 22, 2020</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p>Anyway, so here’s the fuller list:</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>affair(s)</i>, <i>air</i>, <i>aircraft</i>, <i>airfare</i>, <i>airline(s)</i>, <i>airlines</i>, <i>airplane</i>, <i>airport(s)</i>, <i>airways</i>, <i>aware</i>, <i>awareness</i>, <i>Ayrshire</i>, <i>bare(ly)</i>, <i>bear(s)</i>, <i>beware</i>, <i>Blair</i>, <i>blare</i>, <i>care{s|d}</i>, <i>careful(ly)</i>, <i>chair(s)</i>, <i>Clair(e)</i>, <i>clare</i>, <i>compare(d)</i>, <i>dare</i>, <i>declare(d)</i>, <i>despair</i>, <i>downstairs</i>, <i>fair(ly)</i>, <i>fare(s)</i>, <i>flair</i>, <i>flare</i>, <i>glare</i>, <i>hair{s|ed}ed)</i>, <i>haircut</i>, <i>hairdresser(s)</i>, <i>hare</i>, <i>heir</i>, <i>heirloom</i>, <i>hilaire</i>, <i>impaired</i>, <i>lair</i>, <i>mare</i>, <i>mayor</i>, <i>pair(s)</i>, <i>pare</i>, <i>pear</i>, <i>Pierre</i>, <i>prayer(s)</i>, <i>prepare(d)</i>, <i>questionnaire</i>, <i>rare(ly)</i>, <i>repair(s)</i>, <i>scarce(ly)</i>, <i>scare(d)</i>, <i>share{s|d}</i>, <i>shareholder(s)</i>, <i>shareware</i>, <i>snare</i>, <i>spare</i>, <i>square{s|d}</i>, <i>stair(s)</i>, <i>staircase</i>, <i>stare(d)</i>, <i>swear</i>, <i>tear(s)</i>, <i>their(s)</i>, <i>there</i>, <i>therefore</i>, <i>unaware</i>, <i>unfair</i>, <i>upstairs</i>, <i>ware</i>, <i>warehouse</i>, <i>wear(s)</i>, <i>where</i>, <i>wherewhithal</i>
</p>
</section>
<section id="supplemental-mary-words" class="level3">
<h3 class="anchored" data-anchor-id="supplemental-mary-words">Supplemental <sc>Mary</sc> words</h3>
<p>Finally, when I searched the <em>The Routledge Dictionary of Pronunciation for Current English</em>, I found these 695 words containing the search pattern “ɛ:r”. I didn’t bother incorporating them into the above list because many of them are very infrequent words. But I wanted to include them for the sake of completeness.</p>
<p style="margin-left:35px; background-color: #C0BFD9; padding:5px; border-radius:7px">
<i>Aaron</i>, <i>abecedarian</i>, <i>Abertillery</i>, <i>actuarial</i>, <i>actuarially</i>, <i>adversarial</i>, <i>aerial</i>, <i>aerialist</i>, <i>aeriality</i>, <i>aerially</i>, <i>aeriated</i>, <i>aerie</i>, <i>aeriform</i>, <i>aero</i>, <i>aerobatic</i>, <i>aerobe</i>, <i>aerobiologist</i>, <i>aerobiology</i>, <i>aerodrome</i>, <i>aerodynamic</i>, <i>aerodynamically</i>, <i>aerodynamicist</i>, <i>aerodyne</i>, <i>aero-engine</i>, <i>Aeroflot</i>, <i>aerofoil</i>, <i>aerogram</i>, <i>aerogramme</i>, <i>aerolite</i>, <i>aerological</i>, <i>aeromagnetic</i>, <i>aeronaut</i>, <i>aeronautic</i>, <i>aeronautical</i>, <i>aeronautically</i>, <i>aeroplane</i>, <i>aerosol</i>, <i>aerospace</i>, <i>aerostat</i>, <i>aerostatic</i>, <i>aerostatically</i>, <i>aerotow</i>, <i>aerotrain</i>, <i>aery</i>, <i>affair</i>, <i>agrarian</i>, <i>Ahasuerus</i>, <i>airer</i>, <i>airily</i>, <i>airiness</i>, <i>airing</i>, <i>airy</i>, <i>Althusserean</i>, <i>Althusserian</i>, <i>Antares</i>, <i>antimalarial</i>, <i>antiquarian</i>, <i>antiquarianism</i>, <i>antisabbatarian</i>, <i>antitrinitarian</i>, <i>aorist</i>, <i>apiarian</i>, <i>Apollinaris</i>, <i>aquaria</i>, <i>Aquarian</i>, <i>aquarium</i>, <i>Aquarius</i>, <i>araucaria</i>, <i>area</i>, <i>areal</i>, <i>areaway</i>, <i>areometer</i>, <i>Ares</i>, <i>Arian</i>, <i>Arianism</i>, <i>ariel</i>, <i>Aries</i>, <i>Arius</i>, <i>armamentaria</i>, <i>armamentarium</i>, <i>armillaria</i>, <i>aroid</i>, <i>arum</i>, <i>Aryan</i>, <i>authoritarian</i>, <i>authoritarianism</i>, <i>Azeri</i>, <i>Balearic</i>, <i>ballbearing</i>, <i>Ballesteros</i>, <i>barbarian</i>, <i>baric</i>, <i>barite</i>, <i>barium</i>, <i>Bavaria</i>, <i>Bavarian</i>, <i>bearability</i>, <i>bearable</i>, <i>bearably</i>, <i>bearer</i>, <i>bearing</i>, <i>bearish</i>, <i>bearishness</i>, <i>Behrens</i>, <i>Behring</i>, <i>Belisarius</i>, <i>Berengaria</i>, <i>Bering</i>, <i>billionairess</i>, <i>bolero</i>, <i>Buenos Aires</i>, <i>Bulgaria</i>, <i>Bulgarian</i>, <i>burglarious</i>, <i>burglariously</i>, <i>bursarial</i>, <i>caballero</i>, <i>caesarean</i>, <i>caesarian</i>, <i>calcareous</i>, <i>calcareousness</i>, <i>calceolaria</i>, <i>caldaria</i>, <i>caldarium</i>, <i>caldera</i>, <i>Canaries</i>, <i>canary</i>, <i>Cancerian</i>, <i>carabiniere</i>, <i>carabinieri</i>, <i>carer</i>, <i>Carew</i>, <i>Carey</i>, <i>Caria</i>, <i>caries</i>, <i>caring</i>, <i>carious</i>, <i>Carpentaria</i>, <i>Carreras</i>, <i>Cary</i>, <i>cassowary</i>, <i>centenarian</i>, <i>cercaria</i>, <i>cercariae</i>, <i>certiorari</i>, <i>cesarean</i>, <i>cesarian</i>, <i>charily</i>, <i>chariness</i>, <i>Charing Cross</i>, <i>Charon</i>, <i>chary</i>, <i>cheeseparing</i>, <i>childbearing</i>, <i>ciguatera</i>, <i>cineraria</i>, <i>cinerarium</i>, <i>clairaudience</i>, <i>clairaudient</i>, <i>Clara</i>, <i>clary</i>, <i>columbaria</i>, <i>columbarium</i>, <i>commissarial</i>, <i>commissariat</i>, <i>communitarian</i>, <i>condottiere</i>, <i>condottieri</i>, <i>contrarily</i>, <i>contrariness</i>, <i>contrariwise</i>, <i>contrary</i>, <i>cordillera</i>, <i>costmary</i>, <i>covariance</i>, <i>cruzeiro</i>, <i>cupbearer</i>, <i>daguerreotype</i>, <i>daguerrotype</i>, <i>dairy</i>, <i>dairying</i>, <i>dairymaid</i>, <i>dairyman</i>, <i>dairymen</i>, <i>darer</i>, <i>Dari</i>, <i>Darien</i>, <i>daring</i>, <i>daringly</i>, <i>Darius</i>, <i>de-aerate</i>, <i>declarable</i>, <i>declarant</i>, <i>declaredly</i>, <i>declarer</i>, <i>Demerara</i>, <i>denarii</i>, <i>denarius</i>, <i>despairingly</i>, <i>de Valera</i>, <i>dinero</i>, <i>disciplinarian</i>, <i>doctrinairism</i>, <i>doctrinarian</i>, <i>dolphinarium</i>, <i>Dun Laoghaire</i>, <i>egalitarian</i>, <i>egalitarianism</i>, <i>√âire</i>, <i>equalitarian</i>, <i>equalitarianism</i>, <i>establishmentarian</i>, <i>establishmentarianism</i>, <i>Europarliamentarian</i>, <i>eyrie</i>, <i>eyry</i>, <i>faerie</i>, <i>Faeroe Islands</i>, <i>Faeroes</i>, <i>Faeroese</i>, <i>faery</i>, <i>fairing</i>, <i>fairish</i>, <i>fairy</i>, <i>fairyland</i>, <i>Fareham</i>, <i>faro</i>, <i>Faro</i>, <i>Faroe</i>, <i>Faroese</i>, <i>filaria</i>, <i>filariae</i>, <i>filarial</i>, <i>filariasis</i>, <i>Fleet Air Arm</i>, <i>forastero</i>, <i>forbearance</i>, <i>forbearingly</i>, <i>frigidaria</i>, <i>frigidarium</i>, <i>fruitarian</i>, <i>fusaria</i>, <i>fusarium</i>, <i>futilitarian</i>, <i>garish</i>, <i>garishly</i>, <i>garishness</i>, <i>gharial</i>, <i>Gibraltarian</i>, <i>glaireous</i>, <i>glairiness</i>, <i>glairy</i>, <i>glaringly</i>, <i>glaringness</i>, <i>glary</i>, <i>glossarial</i>, <i>godparent</i>, <i>grammarian</i>, <i>Gran Canaria</i>, <i>grandparent</i>, <i>gregarious</i>, <i>gregariously</i>, <i>gregariousness</i>, <i>Guarneri</i>, <i>Guarnerius</i>, <i>Guerrero</i>, <i>Guti√©rrez</i>, <i>habanera</i>, <i>hairily</i>, <i>hairiness</i>, <i>hairy</i>, <i>Halmahera</i>, <i>Hanoverian</i>, <i>hardwearing</i>, <i>harem</i>, <i>harum-scarum</i>, <i>heiress</i>, <i>herbaria</i>, <i>herbarium</i>, <i>Herero</i>, <i>Herrera</i>, <i>hilarious</i>, <i>hilariously</i>, <i>hilariousness</i>, <i>honoraria</i>, <i>honorarium</i>, <i>houseparent</i>, <i>humanitarian</i>, <i>humanitarianism</i>, <i>Hungarian</i>, <i>Indo-Aryan</i>, <i>inegalitarian</i>, <i>infralapsarian</i>, <i>insectaria</i>, <i>insectarium</i>, <i>invariability</i>, <i>invariable</i>, <i>invariableness</i>, <i>invariably</i>, <i>invariance</i>, <i>invariant</i>, <i>Inveraray</i>, <i>Karaite</i>, <i>lairage</i>, <i>lairy</i>, <i>lares</i>, <i>latitudinarian</i>, <i>latitudinarianism</i>, <i>Lehrer</i>, <i>leprosaria</i>, <i>leprosarium</i>, <i>libertarian</i>, <i>libertarianism</i>, <i>librarian</i>, <i>librarianship</i>, <i>Lilliburlero</i>, <i>llanero</i>, <i>Lothario</i>, <i>lumpenproletariat</i>, <i>lupus vulgaris</i>, <i>mace-bearer</i>, <i>Mainwaring</i>, <i>majoritarian</i>, <i>malaria</i>, <i>malarial</i>, <i>malarian</i>, <i>malarious</i>, <i>Marian</i>, <i>mariolatry</i>, <i>Mariology</i>, <i>Marist</i>, <i>Mary</i>, <i>Mary Celeste</i>, <i>Maryland</i>, <i>Mary Magdalene</i>, <i>Maryport</i>, <i>Maseru</i>, <i>mayoral</i>, <i>mayoralty</i>, <i>mayoress</i>, <i>miliaria</i>, <i>militaria</i>, <i>millenarian</i>, <i>millenarianism</i>, <i>millenarianist</i>, <i>millionairess</i>, <i>miserere</i>, <i>multifarious</i>, <i>multifariously</i>, <i>multifariousness</i>, <i>multivariate</i>, <i>nareal</i>, <i>nares</i>, <i>narial</i>, <i>nary</i>, <i>necessarian</i>, <i>necessarianism</i>, <i>necessitarian</i>, <i>necessitarianism</i>, <i>nectarean</i>, <i>nectareous</i>, <i>nefarious</i>, <i>nefariously</i>, <i>Nehru</i>, <i>nightmarish</i>, <i>nightmarishness</i>, <i>nonagenarian</i>, <i>notarial</i>, <i>notarially</i>, <i>Nyerere</i>, <i>obituarial</i>, <i>oceanaria</i>, <i>oceanarium</i>, <i>octogenarian</i>, <i>octonarian</i>, <i>octonarii</i>, <i>octonarius</i>, <i>Old Sarum</i>, <i>O’Meara</i>, <i>omnifarious</i>, <i>Ontario</i>, <i>ovarian</i>, <i>ovariectomy</i>, <i>ovariotomy</i>, <i>pairing</i>, <i>pallbearer</i>, <i>pampero</i>, <i>pareira</i>, <i>parent</i>, <i>parentage</i>, <i>parenthood</i>, <i>parentless</i>, <i>parer</i>, <i>Parian</i>, <i>paring</i>, <i>parliamentarian</i>, <i>Perak</i>, <i>pereira</i>, <i>Pharaoh</i>, <i>Pharaonic</i>, <i>Pharoah</i>, <i>pharos</i>, <i>Pierian</i>, <i>Pinero</i>, <i>planarian</i>, <i>planetaria</i>, <i>planetarium</i>, <i>platitudinarian</i>, <i>plein-airist</i>, <i>potrero</i>, <i>prairie</i>, <i>precarious</i>, <i>precariously</i>, <i>precariousness</i>, <i>predestinarian</i>, <i>prelapsarian</i>, <i>preparedness</i>, <i>preparer</i>, <i>primavera</i>, <i>proletarian</i>, <i>proletarianisation</i>, <i>proletarianise</i>, <i>proletarianism</i>, <i>proletarianization</i>, <i>proletarianize</i>, <i>proletariat</i>, <i>pulmonaria</i>, <i>quadragenarian</i>, <i>quinquagenarian</i>, <i>quodlibetarian</i>, <i>radiolaria</i>, <i>radiolarian</i>, <i>ranchero</i>, <i>rara avis</i>, <i>raree-show</i>, <i>rarefaction</i>, <i>rarefactive</i>, <i>rarefication</i>, <i>rarefy</i>, <i>rarify</i>, <i>raring</i>, <i>rarity</i>, <i>Rarotonga</i>, <i>Rarotongan</i>, <i>Rastafarian</i>, <i>Rastafarianism</i>, <i>repairable</i>, <i>repairer</i>, <i>retiarii</i>, <i>retiarius</i>, <i>riparian</i>, <i>Ripuarian</i>, <i>Rivera</i>, <i>Riviera</i>, <i>Romero</i>, <i>rosaria</i>, <i>rosarian</i>, <i>rosarium</i>, <i>Rotarian</i>, <i>sabbatarian</i>, <i>sabbatarianism</i>, <i>sacramentarian</i>, <i>sacraria</i>, <i>sacrarium</i>, <i>Sagittarian</i>, <i>Sagittarius</i>, <i>salariat</i>, <i>Salieri</i>, <i>Samaria</i>, <i>samarium</i>, <i>sanataria</i>, <i>sanatarium</i>, <i>sanitaria</i>, <i>sanitarian</i>, <i>sanitarium</i>, <i>Sara</i>, <i>Sarah</i>, <i>sarify</i>, <i>Saros</i>, <i>Sarum</i>, <i>Sauveterrian</i>, <i>scarer</i>, <i>scarification</i>, <i>scarificator</i>, <i>scarifier</i>, <i>scarify</i>, <i>scarily</i>, <i>scariness</i>, <i>scarious</i>, <i>scaroid</i>, <i>scarus</i>, <i>scary</i>, <i>scenario</i>, <i>seafarer</i>, <i>seafaring</i>, <i>secretarial</i>, <i>secretariat</i>, <i>sectarian</i>, <i>sectarianise</i>, <i>sectarianism</i>, <i>sectarianize</i>, <i>sederunt</i>, <i>seminarian</i>, <i>senarii</i>, <i>senarius</i>, <i>septenarii</i>, <i>septenarius</i>, <i>septuagenarian</i>, <i>sexagenarian</i>, <i>shareable</i>, <i>share-out</i>, <i>sharer</i>, <i>Sharon</i>, <i>sharon fruit</i>, <i>snarer</i>, <i>solaria</i>, <i>solarium</i>, <i>sombrero</i>, <i>sparer</i>, <i>sparerib</i>, <i>sparing</i>, <i>sparingly</i>, <i>sparingness</i>, <i>square-eyed</i>, <i>squarer</i>, <i>Squarial</i>, <i>squarish</i>, <i>starer</i>, <i>step-parent</i>, <i>Stradivarius</i>, <i>sublapsarian</i>, <i>sub-librarian</i>, <i>sudaria</i>, <i>sudarium</i>, <i>Sumerian</i>, <i>supralapsarian</i>, <i>swearer</i>, <i>swordbearer</i>, <i>talaria</i>, <i>talebearer</i>, <i>talebearing</i>, <i>tearable</i>, <i>tearaway</i>, <i>tearer</i>, <i>tear-off</i>, <i>temerarious</i>, <i>tepidaria</i>, <i>tepidarium</i>, <i>termitaria</i>, <i>termitarium</i>, <i>terraria</i>, <i>terrarium</i>, <i>therabouts</i>, <i>thereabout</i>, <i>thereafter</i>, <i>thereanent</i>, <i>thereat</i>, <i>therein</i>, <i>thereinafter</i>, <i>thereinbefore</i>, <i>thereinto</i>, <i>thereof</i>, <i>thereon</i>, <i>thereout</i>, <i>thereunder</i>, <i>thereunto</i>, <i>thereupon</i>, <i>time-sharing</i>, <i>Tipperary</i>, <i>Tocharian</i>, <i>Tokharian</i>, <i>topiarian</i>, <i>torch-bearer</i>, <i>torero</i>, <i>totalitarian</i>, <i>totalitarianism</i>, <i>tractarian</i>, <i>Tractarian</i>, <i>Tractarianism</i>, <i>transparence</i>, <i>transparency</i>, <i>transparent</i>, <i>transparently</i>, <i>transparentness</i>, <i>Trinitarian</i>, <i>Trinitarianism</i>, <i>Trocadero</i>, <i>turbellarian</i>, <i>ubiquitarian</i>, <i>ubiquitarianism</i>, <i>unbearable</i>, <i>unbearableness</i>, <i>unbearably</i>, <i>unbury</i>, <i>uncaring</i>, <i>uncaringly</i>, <i>uniformitarian</i>, <i>uniformitarianism</i>, <i>Unitarian</i>, <i>Unitarianism</i>, <i>unpreparedly</i>, <i>unpreparedness</i>, <i>unrepairable</i>, <i>unsectarian</i>, <i>unsparing</i>, <i>unsparingly</i>, <i>unsparingness</i>, <i>untearable</i>, <i>unvaried</i>, <i>unvarying</i>, <i>unvaryingly</i>, <i>unvaryingness</i>, <i>unwarily</i>, <i>unwariness</i>, <i>unwary</i>, <i>unwearable</i>, <i>urticaria</i>, <i>utilitarian</i>, <i>utilitarianism</i>, <i>vagarious</i>, <i>Valera</i>, <i>valerian</i>, <i>valetudinarian</i>, <i>valetudinarianism</i>, <i>vaquero</i>, <i>varia</i>, <i>variability</i>, <i>variable</i>, <i>variably</i>, <i>variance</i>, <i>variant</i>, <i>variate</i>, <i>variation</i>, <i>variational</i>, <i>variationally</i>, <i>variationist</i>, <i>varices</i>, <i>varicolored</i>, <i>varicoloured</i>, <i>varied</i>, <i>variedly</i>, <i>variegate</i>, <i>variegation</i>, <i>varifocal</i>, <i>variform</i>, <i>variolate</i>, <i>variole</i>, <i>variolite</i>, <i>variolitic</i>, <i>varioloid</i>, <i>variolous</i>, <i>variometer</i>, <i>variorum</i>, <i>various</i>, <i>variously</i>, <i>variousness</i>, <i>varix</i>, <i>varus</i>, <i>vary</i>, <i>varyingly</i>, <i>vegetarian</i>, <i>vegetarianism</i>, <i>veterinarian</i>, <i>vicarial</i>, <i>vicariate</i>, <i>vicarious</i>, <i>vicariously</i>, <i>vicariousness</i>, <i>vivaria</i>, <i>vivarium</i>, <i>vulgarian</i>, <i>Wareham</i>, <i>Wareing</i>, <i>warily</i>, <i>wariness</i>, <i>Waring</i>, <i>wary</i>, <i>wayfarer</i>, <i>wayfaring</i>, <i>wearability</i>, <i>wearable</i>, <i>wear-and-tear</i>, <i>wearer</i>, <i>wearing</i>, <i>wearingly</i>, <i>welfarism</i>, <i>welfarist</i>, <i>whereabouts</i>, <i>whereabouts</i>, <i>where’er</i>, <i>whereupon</i>, <i>worksharing</i>
</p>
</section>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>I hope this list is useful to other folks who have the merger but need to distinguish them for whatever reason. I’m starting to remember which class words belong to a little bit, though this is just learned knowledge rather than intuition. Also, if anyone has different intuitions than what this page shows, please let me know!</p>


</section>

 ]]></description>
  <category>Lexical Sets</category>
  <category>Side Projects</category>
  <category>Teaching</category>
  <guid>https://new.joeystanley.com/blog/mary-merry-marry/index.html</guid>
  <pubDate>Mon, 28 Sep 2020 15:25:00 GMT</pubDate>
</item>
<item>
  <title>barktools: Functions to help when working with Barks</title>
  <dc:creator>Joey Stanley</dc:creator>
  <link>https://new.joeystanley.com/blog/barktools/index.html</link>
  <description><![CDATA[ 




<p>I’m happy to announce that I’ve just released another small R package called <code>barktools</code>. Now that I’ve got <a href="../../blog/futurevisions-my-first-r-package">one R package out there already</a>, I’ve sort of caught the bug and realized it’s kinda fun to put these small packages out there. This one is just a lightweight little guy that I thought up a few days ago while falling asleep that’ll help me when working with Barks. You can download the package from my <a href="https://joeystanley.github.io/barktools/">GitHub</a>.</p>
<section id="barktools" class="level1">
<h1>barktools</h1>
<p>Functions to help when working with Barks.</p>
<p>This package makes it easier to work with the Bark scale when analyzing and plotting acoustic data. It contains two pairs of functions. The first (<code>bark</code> and <code>hz</code>) convert between Hz and Barks. The other (<code>scale_x_bark</code> and <code>scale_y_bark</code>) make it easy to plot data in ggplot2 using the Bark scale.</p>
<p>To install the package, you can do so by downloading it from github.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># install.packages("remotes") # &lt;- if not already installed</span></span>
<span id="cb1-2">remotes<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">::</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">install_github</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"joeystanley/barktools"</span>)</span></code></pre></div>
</div>
<p>You can then load it like any other library.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(barktools)</span></code></pre></div>
</div>
<section id="load-the-data" class="level2">
<h2 class="anchored" data-anchor-id="load-the-data">Load the data</h2>
<p>For this little vignette, I’ll load some sample vowel data from my own speech. It’s got some outliers, but that’s the nature of automatically-processed data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">library</span>(tidyverse)</span>
<span id="cb3-2">vowels <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">read_csv</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"http://joeystanley.com/data/joey.csv"</span>, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">show_col_types =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
</div>
<p>Here’s a simple plot that shows my vowel space. For now, I’ll just keep it simple.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(vowels, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb4-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Joey's vowels"</span>,</span>
<span id="cb4-7">       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Data and plot are in Hz"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/barktools/index_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now, let’s say I want to plot using Barks. You can use the <code>bark()</code> function to convert the formant frequencies into Barks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1">vowels_with_barks <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> vowels <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb5-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">mutate</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">F1_bark =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bark</span>(F1),</span>
<span id="cb5-3">         <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">F2_bark =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">bark</span>(F2))</span>
<span id="cb5-4"></span>
<span id="cb5-5"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(vowels_with_barks, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2_bark, F1_bark)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_reverse</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-9">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb5-10">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Joey's vowels"</span>,</span>
<span id="cb5-11">       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Data and plot are in Barks"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/barktools/index_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The Bark scale turns the nonlinear Hz data into something a little more linear, so the shape of the vowel space should change somewhat.</p>
<p>The problem is most people can’t readily interpret the Barks unit. What is the Hz equivalent of 6 Barks? We can look this up using the <code>hz()</code> function:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">hz</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 631.1045</code></pre>
</div>
</div>
<p>But it would be better if we could incorporate more interpretable values into the plot itself. I think the first time I saw this was in <a href="https://www.jstor.org/stable/44526873?seq=1#metadata_info_tab_contents">Harrington et al’s (2000) paper</a> on how the Queen of England’s speech changes over time:</p>
<p><img src="https://new.joeystanley.com/blog/barktools/harrington_sample.jpg" class="img-fluid"></p>
<p>Notice how the axes are in Barks, but the data is still plotted in Hz. This is a perfect case for using the <code>scale_x_bark()</code> and <code>scale_y_bark()</code> functions. Like the other <code>scale_*</code> functions in ggplot2, this will transform the axes of your plot. In this case, it’ll convert the plotting area to the Bark scale, but the values will be in Hz still.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(vowels, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_bark</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_bark</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb8-6">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Joey's vowels"</span>,</span>
<span id="cb8-7">       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Data is in Hz; plot is in Barks"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/barktools/index_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now, you can see that the shape of the vowel space is identical to the plot above, except the axis labels are more useful: I have a better idea of what 500Hz means. Note that the axes are reversed as well, just like <code>scale_*_reverse</code>.</p>
<p>At this point, it might be useful to modify the axes with some additional labels. Since <code>scale_*_bark</code> is just a wrapper around <code>scale_*_continuous</code>, any argument that you would normally include in the latter function will work just fine in the bark function. Specifically, I’ll modify which values get labels with <code>breaks</code> and the gridlines with <code>minor_breaks</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(vowels, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(F2, F1)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_point</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_x_bark</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1500</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3000</span>)),</span>
<span id="cb9-4">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">minor_breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">4000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb9-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_bark</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">400</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">600</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">800</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1500</span>)),</span>
<span id="cb9-6">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">minor_breaks =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">seq</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3000</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-7">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_minimal</span>() <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb9-8">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">labs</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">title =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Joey's vowels"</span>,</span>
<span id="cb9-9">       <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">subtitle =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Data is in Hz; plot is in Barks"</span>)</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/barktools/index_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Exactly which values you want to put is up to you, obviously, so play around with it until it looks good.</p>
</section>
<section id="spectrogram-plots" class="level2">
<h2 class="anchored" data-anchor-id="spectrogram-plots">Spectrogram plots</h2>
<p>The other type of plot you might want to use <code>scale_y_bark</code> for is something that looks like a spectrogram, that is a time-by-hz plot. You’ll have to transform the data a little bit. You can use the code that I provided in my <a href="http://joeystanley.com/blog/reshaping-vowel-formant-data-with-tidyr">tutorial</a> with the new <code>pivot_longer</code> function in <code>dplyr</code>. I’ll just pull out my /aʊ/ vowel for this plot:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1">vowels_long <span class="ot" style="color: #003B4F;
background-color: null;
font-style: inherit;">&lt;-</span> vowels <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">filter</span>(vowel <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"AW"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>(<span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contains</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"@"</span>)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">rowid_to_column</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"phoneme_id"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-5">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">pivot_longer</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">cols =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">contains</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"@"</span>), </span>
<span id="cb10-6">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_to =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"formant"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"percent"</span>), </span>
<span id="cb10-7">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_pattern =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"(F</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\\</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">d)@(</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\\</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">d</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\\</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">d)%"</span>, </span>
<span id="cb10-8">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_ptypes =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">formant =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">factor</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">levels =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">c</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"F2"</span>))), </span>
<span id="cb10-9">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">names_transform =</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">list</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">percent =</span> as.integer),</span>
<span id="cb10-10">               <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">values_to =</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hz"</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">%&gt;%</span></span>
<span id="cb10-11">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">unite</span>(traj_id, phoneme_id, formant, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">remove =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>)</span></code></pre></div>
</div>
<p>Here’s what a spectrogram-like plot might look like</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(vowels_long, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(percent, hz, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> formant, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">group =</span> traj_id)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb11-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_path</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">alpha =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb11-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_bw</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/barktools/index_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now, a lot of the change in /ai/ happens along the F1 dimension, but because of the logarithmic nature of sound, F2 visually takes up most of the vertical space and F1 is sort of squished down at the bottom. We can emphasize F1 by transforming the <em>y</em>-axis into the Bark scale.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">ggplot</span>(vowels_long, <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">aes</span>(percent, hz, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">color =</span> formant, <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">group =</span> traj_id)) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb12-2">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">geom_path</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">alpha =</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span></span>
<span id="cb12-3">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">scale_y_bark</span>(<span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">rev =</span> <span class="cn" style="color: #8f5902;
background-color: null;
font-style: inherit;">FALSE</span>) <span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> </span>
<span id="cb12-4">  <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">theme_bw</span>()</span></code></pre></div>
<div class="cell-output-display">
<p><img src="https://new.joeystanley.com/blog/barktools/index_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Note that this time, I added the argument <code>rev = FALSE</code> to <code>scale_y_bark</code>. By default, the function will flip the axis (like <code>scale_y_reverse</code>), but in this case that behavior is not desired. So, you can suppress that flip by specifying <code>rev = FALSE</code>.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>And that’s it! That’s the whole package. I thought it would be a useful thing for me. Perhaps you’ll find some use for it too.</p>


</section>
</section>

 ]]></description>
  <category>Data Viz</category>
  <category>Github</category>
  <category>How-to Guides</category>
  <category>Methods</category>
  <category>Phonetics</category>
  <category>R</category>
  <category>R Packages</category>
  <category>Side Projects</category>
  <category>Skills</category>
  <guid>https://new.joeystanley.com/blog/barktools/index.html</guid>
  <pubDate>Mon, 27 Apr 2020 19:45:00 GMT</pubDate>
</item>
</channel>
</rss>
