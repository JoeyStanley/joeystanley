{
  "hash": "8e9ae188e0395fbcf329b2aa9b018c52",
  "result": {
    "markdown": "---\nlayout: post\ntitle: \"joeysvowels: An R package of vowel data\"\ndate: 2020-09-30 02:28:00 -0600\ncategories:\n  - Github\n  - Methods\n  - Phonetics\n  - R\n  - R Packages\n  - Side Projects\n  - Teaching\n  - West\n---\n\n\nI've just released my third R package, [`joeysvowels`](https://joeystanley.github.io/joeysvowels/). It provides a handful of datasets, some subsets of others, that contain formant measurements and other information about the vowels in my own speech. The purpose of the package is to make vowel data easily accessible for demonstrating code snippets when demonstrating how to work with sociophonetic data. There are no functions contained in `joeysvowels`; it's a data-only package.\n\nThis is my third package. My first one, [`futurevisions`](https://github.com/JoeyStanley/futurevisions), contains a collection of color palettes. The second is [`barktools`](https://joeystanley.github.io/barktools/), which helps you work with Barks in your sociophonetic data (and even has its own hex!). Technically, I have another package called [`joeyr`](https://joeystanley.github.io/joeyr/) that is sort of my sandbox package that I use it all the time and has useful functions for sociophonetic work but it's not quite ready for distribution yet.\n\nWhy create a data-only package? A lot of it had to with my `barktools` and `joeyr` packages. As I was developing websites for them using `pkgdown`, I wanted to create some better help files and examples. To do that, I needed real vowel data to work with. So for a while I had a couple datasets built into each of those packages. Sometimes the same dataset was included with both packages, which is fine by themselves, but since I often had both loaded in the same script, it created a small clash. I figured I should just offload the data from the two packages onto a third one, which would then be a dependency of both. Thus `joeysvowels` was born!\n\n## Installation\n\nYou can install `joeysvowels` through GitHub:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nremotes::install_github(\"joeystanley/joeysvowels\")\n```\n:::\n\n\nYou can then load the package like normally:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(joeysvowels)\n```\n:::\n\n\nI'll load a few other packages for the purposes of this post.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(dplyr)\n```\n:::\n\n\n## Contents\n\nCurrently, there are six datasets contained in `joeysvowels`. You can access them using `data()`. I'll briefly visualize the datasets.\n\n### A messy dataset: `darla`\n\n`darla` is one that was prepared using pretty standard methods, using the DARLA web interface to automatically transcribe, force-align, and extract formants from the audio. The audio was me reading 300 prepared sentences. It's a bit of a noisy dataset, so it's a good example of working with real data and testing out various outlier detection functions. It is also very close to the format that FAVE exports its data, so any tutorials that use FAVE-produced spreadsheets can be followed along using `darla`. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(darla)\nggplot(darla, aes(F2, F1, color = vowel)) + \n  geom_point() + \n  scale_x_reverse() + \n  scale_y_reverse()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n### Cleaner datasets: `coronals` and its subsets\n\n`coronals` is a much cleaner, more controlled dataset. You can read about the methods by viewing the documentation (`?coronals`). Essentially, I read a bunch of (C)CVC(C) nonce words where the consonants were (almost) all coronal. All my vowel phonemes are represented. I aligned and extracted formants from the data myself. Four formants were extracted every 5% of the vowels' durations, so great for demonstrating functions and visuals involving vowel trajectories. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(coronals)\navg_trajs <- coronals %>%\n  group_by(vowel, percent) %>%\n  summarize(across(c(F1, F2), mean)) %>%\n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 273 × 4\n# Groups:   vowel [13]\n   vowel percent    F1    F2\n   <fct>   <dbl> <dbl> <dbl>\n 1 LOT         0  454. 1616.\n 2 LOT         5  592. 1346.\n 3 LOT        10  648. 1283.\n 4 LOT        15  651. 1238.\n 5 LOT        20  661. 1178.\n 6 LOT        25  651. 1176.\n 7 LOT        30  636. 1152.\n 8 LOT        35  630. 1148.\n 9 LOT        40  633. 1153.\n10 LOT        45  625. 1158.\n# ℹ 263 more rows\n```\n:::\n\n```{.r .cell-code}\nggplot(avg_trajs, aes(F2, F1, color = vowel)) + \n  geom_path(aes(group = vowel), \n            arrow = arrow(angle = 20, length = unit(0.15, \"in\"), type = \"closed\")) + \n  scale_x_reverse() + \n  scale_y_reverse()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nIf you don't care about trajectories but would like something clearer than `darla`, then `midpoints` what you'll want. It's a subset of `coronals` and contains only the midpoints from F1 and F2.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(midpoints)\nggplot(midpoints, aes(F2, F1, color = vowel)) + \n  geom_point() + \n  scale_x_reverse() + \n  scale_y_reverse()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nIf you just need to demonstrate one vowel's trajectory, check out `mouth` since it's only the <sc>mouth</sc> (/aw/) vowel.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(mouth)\nggplot(mouth, aes(percent, hz, color = formant)) + \n  geom_path(aes(group = traj_id))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n`mouth_lite` is a subset of `mouth` and trims away most of the columns and only contains 10 tokens. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(mouth_lite)\nggplot(mouth_lite, aes(percent, hz, color = formant)) + \n  geom_path(aes(group = traj_id))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\n  \n### Multiple speakers: `idahoans`\n\n`idahoans` contains formant measurements from 11 individuals from the state of Idaho in the US.<span class=\"sidenote\">These participants did consent to their data being used for teaching purposes and to be distributed to interested researchers.</span> I needed something to test out some functions that do vowel normalization and relying on my own voice wasn't going to cut it. It's not a full dataset: for each of the 10 speakers, there are ten tokens per canonical monophthong, randomly selected from a larger dataset. But it should be enough for illustrative purposes. Plus, when was the last time you saw acoustic data from Idaho??\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(idahoans)\nggplot(idahoans, aes(F2, F1, color = vowel)) + \n  geom_point() + \n  scale_x_reverse() + \n  scale_y_reverse() + \n  facet_wrap(~speaker)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\n## Conclusion\n\nThat's it so far! Feel free to use the datasets for teaching and demos. That's what they're there for.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}