{
  "hash": "c4a13dd53e40a415dc429807d79bd799",
  "result": {
    "engine": "knitr",
    "markdown": "---\nlayout: post\ntitle: Testing out the tidynorm package\ndate: 2025-06-18 09:39:00 -0600\ndate-modified: last-modified\ncategories:\n  - How-to Guides\n  - Methods\n  - Phonetics\n  - R\n  - Skills\n---\n\n\n\nJosef Fruehwald has recently released the [tidynorm](https://jofrhwld.github.io/tidynorm/) R package. It \"provide[s] convenient and tidy functions to normalize vowel formant data.\" Since I normalize my data a lot and am entrenched in the [tidyverse](https://www.tidyverse.org), I thought I'd give it a try, especially since I have also written some functions that normalize your data for you and I wanted to compare them. After playing around `tidynorm`, I can confidently say it's a *lot* better than what my versions did. So, the purpose of this post is to \n\n1. Show a little bit of what `tidynorm` can do.\n\n2. Convince you to switch from the normalization functions in my own packages (namely, `joeyr`) and to `tidynorm`.\n\nOn this page, I walk through the functions in `tidynorm` that normalized point-based (i.e. not trajectory) formant data. I'll follow along [this article](https://jofrhwld.github.io/tidynorm/articles/norm-methods.html). As I go through each one, I'll show how you can implement each method using my own packages if applicable, and how it's done in `tidynorm`. Hopefully by the end, I will have convinced you to start adopting `tidynorm`. \n\n## Preliminaries\n\nI'll load the packages I need, including my own [`joeysvowels`](https://joeystanley.github.io/joeysvowels/) package from Github. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidynorm)\n\n# remotes::install_github(\"joeystanley/joeysvowels\")\nlibrary(joeysvowels)\n```\n:::\n\n\nI'll play around with the Idahoans dataset in this post, which sample data from 10 people from Idaho. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans <- joeysvowels::idahoans |> \n  rowid_to_column(\"token_id\") |> \n  select(-sex, -F4) |> \n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 6\n   token_id speaker vowel    F1    F2    F3\n      <int> <fct>   <chr> <dbl> <dbl> <dbl>\n 1        1 01      AA     699. 1655. 2019.\n 2        2 01      AA     685. 1360. 1914.\n 3        3 01      AA     713. 1507. 2460.\n 4        4 01      AA     801. 1143. 1868.\n 5        5 01      AA     757. 1258. 1772.\n 6        6 01      AA     804. 1403. 2339.\n 7        7 01      AA     664. 1279. 1714.\n 8        8 01      AA     757. 1325. 1929.\n 9        9 01      AA     730. 1578. 2297.\n10       10 01      AA     700. 1546. 2109.\n# ℹ 1,090 more rows\n```\n\n\n:::\n:::\n\n\n\n\nI created this dataset for the express purpose of testing out normalization functions. Let's take a peek at it.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(idahoans, aes(F2, F1, color = vowel)) + \n  geom_point() + \n  scale_x_reverse() + \n  scale_y_reverse() + \n  facet_wrap(~speaker) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n\n\nI'll load my packages as well.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# remotes::install_github(\"joeystanley/joeyr\")\nlibrary(joeyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'joeyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:tidynorm':\n\n    norm_deltaF\n```\n\n\n:::\n\n```{.r .cell-code}\n# remotes::install_github(\"joeystanley/barktools\")\nlibrary(barktools)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'barktools'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:joeysvowels':\n\n    mouth\n```\n\n\n:::\n:::\n\n\n\n\n\n## Lobanov normalization\n\nThough Barreda ([2021](https://doi.org/10.1017/S0954394521000016) and [2025](https://doi.org/10.1016/j.wocn.2025.101409)) advises against Lobanov normalization, I'll start there because it's probably the most familiar to the most number of people. Lobanov normalization is straightforward and can be easily implemented with the `scale` function in base R. Here's a more verbose way of doing things:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |> \n  group_by(speaker) |> \n  mutate(F1_z = scale(F1),\n         F2_z = scale(F2),\n         F3_z = scale(F3))\n```\n:::\n\n\n\nHere's a more compact way that is functionally equivalent using some tidyverse tricks. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |> \n  mutate(across(F1:F3, scale, .names = \"{.col}_z\"), .by = speaker)\n```\n:::\n\n\n\nHere's how you'd do the Lobanov normalization in `tidynorm`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans_lob <- idahoans |> \n  norm_lobanov(F1:F3, .by = speaker, .silent = TRUE) |> \n  print()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 10\n     .id token_id speaker    F1    F2    F3  F1_z   F2_z   F3_z vowel\n   <int>    <int> <fct>   <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> <chr>\n 1     1        1 01       699. 1655. 2019. 1.15  -0.341 -1.31  AA   \n 2     2        2 01       685. 1360. 1914. 1.04  -0.906 -1.57  AA   \n 3     3        3 01       713. 1507. 2460. 1.26  -0.624 -0.239 AA   \n 4     4        4 01       801. 1143. 1868. 1.94  -1.32  -1.68  AA   \n 5     5        5 01       757. 1258. 1772. 1.59  -1.10  -1.91  AA   \n 6     6        6 01       804. 1403. 2339. 1.97  -0.824 -0.534 AA   \n 7     7        7 01       664. 1279. 1714. 0.872 -1.06  -2.06  AA   \n 8     8        8 01       757. 1325. 1929. 1.60  -0.972 -1.53  AA   \n 9     9        9 01       730. 1578. 2297. 1.39  -0.488 -0.637 AA   \n10    10       10 01       700. 1546. 2109. 1.15  -0.550 -1.09  AA   \n# ℹ 1,090 more rows\n```\n\n\n:::\n:::\n\n\n\nSo, the output is identical. The benefit of using `scale` is that you pop the hood a little bit and it's easier to see what mathematically is happening. The benefit of using `norm_lobanov` is that it's easy to see that you're doing the Lobanov normalization.\n\nOne thing that I think is worth mentioning here---and this will be true of all the `tidynorm` functions I show here---is that there are two changes to the dataframe other than the addition of new normalized vowel formant columns. First, there is a new `.id` column, which just shows the row numbers. That gets added during the normalization procedure and apparently stays. Also, the order of columns has shifted a little bit. The formant columns are now located before the vowel column.\n\nAlso, please note that `tidynorm` function calls by default return some helpful information that provides some good feedback to make sure you've normalized the way you meant to. For me though, those messages were causing some issues in my R console, so throughout this post I'll use `.silent = TRUE` anytime I run a `tidynorm` function. Be sure to look at the output in your own code though, which you can can always do with `check_norm`. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_norm(idahoans_lob)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nNormalization Step\n• normalized with `tidynorm::norm_lobanov()`\n• normalized `F1`, `F2`, and `F3`\n• normalized values in `F1_z`, `F2_z`, and `F3_z`\n• grouped by `speaker`\n• within formant: TRUE\n• (.formant - mean(.formant, na.rm = T))/(sd(.formant, na.rm = T))\n```\n\n\n:::\n:::\n\n\n\n## Logmeans (=Neary) normalization\n\nMy go-to normalization procedure now is the Nearey method, thanks to Barreda's work. In my `joeyr` package, I had a function called `norm_logmeans`, which handled everything as best I could. (Although it was crashing for some users, and I'm not sure why.) It was pretty clunky because it required you to log transform the formant measurements first and I always ended up renaming the columns afterwards anyway. Because it was inhereted code, it also was a departure from `tidyverse` under the hood, so the result didn't get returned as a tibble.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |>\n  mutate(across(F1:F3, log, .names = \"{.col}_log\")) |> \n  joeyr_norm_logmeans(.formant_cols = F1_log:F3_log,\n                .speaker_col = speaker,\n                .vowel_col = vowel) |>\n  rename(F1_logmeans = F1_log_logmeans,\n         F2_logmeans = F2_log_logmeans,\n         F3_logmeans = F3_log_logmeans) |> \n  tibble()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 12\n   token_id speaker vowel    F1    F2    F3 F1_log F2_log F3_log F1_logmeans\n      <int> <fct>   <chr> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>       <dbl>\n 1        1 01      AA     699. 1655. 2019.   6.55   7.41   7.61      -0.645\n 2        2 01      AA     685. 1360. 1914.   6.53   7.22   7.56      -0.666\n 3        3 01      AA     713. 1507. 2460.   6.57   7.32   7.81      -0.626\n 4        4 01      AA     801. 1143. 1868.   6.69   7.04   7.53      -0.509\n 5        5 01      AA     757. 1258. 1772.   6.63   7.14   7.48      -0.567\n 6        6 01      AA     804. 1403. 2339.   6.69   7.25   7.76      -0.505\n 7        7 01      AA     664. 1279. 1714.   6.50   7.15   7.45      -0.697\n 8        8 01      AA     757. 1325. 1929.   6.63   7.19   7.56      -0.566\n 9        9 01      AA     730. 1578. 2297.   6.59   7.36   7.74      -0.602\n10       10 01      AA     700. 1546. 2109.   6.55   7.34   7.65      -0.644\n# ℹ 1,090 more rows\n# ℹ 2 more variables: F2_logmeans <dbl>, F3_logmeans <dbl>\n```\n\n\n:::\n:::\n\n\n\nFortunately, `tidynorm` makes this much easier to do now and you can do the whole thing with just one line of code.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |> \n  norm_nearey(F1:F3, .by = speaker, .silent = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 10\n     .id token_id speaker    F1    F2    F3  F1_lm    F2_lm F3_lm vowel\n   <int>    <int> <fct>   <dbl> <dbl> <dbl>  <dbl>    <dbl> <dbl> <chr>\n 1     1        1 01       6.55  7.41  7.61 -0.645  0.216   0.415 AA   \n 2     2        2 01       6.53  7.22  7.56 -0.666  0.0197  0.361 AA   \n 3     3        3 01       6.57  7.32  7.81 -0.626  0.123   0.613 AA   \n 4     4        4 01       6.69  7.04  7.53 -0.509 -0.154   0.337 AA   \n 5     5        5 01       6.63  7.14  7.48 -0.567 -0.0583  0.285 AA   \n 6     6        6 01       6.69  7.25  7.76 -0.505  0.0506  0.562 AA   \n 7     7        7 01       6.50  7.15  7.45 -0.697 -0.0416  0.251 AA   \n 8     8        8 01       6.63  7.19  7.56 -0.566 -0.00604 0.369 AA   \n 9     9        9 01       6.59  7.36  7.74 -0.602  0.169   0.544 AA   \n10    10       10 01       6.55  7.34  7.65 -0.644  0.148   0.459 AA   \n# ℹ 1,090 more rows\n```\n\n\n:::\n:::\n\n\n\n:::{.callout-note}\nIt appears that the original F1--F3 columns have been lost and new log-transformed versions of them take their place. This appears to be a bug in the procedure and will hopefully be fixed soon.\n:::\n\nAs I was playing with this, I realized that my own `norm_logmeans` function wasn't necessarily returning the same output. I found out it was for two reasons. First, I have been using `log10` instead of `log` as input. I'm now pretty concerned that I might has messed up a lot of people's analyses, including my own! The other reason was I had to make sure that I was using all the same formants (F1--F3 and not just F1 and F2) when doing the two procedures to get them to match. Fortunately, they do, which means my `norm_logmeans` function did indeed have the match all incorporated correctly. Still, I'd recommend switching over to `tidynorm` because it's a whole lot less clunky than my own version. \n\n## Delta-F Normalization\n\nIn my joeyr package, I have a function called `norm_deltaF`. I wrote it quickly without much testing and I honestly haven't used it much. But it does work:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |>\n   group_by(speaker) |>\n   joeyr_norm_deltaF(F1, F2, F3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 9\n# Groups:   speaker [10]\n   token_id speaker vowel    F1    F2    F3 F1_deltaF F2_deltaF F3_deltaF\n      <int> <fct>   <chr> <dbl> <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n 1        1 01      AA     699. 1655. 2019.     0.626      1.48      1.81\n 2        2 01      AA     685. 1360. 1914.     0.614      1.22      1.71\n 3        3 01      AA     713. 1507. 2460.     0.639      1.35      2.20\n 4        4 01      AA     801. 1143. 1868.     0.718      1.02      1.67\n 5        5 01      AA     757. 1258. 1772.     0.677      1.13      1.59\n 6        6 01      AA     804. 1403. 2339.     0.720      1.26      2.09\n 7        7 01      AA     664. 1279. 1714.     0.595      1.15      1.53\n 8        8 01      AA     757. 1325. 1929.     0.678      1.19      1.73\n 9        9 01      AA     730. 1578. 2297.     0.654      1.41      2.06\n10       10 01      AA     700. 1546. 2109.     0.627      1.38      1.89\n# ℹ 1,090 more rows\n```\n\n\n:::\n:::\n\n\n\nBut, this too was a bit clunky because rather than passing in all the formant columns at once, it actually required F1, F2, and F3 to be separate arguments. As expected, `tidynorm::norm_deltaF` handles this in a much more straightforward manner.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |>\n   tidynorm::norm_deltaF(F1:F3, .by = speaker, .silent = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 10\n     .id token_id speaker    F1    F2    F3 F1_df F2_df F3_df vowel\n   <int>    <int> <fct>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>\n 1     1        1 01       699. 1655. 2019. 0.626  1.48  1.81 AA   \n 2     2        2 01       685. 1360. 1914. 0.614  1.22  1.71 AA   \n 3     3        3 01       713. 1507. 2460. 0.639  1.35  2.20 AA   \n 4     4        4 01       801. 1143. 1868. 0.718  1.02  1.67 AA   \n 5     5        5 01       757. 1258. 1772. 0.677  1.13  1.59 AA   \n 6     6        6 01       804. 1403. 2339. 0.720  1.26  2.09 AA   \n 7     7        7 01       664. 1279. 1714. 0.595  1.15  1.53 AA   \n 8     8        8 01       757. 1325. 1929. 0.678  1.19  1.73 AA   \n 9     9        9 01       730. 1578. 2297. 0.654  1.41  2.06 AA   \n10    10       10 01       700. 1546. 2109. 0.627  1.38  1.89 AA   \n# ℹ 1,090 more rows\n```\n\n\n:::\n:::\n\n\n\nOne (of several) major benefits to `tidynorm` is its consistency in syntax. All three of my normalization procedures had different syntax, which reflected wildly different implementations under the hood. It was not good. `tidynorm`'s functions are all consistent because they actually call a more general `norm_generic`. \n\n## Bark Difference Metric\n\nThe last one that I've written code for that `tidynorm` handles so much better is the Bark Difference Metric. This was once a part of `joeyr` but I moved it to `barktools` instead. Here's how you'd get the Bark Difference Metric using that package. First, you calculate the barks, and then you manually get the difference metric.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |> \n  mutate(across(F1:F3, bark, .names = \"{.col}_bark\"),\n         F1_barkdiff = F1_bark - F3_bark,\n         F2_barkdiff = F2_bark - F3_bark)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 11\n   token_id speaker vowel    F1    F2    F3 F1_bark F2_bark F3_bark F1_barkdiff\n      <int> <fct>   <chr> <dbl> <dbl> <dbl>   <dbl>   <dbl>   <dbl>       <dbl>\n 1        1 01      AA     699. 1655. 2019.    6.52   11.7     13.1       -6.55\n 2        2 01      AA     685. 1360. 1914.    6.41   10.5     12.7       -6.30\n 3        3 01      AA     713. 1507. 2460.    6.62   11.1     14.4       -7.77\n 4        4 01      AA     801. 1143. 1868.    7.25    9.34    12.6       -5.30\n 5        5 01      AA     757. 1258. 1772.    6.94    9.95    12.2       -5.26\n 6        6 01      AA     804. 1403. 2339.    7.27   10.7     14.1       -6.79\n 7        7 01      AA     664. 1279. 1714.    6.25   10.1     12.0       -5.72\n 8        8 01      AA     757. 1325. 1929.    6.94   10.3     12.8       -5.83\n 9        9 01      AA     730. 1578. 2297.    6.75   11.4     13.9       -7.19\n10       10 01      AA     700. 1546. 2109.    6.53   11.3     13.4       -6.84\n# ℹ 1,090 more rows\n# ℹ 1 more variable: F2_barkdiff <dbl>\n```\n\n\n:::\n:::\n\n\n\nStraightforward and transparent. Here's how you'd do it in `tidynorm`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |> \n  norm_barkz(F1:F3, .by = speaker, .silent = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 10\n     .id token_id speaker    F1    F2    F3 F1_bz F2_bz F3_bz vowel\n   <int>    <int> <fct>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>\n 1     1        1 01       6.52 11.7   13.1 -6.55 -1.33     0 AA   \n 2     2        2 01       6.41 10.5   12.7 -6.30 -2.26     0 AA   \n 3     3        3 01       6.62 11.1   14.4 -7.77 -3.27     0 AA   \n 4     4        4 01       7.25  9.34  12.6 -5.30 -3.21     0 AA   \n 5     5        5 01       6.94  9.95  12.2 -5.26 -2.25     0 AA   \n 6     6        6 01       7.27 10.7   14.1 -6.79 -3.41     0 AA   \n 7     7        7 01       6.25 10.1   12.0 -5.72 -1.92     0 AA   \n 8     8        8 01       6.94 10.3   12.8 -5.83 -2.48     0 AA   \n 9     9        9 01       6.75 11.4   13.9 -7.19 -2.51     0 AA   \n10    10       10 01       6.53 11.3   13.4 -6.84 -2.08     0 AA   \n# ℹ 1,090 more rows\n```\n\n\n:::\n:::\n\n\n\nLike what we saw with the Lobanov method above, the benefit of using the more lower-level functions is that you are more closely connected to the math. The downside is that it's prone to error and it's not clear from the code what it's actually doing. The benefit of this `norm_barkz` function is that it's all wrapped up into one tidy function and the purpose is clear. In this case the `F1_bz` and `F2_bz` columns correspond to the difference metrics. The `F3_bz` column is not helpful since it's just `Bark(F3) - Bark(F3)`, which is zero, so you can drop it. \n\n## Watt and Fabricious method\n\nThis is not a method I have ever implemented in any of my packages, so I'll just show how it's done in tidynorm. (You can probably guess the syntax by now though!)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidahoans |> \n  norm_wattfab(F1:F3, .by = speaker, .silent = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,100 × 10\n     .id token_id speaker    F1    F2    F3 F1_wf F2_wf F3_wf vowel\n   <int>    <int> <fct>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <chr>\n 1     1        1 01       699. 1655. 2019.  1.27 0.903 0.789 AA   \n 2     2        2 01       685. 1360. 1914.  1.24 0.742 0.748 AA   \n 3     3        3 01       713. 1507. 2460.  1.29 0.822 0.962 AA   \n 4     4        4 01       801. 1143. 1868.  1.45 0.623 0.730 AA   \n 5     5        5 01       757. 1258. 1772.  1.37 0.686 0.693 AA   \n 6     6        6 01       804. 1403. 2339.  1.46 0.765 0.914 AA   \n 7     7        7 01       664. 1279. 1714.  1.20 0.698 0.670 AA   \n 8     8        8 01       757. 1325. 1929.  1.37 0.723 0.754 AA   \n 9     9        9 01       730. 1578. 2297.  1.32 0.861 0.898 AA   \n10    10       10 01       700. 1546. 2109.  1.27 0.843 0.824 AA   \n# ℹ 1,090 more rows\n```\n\n\n:::\n:::\n\n\n\n## Conclusions\n\nAs you can see here, `tidynorm` handles various normalization procedures in a simple way with consistent syntax across functions. While some of my functions kinda worked, this works way better. \n\nIn fact, as of today, **I have depreciated the three normalizations functions within `joeyr`** (`norm_logmeans`, `norm_anae`, and `norm_deltaF`). The functions still do exist, but they do nothing other than give a message saying that you should switch to `tidynorm`. This means, if you update to `joeyr` version 0.10, it'll introduce breaking changes into your code. If you want to keep using my functions, you can by adding `joeyr_` as a prefix to the function name (e.g. `joeyr_norm_logmeans`). \n\nThere is more to `tidynorm` beyond what I've shown here, namely that it handles normalizing trajectory data and DCT coefficients, but I'll have to play around with those later.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}